#!/usr/bin/env python3
"""
CLI Agent Orchestration Testing Suite
Tests the enterprise orchestration of multiple CLI coding agents.
"""

import asyncio
import sys
import uuid
from pathlib import Path
from typing import Dict, List

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from app.core.cli_agent_orchestrator import (
    CLIAgentOrchestrator,
    CLIAgentType,
    AgentCapability,
    AgentTask,
    AgentResponse,
    create_cli_agent_orchestrator
)


class CLIAgentOrchestrationTester:
    """Test CLI agent orchestration capabilities."""
    
    def __init__(self):
        self.orchestrator: CLIAgentOrchestrator = None
        self.test_results = []
    
    async def test_agent_detection(self) -> Dict[str, any]:
        """Test CLI agent auto-detection."""
        print("\n" + "="*60)
        print("TEST 1: CLI AGENT AUTO-DETECTION")
        print("="*60)
        
        try:
            # Create orchestrator and detect agents
            self.orchestrator = await create_cli_agent_orchestrator()
            
            available_agents = self.orchestrator.get_available_agents()
            agent_info = self.orchestrator.agent_info
            
            print(f"âœ… Orchestrator initialized successfully")
            print(f"ğŸ“Š Detection Results:")
            
            for agent_type, info in agent_info.items():
                status = "âœ… Available" if info.is_available else "âŒ Not Found"
                print(f"  {agent_type.value}: {status}")
                if info.is_available:
                    print(f"    Version: {info.version}")
                    print(f"    Path: {info.executable_path}")
                    print(f"    Capabilities: {len(info.capabilities)}")
                else:
                    print(f"    Status: {info.installation_status}")
            
            return {
                "test": "agent_detection",
                "success": True,
                "total_agents_checked": len(agent_info),
                "available_agents": len(available_agents),
                "agent_details": {
                    agent_type.value: {
                        "available": info.is_available,
                        "version": info.version,
                        "capabilities": len(info.capabilities)
                    }
                    for agent_type, info in agent_info.items()
                }
            }
            
        except Exception as e:
            print(f"âŒ Agent detection failed: {e}")
            return {
                "test": "agent_detection",
                "success": False,
                "error": str(e)
            }
    
    async def test_optimal_agent_selection(self) -> Dict[str, any]:
        """Test intelligent agent selection for different tasks."""
        print("\n" + "="*60)
        print("TEST 2: OPTIMAL AGENT SELECTION")
        print("="*60)
        
        try:
            if not self.orchestrator:
                raise Exception("Orchestrator not initialized")
            
            # Test different task types
            test_tasks = [
                {
                    "capability": AgentCapability.ARCHITECTURAL_DESIGN,
                    "description": "Design a microservices architecture",
                    "expected_agent": CLIAgentType.CLAUDE_CODE
                },
                {
                    "capability": AgentCapability.RAPID_PROTOTYPING,
                    "description": "Create a quick prototype",
                    "expected_agent": CLIAgentType.GEMINI_CLI
                },
                {
                    "capability": AgentCapability.OSS_INTEGRATION,
                    "description": "Integrate open source libraries",
                    "expected_agent": CLIAgentType.OPENCODE
                }
            ]
            
            selection_results = []
            
            for i, test_case in enumerate(test_tasks, 1):
                task = AgentTask(
                    id=f"selection_test_{i}",
                    description=test_case["description"],
                    task_type=test_case["capability"],
                    requirements=[test_case["description"]],
                    context={"language": "python"}
                )
                
                selected_agent = self.orchestrator.select_optimal_agent(task)
                
                print(f"Task {i}: {test_case['capability'].value}")
                print(f"  Description: {test_case['description']}")
                print(f"  Selected Agent: {selected_agent.value if selected_agent else 'None'}")
                
                # Check if available agents can handle the task
                available_for_task = []
                for agent_type, adapter in self.orchestrator.agents.items():
                    capabilities = adapter.get_capabilities()
                    if test_case["capability"] in capabilities:
                        score = capabilities[test_case["capability"]]
                        available_for_task.append((agent_type, score))
                
                available_for_task.sort(key=lambda x: x[1], reverse=True)
                print(f"  Available agents: {[(a.value, f'{s:.2f}') for a, s in available_for_task]}")
                
                selection_results.append({
                    "task_type": test_case["capability"].value,
                    "selected_agent": selected_agent.value if selected_agent else None,
                    "available_agents": len(available_for_task)
                })
            
            print(f"\nâœ… Agent selection test completed")
            
            return {
                "test": "optimal_agent_selection",
                "success": True,
                "selection_results": selection_results
            }
            
        except Exception as e:
            print(f"âŒ Agent selection test failed: {e}")
            return {
                "test": "optimal_agent_selection",
                "success": False,
                "error": str(e)
            }
    
    async def test_single_agent_execution(self) -> Dict[str, any]:
        """Test executing tasks with individual agents."""
        print("\n" + "="*60)
        print("TEST 3: SINGLE AGENT EXECUTION")
        print("="*60)
        
        try:
            if not self.orchestrator:
                raise Exception("Orchestrator not initialized")
            
            # Create test task
            task = AgentTask(
                id=f"single_exec_{uuid.uuid4().hex[:8]}",
                description="Create a simple calculator function",
                task_type=AgentCapability.CODE_GENERATION,
                requirements=[
                    "Function should handle basic arithmetic",
                    "Include input validation",
                    "Add comprehensive docstring"
                ],
                context={"language": "python"}
            )
            
            # Test execution with optimal agent
            print(f"ğŸ¯ Task: {task.description}")
            print(f"ğŸ“‹ Requirements: {len(task.requirements)} requirements")
            
            response = await self.orchestrator.execute_with_optimal_agent(task)
            
            print(f"\nğŸ“Š Execution Results:")
            print(f"  Agent: {response.agent_type.value}")
            print(f"  Success: {'âœ…' if response.success else 'âŒ'}")
            print(f"  Execution Time: {response.execution_time_seconds:.2f}s")
            print(f"  Artifacts: {len(response.artifacts)}")
            
            if response.success:
                print(f"  Output Preview: {response.output[:100]}{'...' if len(response.output) > 100 else ''}")
                
                # Show artifacts
                for i, artifact in enumerate(response.artifacts, 1):
                    print(f"  Artifact {i}: {artifact.get('type', 'unknown')} - {artifact.get('file_name', 'unnamed')}")
            else:
                print(f"  Error: {response.error_message}")
            
            return {
                "test": "single_agent_execution",
                "success": response.success,
                "agent_used": response.agent_type.value,
                "execution_time": response.execution_time_seconds,
                "artifacts_generated": len(response.artifacts),
                "error": response.error_message if not response.success else None
            }
            
        except Exception as e:
            print(f"âŒ Single agent execution test failed: {e}")
            return {
                "test": "single_agent_execution",
                "success": False,
                "error": str(e)
            }
    
    async def test_multi_agent_coordination(self) -> Dict[str, any]:
        """Test multi-agent coordination and cross-validation."""
        print("\n" + "="*60)
        print("TEST 4: MULTI-AGENT COORDINATION")
        print("="*60)
        
        try:
            if not self.orchestrator:
                raise Exception("Orchestrator not initialized")
            
            # Create task for multi-agent execution
            task = AgentTask(
                id=f"multi_exec_{uuid.uuid4().hex[:8]}",
                description="Create a REST API endpoint for user management",
                task_type=AgentCapability.CODE_GENERATION,
                requirements=[
                    "POST endpoint for creating users",
                    "Input validation and error handling",
                    "Include unit tests"
                ],
                context={"language": "python", "framework": "fastapi"}
            )
            
            # Get available agents for this task
            available_agents = []
            for agent_type, adapter in self.orchestrator.agents.items():
                capabilities = adapter.get_capabilities()
                if task.task_type in capabilities and capabilities[task.task_type] > 0.5:
                    available_agents.append(agent_type)
            
            print(f"ğŸ¯ Task: {task.description}")
            print(f"ğŸ‘¥ Available agents for task: {[a.value for a in available_agents]}")
            
            if len(available_agents) < 2:
                print("âš ï¸  Need at least 2 agents for multi-agent coordination test")
                print("âœ… Single-agent fallback would be used")
                return {
                    "test": "multi_agent_coordination",
                    "success": True,
                    "note": "Insufficient agents for multi-agent test, single-agent fallback working",
                    "available_agents": len(available_agents)
                }
            
            # Execute with multiple agents
            print(f"\nğŸš€ Executing with {len(available_agents)} agents in parallel...")
            
            responses = await self.orchestrator.execute_with_multiple_agents(task, available_agents[:3])  # Limit to 3 for testing
            
            print(f"\nğŸ“Š Multi-Agent Results:")
            print(f"  Responses received: {len(responses)}")
            
            successful_responses = [r for r in responses if r.success]
            print(f"  Successful executions: {len(successful_responses)}")
            
            # Show individual results
            for i, response in enumerate(responses, 1):
                status = "âœ…" if response.success else "âŒ"
                print(f"  Agent {i} ({response.agent_type.value}): {status} ({response.execution_time_seconds:.2f}s)")
                if not response.success:
                    print(f"    Error: {response.error_message}")
                else:
                    print(f"    Artifacts: {len(response.artifacts)}")
            
            # Calculate consensus
            consensus = self.orchestrator.calculate_consensus(responses)
            print(f"\nğŸ¤ Consensus Analysis:")
            print(f"  Consensus: {consensus.get('consensus', 'unknown')}")
            print(f"  Confidence: {consensus.get('confidence', 0.0):.1%}")
            print(f"  Success Rate: {len(successful_responses)}/{len(responses)}")
            
            return {
                "test": "multi_agent_coordination",
                "success": True,
                "agents_executed": len(responses),
                "successful_agents": len(successful_responses),
                "consensus": consensus,
                "avg_execution_time": sum(r.execution_time_seconds for r in successful_responses) / len(successful_responses) if successful_responses else 0
            }
            
        except Exception as e:
            print(f"âŒ Multi-agent coordination test failed: {e}")
            return {
                "test": "multi_agent_coordination",
                "success": False,
                "error": str(e)
            }
    
    async def test_enterprise_workflow(self) -> Dict[str, any]:
        """Test complete enterprise workflow with CLI agent orchestration."""
        print("\n" + "="*60)
        print("TEST 5: ENTERPRISE WORKFLOW DEMONSTRATION")
        print("="*60)
        
        try:
            if not self.orchestrator:
                raise Exception("Orchestrator not initialized")
            
            # Simulate enterprise development workflow
            workflow_tasks = [
                {
                    "name": "Architecture Design",
                    "capability": AgentCapability.ARCHITECTURAL_DESIGN,
                    "description": "Design authentication system architecture"
                },
                {
                    "name": "Code Generation",
                    "capability": AgentCapability.CODE_GENERATION,
                    "description": "Implement JWT authentication middleware"
                },
                {
                    "name": "Code Review",
                    "capability": AgentCapability.CODE_REVIEW,
                    "description": "Review authentication implementation for security"
                },
                {
                    "name": "Testing",
                    "capability": AgentCapability.TESTING,
                    "description": "Create comprehensive tests for authentication"
                }
            ]
            
            print(f"ğŸ¢ Enterprise Workflow: Authentication System Development")
            print(f"ğŸ“‹ Workflow Steps: {len(workflow_tasks)}")
            
            workflow_results = []
            total_time = 0.0
            
            for i, step in enumerate(workflow_tasks, 1):
                print(f"\nğŸ”„ Step {i}: {step['name']}")
                print(f"   Task: {step['description']}")
                
                task = AgentTask(
                    id=f"workflow_step_{i}",
                    description=step["description"],
                    task_type=step["capability"],
                    requirements=[step["description"]],
                    context={"language": "python", "framework": "fastapi"}
                )
                
                # Execute with optimal agent
                response = await self.orchestrator.execute_with_optimal_agent(task)
                
                status = "âœ…" if response.success else "âŒ"
                print(f"   Result: {status} ({response.agent_type.value}, {response.execution_time_seconds:.2f}s)")
                
                if response.success:
                    print(f"   Artifacts: {len(response.artifacts)} generated")
                    total_time += response.execution_time_seconds
                else:
                    print(f"   Error: {response.error_message}")
                
                workflow_results.append({
                    "step": step["name"],
                    "agent": response.agent_type.value,
                    "success": response.success,
                    "execution_time": response.execution_time_seconds,
                    "artifacts": len(response.artifacts)
                })
            
            successful_steps = len([r for r in workflow_results if r["success"]])
            success_rate = successful_steps / len(workflow_results)
            
            print(f"\nğŸ¯ Enterprise Workflow Summary:")
            print(f"  Total Steps: {len(workflow_results)}")
            print(f"  Successful: {successful_steps}")
            print(f"  Success Rate: {success_rate:.1%}")
            print(f"  Total Time: {total_time:.2f}s")
            print(f"  Avg Time/Step: {total_time/len(workflow_results):.2f}s")
            
            return {
                "test": "enterprise_workflow",
                "success": success_rate >= 0.75,  # 75% success rate minimum
                "workflow_steps": len(workflow_results),
                "successful_steps": successful_steps,
                "success_rate": success_rate,
                "total_execution_time": total_time,
                "step_results": workflow_results
            }
            
        except Exception as e:
            print(f"âŒ Enterprise workflow test failed: {e}")
            return {
                "test": "enterprise_workflow",
                "success": False,
                "error": str(e)
            }
    
    async def run_all_tests(self) -> Dict[str, any]:
        """Run all CLI agent orchestration tests."""
        print("ğŸ¯ CLI AGENT ORCHESTRATION TESTING SUITE")
        print("ğŸ”§ Enterprise Multi-Agent Coordination Validation")
        print("")
        
        # Run all tests
        test_methods = [
            self.test_agent_detection,
            self.test_optimal_agent_selection,
            self.test_single_agent_execution,
            self.test_multi_agent_coordination,
            self.test_enterprise_workflow
        ]
        
        all_results = []
        for test_method in test_methods:
            result = await test_method()
            all_results.append(result)
            self.test_results.append(result)
        
        # Calculate overall results
        successful_tests = len([r for r in all_results if r.get("success", False)])
        total_tests = len(all_results)
        overall_success_rate = successful_tests / total_tests if total_tests > 0 else 0
        
        print("\n" + "="*60)
        print("CLI AGENT ORCHESTRATION TESTING SUMMARY")
        print("="*60)
        
        print(f"Success Rate: {successful_tests}/{total_tests} ({overall_success_rate:.1%})")
        
        for result in all_results:
            status = "âœ…" if result.get("success", False) else "âŒ"
            test_name = result.get("test", "unknown").replace("_", " ").title()
            print(f"{status} {test_name}")
            if not result.get("success", False) and "error" in result:
                print(f"   Error: {result['error']}")
        
        # Overall assessment
        if overall_success_rate >= 0.8:
            print(f"\nğŸ‰ CLI AGENT ORCHESTRATION: ENTERPRISE READY ({overall_success_rate:.1%})")
            enterprise_ready = True
        elif overall_success_rate >= 0.6:
            print(f"\nâš ï¸  CLI AGENT ORCHESTRATION: GOOD PROGRESS ({overall_success_rate:.1%})")
            enterprise_ready = False
        else:
            print(f"\nâŒ CLI AGENT ORCHESTRATION: NEEDS IMPROVEMENT ({overall_success_rate:.1%})")
            enterprise_ready = False
        
        return {
            "overall_success_rate": overall_success_rate,
            "successful_tests": successful_tests,
            "total_tests": total_tests,
            "enterprise_ready": enterprise_ready,
            "test_results": all_results
        }


if __name__ == "__main__":
    async def main():
        tester = CLIAgentOrchestrationTester()
        result = await tester.run_all_tests()
        
        # Exit with appropriate code
        if result["enterprise_ready"]:
            print(f"\nğŸš€ Status: Ready for Strategic Priority 3 (GitHub Integration)")
            sys.exit(0)
        else:
            print(f"\nğŸ”§ Status: CLI orchestration needs refinement before enterprise deployment")
            sys.exit(1)
    
    asyncio.run(main())