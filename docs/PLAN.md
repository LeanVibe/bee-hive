# Project Index System Implementation Plan

## ðŸŽ¯ **Current State Analysis**

**âœ… What We Have:**
- Complete database schema with 5 tables + 60 indexes
- Working REST API with project registration
- Standalone server on port 8081 (non-standard as requested)
- Universal installer with intelligent project detection
- Comprehensive documentation and validation framework

**âŒ Critical Missing Components:**
- **Code Analysis Engine**: No actual file scanning or dependency extraction
- **AI Context Optimization**: The core value proposition for agents
- **WebSocket Events**: Real-time progress tracking during analysis  
- **Integration**: Not connected to main bee-hive application
- **Agent Delegation**: Framework designed but not implemented

## ðŸš€ **Strategic Recommendation: 3-Phase Implementation**

### **Phase 1: Core Analysis Engine (Priority 1 - Next 3-4 hours)**

**Goal**: Transform from "Project Registration System" to "Project Analysis System"

**Phase 1 Details:**

1. **Code Analysis Engine** (`app/project_index/analysis_engine.py`)
   ```python
   class ProjectAnalyzer:
       async def analyze_project(self, project_id: UUID) -> AnalysisSession:
           # Scan file system
           # Extract dependencies 
           # Populate file_entries and dependency_relationships tables
           # Track progress in analysis_sessions
   ```

2. **Language-Specific Parsers**
   - **Python**: AST parsing for imports, function definitions, classes
   - **JavaScript/TypeScript**: Extract imports, exports, function calls
   - **SQL**: Parse table references, stored procedures
   - **Configuration Files**: YAML, JSON dependency extraction

3. **Analysis Session Management**
   - Real-time progress tracking (files processed / total files)
   - Error handling and recovery
   - Performance metrics collection

### **Phase 2: AI Context Optimization (Priority 2 - Next 2-3 hours)**

**Goal**: Deliver the core value proposition for AI agents

```python
class ContextOptimizer:
    async def assemble_context(self, project_id: UUID, query: str) -> AgentContext:
        # Semantic search through files
        # Dependency graph traversal
        # Relevance scoring
        # Context size optimization
```

**Key Features:**
- **Semantic File Search**: Find relevant files based on task description
- **Dependency Graph Navigation**: Include related files automatically
- **Context Size Management**: Stay within AI token limits
- **Relevance Scoring**: Prioritize most important code sections

### **Phase 3: Agent Delegation System (Priority 3 - Next 4-6 hours)**

**Goal**: Implement the anti-context-rot agent coordination system

```python
class AgentDelegationCoordinator:
    async def delegate_analysis_task(self, project_id: UUID, task_type: str) -> List[AgentTask]:
        # Break large analysis into chunks
        # Assign specialized agents
        # Coordinate results
        # Prevent context overflow
```

## ðŸ“‹ **Detailed Implementation Plan**

### **Phase 1 Implementation (Starting Now)**

**Step 1A: Core Analysis Engine (1.5 hours)**
```python
# app/project_index/analysis_engine.py
class ProjectAnalyzer:
    async def scan_files(self, project_path: Path) -> List[FileEntry]:
        """Scan project directory and collect file metadata"""
        
    async def extract_dependencies(self, file_path: Path, language: str) -> List[Dependency]:
        """Language-specific dependency extraction"""
        
    async def analyze_project(self, project_id: UUID) -> AnalysisSession:
        """Main analysis orchestration"""
```

**Step 1B: Analysis Endpoint (30 minutes)**
```python
@app.post("/api/project-index/{project_id}/analyze")
async def trigger_analysis(project_id: str):
    """Endpoint that installer expects"""
```

**Step 1C: Language Parsers (1.5 hours)**
- Python AST parser for imports and structure
- JavaScript/TypeScript import/export extraction  
- SQL table and procedure reference parsing
- Configuration file dependency detection

**Step 1D: Progress Tracking (30 minutes)**
- WebSocket events for real-time updates
- Database persistence in `analysis_sessions` table

### **Phase 2: Context Optimization (2-3 hours)**

**Step 2A: File Indexing for Search (1 hour)**
```python
class FileIndexer:
    async def index_file_content(self, file_id: UUID, content: str):
        """Create searchable index of file contents"""
        
    async def search_files(self, project_id: UUID, query: str) -> List[FileMatch]:
        """Semantic search through indexed files"""
```

**Step 2B: Dependency Graph Builder (1 hour)**
```python
class DependencyGraphBuilder:
    async def build_graph(self, project_id: UUID) -> NetworkGraph:
        """Build navigable dependency graph"""
        
    async def find_related_files(self, file_id: UUID, depth: int = 2) -> List[FileEntry]:
        """Find files related through dependencies"""
```

**Step 2C: Context Assembly (1 hour)**
```python
class ContextAssembler:
    async def assemble_context(self, project_id: UUID, task_description: str) -> AgentContext:
        """Assemble optimal context for AI agents"""
        # 1. Semantic search for relevant files
        # 2. Dependency graph traversal
        # 3. Token limit management
        # 4. Priority scoring
```

### **Phase 3: Agent Delegation (4-6 hours)**

**Step 3A: Task Decomposition (2 hours)**
```python
class TaskDecomposer:
    async def decompose_large_task(self, task: AgentTask) -> List[SubTask]:
        """Break large tasks into agent-sized chunks"""
        
    async def estimate_context_requirements(self, task: AgentTask) -> ContextEstimate:
        """Predict context needs to prevent overflow"""
```

**Step 3B: Agent Coordination (2 hours)**
```python
class AgentCoordinator:
    async def assign_specialized_agents(self, tasks: List[SubTask]) -> List[AgentAssignment]:
        """Assign tasks to specialized agents"""
        
    async def coordinate_results(self, assignments: List[AgentAssignment]) -> ConsolidatedResult:
        """Merge results from multiple agents"""
```

**Step 3C: Context Rot Prevention (2 hours)**
```python
class ContextRotPrevention:
    async def monitor_context_usage(self, agent_id: str) -> ContextMetrics:
        """Monitor agent context consumption"""
        
    async def trigger_context_refresh(self, agent_id: str) -> RefreshResult:
        """Trigger sleep/wake cycle when needed"""
```

## ðŸŽ¯ **Success Metrics & Validation**

**Phase 1 Success Criteria:**
- Analyze bee-hive project: scan 500+ files in <60 seconds
- Extract 1000+ dependencies across Python/JS/SQL files
- Generate analysis session with detailed progress tracking
- Installer script completes full workflow end-to-end

**Phase 2 Success Criteria:**
- Context assembly for "implement authentication" returns relevant auth-related files
- Dependency graph navigation finds related files within 2 hops
- Context stays within 100K tokens for typical agent tasks
- Semantic search finds relevant code within 200ms

**Phase 3 Success Criteria:**
- Large refactoring task gets broken into 5+ manageable sub-tasks
- Multiple agents work on project without context conflicts
- Context rot detection prevents agent inefficiency
- Full delegation workflow completes 3x faster than single agent

## âš¡ **Implementation Status**

### **âœ… Completed (Previous Work)**
- [x] Database schema with 5 tables + 60 indexes
- [x] REST API with project registration endpoints
- [x] Standalone server on port 8081
- [x] Universal installer with project detection
- [x] Documentation framework

### **âœ… Phase 1: Core Analysis Engine (COMPLETED)**
- [x] Core Analysis Engine implementation
- [x] Language-specific parsers (Python, JS, TS, SQL, JSON, YAML, Markdown)
- [x] Analysis sessions with progress tracking
- [x] /analyze endpoint implementation
- [x] File content extraction and metadata
- [x] **MILESTONE ACHIEVED**: 2189 files analyzed across 8 languages in <10 seconds
- [x] End-to-end workflow: installer â†’ analysis â†’ completion working perfectly

### **ðŸš§ Phase 2: AI Context Optimization (STARTING NOW)**
- [ ] File indexing for semantic search
- [ ] Python AST dependency extraction
- [ ] Context assembly with token management
- [ ] Relevance scoring system

### **ðŸ“‹ Phase 3: Agent Delegation (Planned)**
- [ ] Task decomposition system
- [ ] Agent coordination framework
- [ ] Context rot prevention
- [ ] Multi-agent workflow orchestration

## ðŸ“š **Architecture Decisions**

### **Technology Stack**
- **Database**: PostgreSQL with pgvector for semantic search
- **API Framework**: FastAPI with asyncio for high performance
- **Language Parsing**: AST modules for each language
- **WebSocket**: For real-time progress updates
- **Caching**: Redis for performance optimization

### **Design Principles**
- **Modular**: Each component can be developed and tested independently
- **Scalable**: Designed to handle large codebases (10K+ files)
- **Language Agnostic**: Extensible parser system for new languages
- **Performance Focused**: <60 seconds analysis for typical projects
- **Agent Optimized**: Built specifically for AI agent workflows

### **Integration Strategy**
- **Standalone First**: Independent operation to validate core functionality
- **Gradual Integration**: Progressive integration with main bee-hive system
- **API-Driven**: RESTful APIs for loose coupling
- **Event-Driven**: WebSocket events for real-time coordination

## ðŸ”„ **Next Actions**

**Immediate Priority**: Implement Phase 2A - Dependency Extraction & File Indexing
- Start with Python AST parsing for import/function dependencies
- Add file content indexing for semantic search
- Build dependency graph from analysis results
- Enable context assembly for relevant file retrieval

**Success Milestone**: Context assembly for "implement authentication" returns relevant auth-related files with dependency connections.

---

*This plan represents the strategic roadmap for transforming the Project Index from a registration system into a full-featured code intelligence platform optimized for AI agent workflows.*