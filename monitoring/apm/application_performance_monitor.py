"""
Epic 7 Phase 3: Comprehensive Application Performance Monitoring (APM)

Production-grade APM system with:
- Detailed API endpoint monitoring with response times and error rates
- Business metrics tracking (user registrations, API usage, system utilization)
- Distributed tracing for request flow across services
- Performance profiling for database queries and API operations
- Real-time performance anomaly detection
"""

import asyncio
import json
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
import structlog

from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry, generate_latest
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

logger = structlog.get_logger()


@dataclass
class APIEndpointMetrics:
    """Comprehensive API endpoint performance metrics."""
    endpoint: str
    method: str
    total_requests: int = 0
    error_count: int = 0
    response_times: List[float] = field(default_factory=list)
    status_codes: Dict[int, int] = field(default_factory=dict)
    last_request_time: Optional[datetime] = None
    avg_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0
    error_rate: float = 0.0
    requests_per_second: float = 0.0


@dataclass 
class BusinessMetrics:
    """Real-time business value metrics."""
    user_registrations_count: int = 0
    user_registrations_rate_per_hour: float = 0.0
    api_usage_count: int = 0
    api_usage_rate_per_minute: float = 0.0
    active_users_current: int = 0
    active_sessions_count: int = 0
    task_completion_rate: float = 0.0
    system_utilization_cpu: float = 0.0
    system_utilization_memory: float = 0.0
    system_utilization_disk: float = 0.0
    database_connection_utilization: float = 0.0
    redis_memory_utilization: float = 0.0


@dataclass
class PerformanceAnomaly:
    """Performance anomaly detection result."""
    metric_name: str
    current_value: float
    baseline_value: float
    deviation_percent: float
    severity: str  # 'warning', 'critical'
    detected_at: datetime
    description: str


class ApplicationPerformanceMonitor:
    """
    Comprehensive APM system for Epic 7 Phase 3.
    
    Provides real-time monitoring, business intelligence, and performance optimization
    for production systems with <100ms monitoring overhead.
    """
    
    def __init__(self):
        self.registry = CollectorRegistry()
        self.setup_prometheus_metrics()
        self.setup_distributed_tracing()
        
        # Real-time metrics storage
        self.api_metrics: Dict[str, APIEndpointMetrics] = {}
        self.business_metrics = BusinessMetrics()
        self.performance_baselines: Dict[str, float] = {}
        self.anomalies: List[PerformanceAnomaly] = []
        
        # Configuration
        self.monitoring_enabled = True
        self.trace_sample_rate = 0.1  # 10% sampling for production
        self.anomaly_detection_threshold = 2.0  # 2 standard deviations
        
        logger.info("üöÄ Application Performance Monitor initialized for Epic 7 Phase 3")
        
    def setup_prometheus_metrics(self):
        """Initialize Prometheus metrics for comprehensive monitoring."""
        
        # API Performance Metrics
        self.api_request_count = Counter(
            'leanvibe_api_requests_total',
            'Total API requests by endpoint and method',
            ['endpoint', 'method', 'status_code'],
            registry=self.registry
        )
        
        self.api_request_duration = Histogram(
            'leanvibe_api_request_duration_seconds',
            'API request duration in seconds',
            ['endpoint', 'method'],
            buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
            registry=self.registry
        )
        
        self.api_error_rate = Gauge(
            'leanvibe_api_error_rate',
            'API error rate by endpoint',
            ['endpoint', 'method'],
            registry=self.registry
        )
        
        # Business Metrics
        self.user_registrations_total = Counter(
            'leanvibe_user_registrations_total',
            'Total user registrations',
            registry=self.registry
        )
        
        self.active_users_gauge = Gauge(
            'leanvibe_active_users_current',
            'Current active users',
            registry=self.registry
        )
        
        self.api_usage_counter = Counter(
            'leanvibe_api_usage_total',
            'Total API usage by user type',
            ['user_type', 'api_category'],
            registry=self.registry
        )
        
        self.task_completion_rate = Gauge(
            'leanvibe_task_completion_rate',
            'Task completion success rate',
            registry=self.registry
        )
        
        # System Utilization Metrics
        self.system_cpu_utilization = Gauge(
            'leanvibe_system_cpu_utilization_percent',
            'System CPU utilization percentage',
            registry=self.registry
        )
        
        self.system_memory_utilization = Gauge(
            'leanvibe_system_memory_utilization_percent', 
            'System memory utilization percentage',
            registry=self.registry
        )
        
        self.database_connection_utilization = Gauge(
            'leanvibe_database_connection_utilization_percent',
            'Database connection pool utilization',
            registry=self.registry
        )
        
        # Performance Anomaly Metrics
        self.performance_anomalies = Gauge(
            'leanvibe_performance_anomalies_detected',
            'Number of performance anomalies detected',
            ['severity'],
            registry=self.registry
        )
        
    def setup_distributed_tracing(self):
        """Initialize OpenTelemetry distributed tracing."""
        try:
            # Configure trace provider
            trace.set_tracer_provider(TracerProvider())
            tracer = trace.get_tracer(__name__)
            
            # Configure Jaeger exporter for distributed tracing
            jaeger_exporter = JaegerExporter(
                agent_host_name="localhost",
                agent_port=6831,
            )
            
            span_processor = BatchSpanProcessor(jaeger_exporter)
            trace.get_tracer_provider().add_span_processor(span_processor)
            
            # Instrument FastAPI and SQLAlchemy
            FastAPIInstrumentor.instrument()
            SQLAlchemyInstrumentor.instrument()
            
            logger.info("‚úÖ Distributed tracing configured with Jaeger")
            
        except Exception as e:
            logger.error("‚ùå Failed to setup distributed tracing", error=str(e))
            
    async def track_api_request(self, endpoint: str, method: str, status_code: int, 
                              response_time: float, user_id: Optional[str] = None):
        """Track API request performance with comprehensive metrics."""
        if not self.monitoring_enabled:
            return
            
        try:
            # Update Prometheus metrics
            self.api_request_count.labels(
                endpoint=endpoint,
                method=method, 
                status_code=status_code
            ).inc()
            
            self.api_request_duration.labels(
                endpoint=endpoint,
                method=method
            ).observe(response_time)
            
            # Update internal metrics
            key = f"{method}:{endpoint}"
            if key not in self.api_metrics:
                self.api_metrics[key] = APIEndpointMetrics(endpoint=endpoint, method=method)
                
            metrics = self.api_metrics[key]
            metrics.total_requests += 1
            metrics.response_times.append(response_time)
            metrics.last_request_time = datetime.utcnow()
            
            if status_code >= 400:
                metrics.error_count += 1
                
            metrics.status_codes[status_code] = metrics.status_codes.get(status_code, 0) + 1
            
            # Calculate derived metrics
            await self._calculate_derived_metrics(metrics)
            
            # Update API usage business metrics
            if user_id:
                self.api_usage_counter.labels(
                    user_type="authenticated",
                    api_category=self._categorize_endpoint(endpoint)
                ).inc()
            else:
                self.api_usage_counter.labels(
                    user_type="anonymous", 
                    api_category=self._categorize_endpoint(endpoint)
                ).inc()
                
            # Check for performance anomalies
            await self._detect_performance_anomalies(key, response_time)
            
        except Exception as e:
            logger.error("‚ùå Failed to track API request", endpoint=endpoint, error=str(e))
            
    async def track_user_registration(self, user_id: str, registration_success: bool):
        """Track user registration business metrics."""
        try:
            if registration_success:
                self.user_registrations_total.inc()
                self.business_metrics.user_registrations_count += 1
                
                # Calculate registration rate per hour
                await self._update_registration_rate()
                
                logger.info("üìä User registration tracked", 
                          user_id=user_id, 
                          total_registrations=self.business_metrics.user_registrations_count)
                          
        except Exception as e:
            logger.error("‚ùå Failed to track user registration", error=str(e))
            
    async def track_system_utilization(self, cpu_percent: float, memory_percent: float, 
                                     disk_percent: float, db_connections_percent: float,
                                     redis_memory_percent: float):
        """Track system utilization metrics."""
        try:
            # Update Prometheus metrics
            self.system_cpu_utilization.set(cpu_percent)
            self.system_memory_utilization.set(memory_percent)
            self.database_connection_utilization.set(db_connections_percent)
            
            # Update business metrics
            self.business_metrics.system_utilization_cpu = cpu_percent
            self.business_metrics.system_utilization_memory = memory_percent
            self.business_metrics.system_utilization_disk = disk_percent
            self.business_metrics.database_connection_utilization = db_connections_percent
            self.business_metrics.redis_memory_utilization = redis_memory_percent
            
            # Check for resource anomalies
            await self._detect_resource_anomalies(cpu_percent, memory_percent, db_connections_percent)
            
        except Exception as e:
            logger.error("‚ùå Failed to track system utilization", error=str(e))
            
    async def track_active_users(self, current_active_count: int, current_sessions_count: int):
        """Track active user business metrics."""
        try:
            self.active_users_gauge.set(current_active_count)
            self.business_metrics.active_users_current = current_active_count
            self.business_metrics.active_sessions_count = current_sessions_count
            
        except Exception as e:
            logger.error("‚ùå Failed to track active users", error=str(e))
            
    async def track_task_completion(self, task_id: str, success: bool, execution_time: float):
        """Track task completion rates and performance."""
        try:
            # Update task completion rate (simplified calculation)
            current_rate = self.business_metrics.task_completion_rate
            if success:
                # Exponential moving average for success rate
                self.business_metrics.task_completion_rate = 0.9 * current_rate + 0.1 * 1.0
            else:
                self.business_metrics.task_completion_rate = 0.9 * current_rate + 0.1 * 0.0
                
            self.task_completion_rate.set(self.business_metrics.task_completion_rate)
            
        except Exception as e:
            logger.error("‚ùå Failed to track task completion", error=str(e))
            
    async def get_performance_summary(self) -> Dict[str, Any]:
        """Get comprehensive performance summary for dashboard."""
        try:
            # Calculate API performance summary
            api_summary = {}
            for key, metrics in self.api_metrics.items():
                api_summary[key] = {
                    "total_requests": metrics.total_requests,
                    "error_rate": metrics.error_rate,
                    "avg_response_time": metrics.avg_response_time,
                    "p95_response_time": metrics.p95_response_time,
                    "requests_per_second": metrics.requests_per_second
                }
                
            # Get business metrics summary
            business_summary = {
                "user_registrations_count": self.business_metrics.user_registrations_count,
                "user_registrations_rate_per_hour": self.business_metrics.user_registrations_rate_per_hour,
                "active_users_current": self.business_metrics.active_users_current,
                "api_usage_rate_per_minute": self.business_metrics.api_usage_rate_per_minute,
                "task_completion_rate": self.business_metrics.task_completion_rate,
                "system_utilization": {
                    "cpu": self.business_metrics.system_utilization_cpu,
                    "memory": self.business_metrics.system_utilization_memory,
                    "disk": self.business_metrics.system_utilization_disk,
                    "database_connections": self.business_metrics.database_connection_utilization,
                    "redis_memory": self.business_metrics.redis_memory_utilization
                }
            }
            
            # Get recent anomalies
            recent_anomalies = [
                {
                    "metric": anomaly.metric_name,
                    "severity": anomaly.severity,
                    "deviation_percent": anomaly.deviation_percent,
                    "detected_at": anomaly.detected_at.isoformat(),
                    "description": anomaly.description
                }
                for anomaly in self.anomalies[-10:]  # Last 10 anomalies
            ]
            
            return {
                "timestamp": datetime.utcnow().isoformat(),
                "api_performance": api_summary,
                "business_metrics": business_summary,
                "performance_anomalies": recent_anomalies,
                "monitoring_status": {
                    "enabled": self.monitoring_enabled,
                    "trace_sample_rate": self.trace_sample_rate,
                    "endpoints_monitored": len(self.api_metrics),
                    "anomalies_detected": len(self.anomalies)
                }
            }
            
        except Exception as e:
            logger.error("‚ùå Failed to get performance summary", error=str(e))
            return {"error": str(e)}
            
    async def get_prometheus_metrics(self) -> str:
        """Generate Prometheus-compatible metrics."""
        try:
            return generate_latest(self.registry).decode('utf-8')
        except Exception as e:
            logger.error("‚ùå Failed to generate Prometheus metrics", error=str(e))
            return ""
            
    async def _calculate_derived_metrics(self, metrics: APIEndpointMetrics):
        """Calculate derived performance metrics."""
        if len(metrics.response_times) == 0:
            return
            
        # Calculate averages and percentiles
        response_times = sorted(metrics.response_times)
        metrics.avg_response_time = sum(response_times) / len(response_times)
        
        if len(response_times) >= 20:  # Need enough data for percentiles
            p95_index = int(0.95 * len(response_times))
            p99_index = int(0.99 * len(response_times))
            metrics.p95_response_time = response_times[p95_index]
            metrics.p99_response_time = response_times[p99_index]
            
        # Calculate error rate
        metrics.error_rate = metrics.error_count / metrics.total_requests if metrics.total_requests > 0 else 0.0
        
        # Update Prometheus error rate
        self.api_error_rate.labels(
            endpoint=metrics.endpoint,
            method=metrics.method
        ).set(metrics.error_rate)
        
        # Keep only recent response times (rolling window)
        if len(metrics.response_times) > 1000:
            metrics.response_times = metrics.response_times[-500:]  # Keep last 500
            
    def _categorize_endpoint(self, endpoint: str) -> str:
        """Categorize API endpoint for business metrics."""
        if '/auth' in endpoint:
            return 'authentication'
        elif '/users' in endpoint:
            return 'user_management'
        elif '/tasks' in endpoint:
            return 'task_management'
        elif '/agents' in endpoint:
            return 'agent_operations'
        elif '/monitoring' in endpoint:
            return 'monitoring'
        else:
            return 'general'
            
    async def _update_registration_rate(self):
        """Update user registration rate per hour."""
        # Simplified calculation - in production would use time-series data
        self.business_metrics.user_registrations_rate_per_hour = self.business_metrics.user_registrations_count * 0.1
        
    async def _detect_performance_anomalies(self, endpoint_key: str, response_time: float):
        """Detect performance anomalies using statistical analysis."""
        try:
            baseline_key = f"baseline_{endpoint_key}_response_time"
            
            if baseline_key not in self.performance_baselines:
                # Establish baseline
                self.performance_baselines[baseline_key] = response_time
                return
                
            baseline = self.performance_baselines[baseline_key]
            deviation_percent = abs(response_time - baseline) / baseline * 100
            
            if deviation_percent > (self.anomaly_detection_threshold * 100):
                severity = "critical" if deviation_percent > 300 else "warning"
                
                anomaly = PerformanceAnomaly(
                    metric_name=f"{endpoint_key}_response_time",
                    current_value=response_time,
                    baseline_value=baseline,
                    deviation_percent=deviation_percent,
                    severity=severity,
                    detected_at=datetime.utcnow(),
                    description=f"Response time deviation of {deviation_percent:.1f}% for {endpoint_key}"
                )
                
                self.anomalies.append(anomaly)
                
                # Update Prometheus anomaly counter
                self.performance_anomalies.labels(severity=severity).inc()
                
                logger.warning("üö® Performance anomaly detected",
                             endpoint=endpoint_key,
                             deviation_percent=deviation_percent,
                             severity=severity)
                             
            # Update baseline with exponential moving average
            self.performance_baselines[baseline_key] = 0.9 * baseline + 0.1 * response_time
            
        except Exception as e:
            logger.error("‚ùå Failed to detect performance anomalies", error=str(e))
            
    async def _detect_resource_anomalies(self, cpu_percent: float, memory_percent: float, 
                                       db_connections_percent: float):
        """Detect system resource anomalies."""
        try:
            thresholds = {
                "cpu": 80.0,
                "memory": 85.0, 
                "database_connections": 90.0
            }
            
            resources = {
                "cpu": cpu_percent,
                "memory": memory_percent,
                "database_connections": db_connections_percent
            }
            
            for resource, current_value in resources.items():
                threshold = thresholds[resource]
                if current_value > threshold:
                    severity = "critical" if current_value > threshold * 1.2 else "warning"
                    
                    anomaly = PerformanceAnomaly(
                        metric_name=f"system_{resource}_utilization",
                        current_value=current_value,
                        baseline_value=threshold,
                        deviation_percent=(current_value - threshold) / threshold * 100,
                        severity=severity,
                        detected_at=datetime.utcnow(),
                        description=f"High {resource} utilization: {current_value:.1f}%"
                    )
                    
                    self.anomalies.append(anomaly)
                    self.performance_anomalies.labels(severity=severity).inc()
                    
                    logger.warning("üö® Resource anomaly detected",
                                 resource=resource,
                                 utilization_percent=current_value,
                                 severity=severity)
                                 
        except Exception as e:
            logger.error("‚ùå Failed to detect resource anomalies", error=str(e))
            

# Global APM instance
apm_monitor = ApplicationPerformanceMonitor()


async def init_apm():
    """Initialize APM system."""
    logger.info("üöÄ Initializing Application Performance Monitor for Epic 7 Phase 3")
    # Additional initialization if needed
    

if __name__ == "__main__":
    # Test the APM system
    async def test_apm():
        await init_apm()
        
        # Simulate some API requests
        await apm_monitor.track_api_request("/api/v2/users", "GET", 200, 0.15, "user123")
        await apm_monitor.track_api_request("/api/v2/tasks", "POST", 201, 0.25, "user123")
        await apm_monitor.track_api_request("/api/v2/agents", "GET", 500, 1.5, "user456")
        
        # Simulate business metrics
        await apm_monitor.track_user_registration("user789", True)
        await apm_monitor.track_system_utilization(45.2, 67.8, 23.4, 12.5, 34.7)
        await apm_monitor.track_active_users(25, 32)
        
        # Get performance summary
        summary = await apm_monitor.get_performance_summary()
        print(json.dumps(summary, indent=2))
        
    asyncio.run(test_apm())