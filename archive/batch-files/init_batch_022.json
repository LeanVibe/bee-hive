{
  "batch_id": "init_batch_022",
  "files": [
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/sqlalchemy/__init__.py",
      "current_size_lines": 273,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "from . import util as _util",
        "from .engine import AdaptedConnection as AdaptedConnection",
        "from .engine import BaseRow as BaseRow",
        "from .engine import BindTyping as BindTyping",
        "from .engine import ChunkedIteratorResult as ChunkedIteratorResult",
        "from .engine import Compiled as Compiled",
        "from .engine import Connection as Connection",
        "from .engine import create_engine as create_engine",
        "from .engine import create_mock_engine as create_mock_engine",
        "from .engine import create_pool_from_url as create_pool_from_url",
        "from .engine import CreateEnginePlugin as CreateEnginePlugin",
        "from .engine import CursorResult as CursorResult",
        "from .engine import Dialect as Dialect",
        "from .engine import Engine as Engine",
        "from .engine import engine_from_config as engine_from_config",
        "from .engine import ExceptionContext as ExceptionContext",
        "from .engine import ExecutionContext as ExecutionContext",
        "from .engine import FrozenResult as FrozenResult",
        "from .engine import Inspector as Inspector",
        "from .engine import IteratorResult as IteratorResult",
        "from .engine import make_url as make_url",
        "from .engine import MappingResult as MappingResult",
        "from .engine import MergedResult as MergedResult",
        "from .engine import NestedTransaction as NestedTransaction",
        "from .engine import Result as Result",
        "from .engine import result_tuple as result_tuple",
        "from .engine import ResultProxy as ResultProxy",
        "from .engine import RootTransaction as RootTransaction",
        "from .engine import Row as Row",
        "from .engine import RowMapping as RowMapping",
        "from .engine import ScalarResult as ScalarResult",
        "from .engine import Transaction as Transaction",
        "from .engine import TwoPhaseTransaction as TwoPhaseTransaction",
        "from .engine import TypeCompiler as TypeCompiler",
        "from .engine import URL as URL",
        "from .inspection import inspect as inspect",
        "from .pool import AssertionPool as AssertionPool",
        "from .pool import AsyncAdaptedQueuePool as AsyncAdaptedQueuePool",
        "from .pool import (",
        "from .pool import NullPool as NullPool",
        "from .pool import Pool as Pool",
        "from .pool import PoolProxiedConnection as PoolProxiedConnection",
        "from .pool import PoolResetState as PoolResetState",
        "from .pool import QueuePool as QueuePool",
        "from .pool import SingletonThreadPool as SingletonThreadPool",
        "from .pool import StaticPool as StaticPool",
        "from .schema import BaseDDLElement as BaseDDLElement",
        "from .schema import BLANK_SCHEMA as BLANK_SCHEMA",
        "from .schema import CheckConstraint as CheckConstraint",
        "from .schema import Column as Column",
        "from .schema import ColumnDefault as ColumnDefault",
        "from .schema import Computed as Computed",
        "from .schema import Constraint as Constraint",
        "from .schema import DDL as DDL",
        "from .schema import DDLElement as DDLElement",
        "from .schema import DefaultClause as DefaultClause",
        "from .schema import ExecutableDDLElement as ExecutableDDLElement",
        "from .schema import FetchedValue as FetchedValue",
        "from .schema import ForeignKey as ForeignKey",
        "from .schema import ForeignKeyConstraint as ForeignKeyConstraint",
        "from .schema import Identity as Identity",
        "from .schema import Index as Index",
        "from .schema import insert_sentinel as insert_sentinel",
        "from .schema import MetaData as MetaData",
        "from .schema import PrimaryKeyConstraint as PrimaryKeyConstraint",
        "from .schema import Sequence as Sequence",
        "from .schema import Table as Table",
        "from .schema import UniqueConstraint as UniqueConstraint",
        "from .sql import ColumnExpressionArgument as ColumnExpressionArgument",
        "from .sql import NotNullable as NotNullable",
        "from .sql import Nullable as Nullable",
        "from .sql import SelectLabelStyle as SelectLabelStyle",
        "from .sql.expression import Alias as Alias",
        "from .sql.expression import alias as alias",
        "from .sql.expression import AliasedReturnsRows as AliasedReturnsRows",
        "from .sql.expression import all_ as all_",
        "from .sql.expression import and_ as and_",
        "from .sql.expression import any_ as any_",
        "from .sql.expression import asc as asc",
        "from .sql.expression import between as between",
        "from .sql.expression import BinaryExpression as BinaryExpression",
        "from .sql.expression import bindparam as bindparam",
        "from .sql.expression import BindParameter as BindParameter",
        "from .sql.expression import bitwise_not as bitwise_not",
        "from .sql.expression import BooleanClauseList as BooleanClauseList",
        "from .sql.expression import CacheKey as CacheKey",
        "from .sql.expression import Case as Case",
        "from .sql.expression import case as case",
        "from .sql.expression import Cast as Cast",
        "from .sql.expression import cast as cast",
        "from .sql.expression import ClauseElement as ClauseElement",
        "from .sql.expression import ClauseList as ClauseList",
        "from .sql.expression import collate as collate",
        "from .sql.expression import CollectionAggregate as CollectionAggregate",
        "from .sql.expression import column as column",
        "from .sql.expression import ColumnClause as ColumnClause",
        "from .sql.expression import ColumnCollection as ColumnCollection",
        "from .sql.expression import ColumnElement as ColumnElement",
        "from .sql.expression import ColumnOperators as ColumnOperators",
        "from .sql.expression import CompoundSelect as CompoundSelect",
        "from .sql.expression import CTE as CTE",
        "from .sql.expression import cte as cte",
        "from .sql.expression import custom_op as custom_op",
        "from .sql.expression import Delete as Delete",
        "from .sql.expression import delete as delete",
        "from .sql.expression import desc as desc",
        "from .sql.expression import distinct as distinct",
        "from .sql.expression import except_ as except_",
        "from .sql.expression import except_all as except_all",
        "from .sql.expression import Executable as Executable",
        "from .sql.expression import Exists as Exists",
        "from .sql.expression import exists as exists",
        "from .sql.expression import Extract as Extract",
        "from .sql.expression import extract as extract",
        "from .sql.expression import false as false",
        "from .sql.expression import False_ as False_",
        "from .sql.expression import FromClause as FromClause",
        "from .sql.expression import FromGrouping as FromGrouping",
        "from .sql.expression import func as func",
        "from .sql.expression import funcfilter as funcfilter",
        "from .sql.expression import Function as Function",
        "from .sql.expression import FunctionElement as FunctionElement",
        "from .sql.expression import FunctionFilter as FunctionFilter",
        "from .sql.expression import GenerativeSelect as GenerativeSelect",
        "from .sql.expression import Grouping as Grouping",
        "from .sql.expression import HasCTE as HasCTE",
        "from .sql.expression import HasPrefixes as HasPrefixes",
        "from .sql.expression import HasSuffixes as HasSuffixes",
        "from .sql.expression import Insert as Insert",
        "from .sql.expression import insert as insert",
        "from .sql.expression import intersect as intersect",
        "from .sql.expression import intersect_all as intersect_all",
        "from .sql.expression import Join as Join",
        "from .sql.expression import join as join",
        "from .sql.expression import Label as Label",
        "from .sql.expression import label as label",
        "from .sql.expression import LABEL_STYLE_DEFAULT as LABEL_STYLE_DEFAULT",
        "from .sql.expression import (",
        "from .sql.expression import LABEL_STYLE_NONE as LABEL_STYLE_NONE",
        "from .sql.expression import (",
        "from .sql.expression import lambda_stmt as lambda_stmt",
        "from .sql.expression import LambdaElement as LambdaElement",
        "from .sql.expression import Lateral as Lateral",
        "from .sql.expression import lateral as lateral",
        "from .sql.expression import literal as literal",
        "from .sql.expression import literal_column as literal_column",
        "from .sql.expression import modifier as modifier",
        "from .sql.expression import not_ as not_",
        "from .sql.expression import Null as Null",
        "from .sql.expression import null as null",
        "from .sql.expression import nulls_first as nulls_first",
        "from .sql.expression import nulls_last as nulls_last",
        "from .sql.expression import nullsfirst as nullsfirst",
        "from .sql.expression import nullslast as nullslast",
        "from .sql.expression import Operators as Operators",
        "from .sql.expression import or_ as or_",
        "from .sql.expression import outerjoin as outerjoin",
        "from .sql.expression import outparam as outparam",
        "from .sql.expression import Over as Over",
        "from .sql.expression import over as over",
        "from .sql.expression import quoted_name as quoted_name",
        "from .sql.expression import ReleaseSavepointClause as ReleaseSavepointClause",
        "from .sql.expression import ReturnsRows as ReturnsRows",
        "from .sql.expression import (",
        "from .sql.expression import SavepointClause as SavepointClause",
        "from .sql.expression import ScalarSelect as ScalarSelect",
        "from .sql.expression import Select as Select",
        "from .sql.expression import select as select",
        "from .sql.expression import Selectable as Selectable",
        "from .sql.expression import SelectBase as SelectBase",
        "from .sql.expression import SQLColumnExpression as SQLColumnExpression",
        "from .sql.expression import StatementLambdaElement as StatementLambdaElement",
        "from .sql.expression import Subquery as Subquery",
        "from .sql.expression import table as table",
        "from .sql.expression import TableClause as TableClause",
        "from .sql.expression import TableSample as TableSample",
        "from .sql.expression import tablesample as tablesample",
        "from .sql.expression import TableValuedAlias as TableValuedAlias",
        "from .sql.expression import text as text",
        "from .sql.expression import TextAsFrom as TextAsFrom",
        "from .sql.expression import TextClause as TextClause",
        "from .sql.expression import TextualSelect as TextualSelect",
        "from .sql.expression import true as true",
        "from .sql.expression import True_ as True_",
        "from .sql.expression import try_cast as try_cast",
        "from .sql.expression import TryCast as TryCast",
        "from .sql.expression import Tuple as Tuple",
        "from .sql.expression import tuple_ as tuple_",
        "from .sql.expression import type_coerce as type_coerce",
        "from .sql.expression import TypeClause as TypeClause",
        "from .sql.expression import TypeCoerce as TypeCoerce",
        "from .sql.expression import UnaryExpression as UnaryExpression",
        "from .sql.expression import union as union",
        "from .sql.expression import union_all as union_all",
        "from .sql.expression import Update as Update",
        "from .sql.expression import update as update",
        "from .sql.expression import UpdateBase as UpdateBase",
        "from .sql.expression import Values as Values",
        "from .sql.expression import values as values",
        "from .sql.expression import ValuesBase as ValuesBase",
        "from .sql.expression import Visitable as Visitable",
        "from .sql.expression import within_group as within_group",
        "from .sql.expression import WithinGroup as WithinGroup",
        "from .types import ARRAY as ARRAY",
        "from .types import BIGINT as BIGINT",
        "from .types import BigInteger as BigInteger",
        "from .types import BINARY as BINARY",
        "from .types import BLOB as BLOB",
        "from .types import BOOLEAN as BOOLEAN",
        "from .types import Boolean as Boolean",
        "from .types import CHAR as CHAR",
        "from .types import CLOB as CLOB",
        "from .types import DATE as DATE",
        "from .types import Date as Date",
        "from .types import DATETIME as DATETIME",
        "from .types import DateTime as DateTime",
        "from .types import DECIMAL as DECIMAL",
        "from .types import DOUBLE as DOUBLE",
        "from .types import Double as Double",
        "from .types import DOUBLE_PRECISION as DOUBLE_PRECISION",
        "from .types import Enum as Enum",
        "from .types import FLOAT as FLOAT",
        "from .types import Float as Float",
        "from .types import INT as INT",
        "from .types import INTEGER as INTEGER",
        "from .types import Integer as Integer",
        "from .types import Interval as Interval",
        "from .types import JSON as JSON",
        "from .types import LargeBinary as LargeBinary",
        "from .types import NCHAR as NCHAR",
        "from .types import NUMERIC as NUMERIC",
        "from .types import Numeric as Numeric",
        "from .types import NVARCHAR as NVARCHAR",
        "from .types import PickleType as PickleType",
        "from .types import REAL as REAL",
        "from .types import SMALLINT as SMALLINT",
        "from .types import SmallInteger as SmallInteger",
        "from .types import String as String",
        "from .types import TEXT as TEXT",
        "from .types import Text as Text",
        "from .types import TIME as TIME",
        "from .types import Time as Time",
        "from .types import TIMESTAMP as TIMESTAMP",
        "from .types import TupleType as TupleType",
        "from .types import TypeDecorator as TypeDecorator",
        "from .types import Unicode as Unicode",
        "from .types import UnicodeText as UnicodeText",
        "from .types import UUID as UUID",
        "from .types import Uuid as Uuid",
        "from .types import VARBINARY as VARBINARY",
        "from .types import VARCHAR as VARCHAR",
        "__version__ = \"2.0.42\"",
        "    from . import exc",
        "    exc._version_token = \"\".join(__version__.split(\".\")[0:2])"
      ],
      "estimated_loc_savings": 14,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/paginate/__init__.py",
      "current_size_lines": 699,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__author__ = \"Christoph Haas\"",
        "__version__ = \"0.5.4\"",
        "__email__ = \"info@webreactor.eu, luke@pumalo.org\""
      ],
      "estimated_loc_savings": 691,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/shellingham/__init__.py",
      "current_size_lines": 19,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "from ._core import ShellDetectionFailure",
        "__version__ = \"1.5.4\""
      ],
      "estimated_loc_savings": 12,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/regex/__init__.py",
      "current_size_lines": 3,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "from .regex import *",
        "from . import regex",
        "__all__ = regex.__all__"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/bandit/__init__.py",
      "current_size_lines": 18,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__author__ = metadata.metadata(\"bandit\")[\"Author\"]",
        "__version__ = metadata.version(\"bandit\")"
      ],
      "estimated_loc_savings": 11,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/wrapt/__init__.py",
      "current_size_lines": 21,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = '.'.join(__version_info__)",
        "from .__wrapt__ import (ObjectProxy, CallableObjectProxy, FunctionWrapper,",
        "from .patches import (resolve_path, apply_patch, wrap_object, wrap_object_attribute,",
        "from .weakrefs import WeakFunctionProxy",
        "from .decorators import (adapter_factory, AdapterFactory, decorator,",
        "from .importer import (register_post_import_hook, when_imported,",
        "from .arguments import formatargspec"
      ],
      "estimated_loc_savings": 9,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/langchain_core/__init__.py",
      "current_size_lines": 15,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = VERSION"
      ],
      "estimated_loc_savings": 9,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/numpy/__init__.py",
      "current_size_lines": 871,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "__version__",
        "from . import version",
        "from ._expired_attrs_2_0 import __expired_attributes__",
        "from ._globals import _CopyMode, _NoValue",
        "from .version import __version__",
        "    from . import _distributor_init",
        "    from . import _core",
        "    from ._core import (",
        "    from . import lib",
        "    from . import matrixlib as _mat",
        "    from .lib import scimath as emath",
        "    from .lib._arraypad_impl import pad",
        "    from .lib._arraysetops_impl import (",
        "    from .lib._function_base_impl import (",
        "    from .lib._histograms_impl import histogram, histogram_bin_edges, histogramdd",
        "    from .lib._index_tricks_impl import (",
        "    from .lib._nanfunctions_impl import (",
        "    from .lib._npyio_impl import (",
        "    from .lib._polynomial_impl import (",
        "    from .lib._shape_base_impl import (",
        "    from .lib._stride_tricks_impl import (",
        "    from .lib._twodim_base_impl import (",
        "    from .lib._type_check_impl import (",
        "    from .lib._ufunclike_impl import fix, isneginf, isposinf",
        "    from .lib._utils_impl import get_include, info, show_runtime",
        "    from .matrixlib import asmatrix, bmat, matrix",
        "    from ._array_api_info import __array_namespace_info__",
        "    __all__ = list(",
        "        set(_core.__all__) |",
        "        set(_mat.__all__) |",
        "        set(lib._histograms_impl.__all__) |",
        "        set(lib._nanfunctions_impl.__all__) |",
        "        set(lib._function_base_impl.__all__) |",
        "        set(lib._twodim_base_impl.__all__) |",
        "        set(lib._shape_base_impl.__all__) |",
        "        set(lib._type_check_impl.__all__) |",
        "        set(lib._arraysetops_impl.__all__) |",
        "        set(lib._ufunclike_impl.__all__) |",
        "        set(lib._arraypad_impl.__all__) |",
        "        set(lib._utils_impl.__all__) |",
        "        set(lib._stride_tricks_impl.__all__) |",
        "        set(lib._polynomial_impl.__all__) |",
        "        set(lib._npyio_impl.__all__) |",
        "        set(lib._index_tricks_impl.__all__) |",
        "        {\"emath\", \"show_config\", \"__version__\", \"__array_namespace_info__\"}",
        "        from . import exceptions"
      ],
      "estimated_loc_savings": 820,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/jose/__init__.py",
      "current_size_lines": 8,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = \"3.5.0\"",
        "__author__ = \"Michael Davis\"",
        "from .exceptions import ExpiredSignatureError  # noqa: F401",
        "from .exceptions import JOSEError  # noqa: F401",
        "from .exceptions import JWSError  # noqa: F401",
        "from .exceptions import JWTError  # noqa: F401"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/charset_normalizer/__init__.py",
      "current_size_lines": 40,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .api import from_bytes, from_fp, from_path, is_binary",
        "from .legacy import detect",
        "from .models import CharsetMatch, CharsetMatches",
        "from .utils import set_logging_handler",
        "from .version import VERSION, __version__",
        "__all__ = (",
        "    \"__version__\","
      ],
      "estimated_loc_savings": 28,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/qrcode/__init__.py",
      "current_size_lines": 22,
      "has_imports": true,
      "has_version": false,
      "has_all": false,
      "preserved_content": [],
      "estimated_loc_savings": 17,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/botocore/__init__.py",
      "current_size_lines": 185,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = '1.40.4'"
      ],
      "estimated_loc_savings": 179,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/httptools/__init__.py",
      "current_size_lines": 4,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from . import parser",
        "from .parser import *  # NOQA",
        "from ._version import __version__  # NOQA",
        "__all__ = parser.__all__ + ('__version__',)  # NOQA"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/PIL/__init__.py",
      "current_size_lines": 73,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "Use PIL.__version__ for this Pillow version.",
        "from . import _version",
        "__version__ = _version.__version__"
      ],
      "estimated_loc_savings": 65,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/requests/__init__.py",
      "current_size_lines": 151,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "from .exceptions import RequestsDependencyWarning",
        "    from charset_normalizer import __version__ as charset_normalizer_version",
        "    from chardet import __version__ as chardet_version",
        "        urllib3.__version__, chardet_version, charset_normalizer_version",
        "            urllib3.__version__, chardet_version, charset_normalizer_version",
        "        from cryptography import __version__ as cryptography_version",
        "from . import packages, utils",
        "from .__version__ import (",
        "    __author__,",
        "    __version__,",
        "from .api import delete, get, head, options, patch, post, put, request",
        "from .exceptions import (",
        "from .models import PreparedRequest, Request, Response",
        "from .sessions import Session, session",
        "from .status_codes import codes"
      ],
      "estimated_loc_savings": 131,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/safety/__init__.py",
      "current_size_lines": 7,
      "has_imports": true,
      "has_version": false,
      "has_all": false,
      "preserved_content": [
        "__author__ = \"\"\"safetycli.com\"\"\"",
        "__email__ = 'support@safetycli.com'"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/termcolor/__init__.py",
      "current_size_lines": 11,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "__all__ = ["
      ],
      "estimated_loc_savings": 5,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/mando/__init__.py",
      "current_size_lines": 12,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = '0.7.1'",
        "    e.version = __version__"
      ],
      "estimated_loc_savings": 5,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/cbor2/__init__.py",
      "current_size_lines": 76,
      "has_imports": true,
      "has_version": false,
      "has_all": false,
      "preserved_content": [
        "from ._decoder import CBORDecoder as CBORDecoder",
        "from ._decoder import load as load",
        "from ._decoder import loads as loads",
        "from ._encoder import CBOREncoder as CBOREncoder",
        "from ._encoder import dump as dump",
        "from ._encoder import dumps as dumps",
        "from ._encoder import shareable_encoder as shareable_encoder",
        "from ._types import CBORDecodeEOF as CBORDecodeEOF",
        "from ._types import CBORDecodeError as CBORDecodeError",
        "from ._types import CBORDecodeValueError as CBORDecodeValueError",
        "from ._types import CBOREncodeError as CBOREncodeError",
        "from ._types import CBOREncodeTypeError as CBOREncodeTypeError",
        "from ._types import CBOREncodeValueError as CBOREncodeValueError",
        "from ._types import CBORError as CBORError",
        "from ._types import CBORSimpleValue as CBORSimpleValue",
        "from ._types import CBORTag as CBORTag",
        "from ._types import FrozenDict as FrozenDict",
        "from ._types import undefined as undefined",
        "        from ._encoder import canonical_encoders, default_encoders",
        "        from ._types import CBORSimpleValue, CBORTag, undefined"
      ],
      "estimated_loc_savings": 51,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/multidict/__init__.py",
      "current_size_lines": 48,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from ._abc import MultiMapping, MutableMultiMapping",
        "from ._compat import USE_EXTENSIONS",
        "__all__ = (",
        "__version__ = \"6.6.3\"",
        "    from ._multidict_py import (",
        "    from ._multidict import ("
      ],
      "estimated_loc_savings": 37,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/anyio/__init__.py",
      "current_size_lines": 100,
      "has_imports": true,
      "has_version": false,
      "has_all": false,
      "preserved_content": [
        "from ._core._contextmanagers import AsyncContextManagerMixin as AsyncContextManagerMixin",
        "from ._core._contextmanagers import ContextManagerMixin as ContextManagerMixin",
        "from ._core._eventloop import current_time as current_time",
        "from ._core._eventloop import get_all_backends as get_all_backends",
        "from ._core._eventloop import get_cancelled_exc_class as get_cancelled_exc_class",
        "from ._core._eventloop import run as run",
        "from ._core._eventloop import sleep as sleep",
        "from ._core._eventloop import sleep_forever as sleep_forever",
        "from ._core._eventloop import sleep_until as sleep_until",
        "from ._core._exceptions import BrokenResourceError as BrokenResourceError",
        "from ._core._exceptions import BrokenWorkerInterpreter as BrokenWorkerInterpreter",
        "from ._core._exceptions import BrokenWorkerProcess as BrokenWorkerProcess",
        "from ._core._exceptions import BusyResourceError as BusyResourceError",
        "from ._core._exceptions import ClosedResourceError as ClosedResourceError",
        "from ._core._exceptions import ConnectionFailed as ConnectionFailed",
        "from ._core._exceptions import DelimiterNotFound as DelimiterNotFound",
        "from ._core._exceptions import EndOfStream as EndOfStream",
        "from ._core._exceptions import IncompleteRead as IncompleteRead",
        "from ._core._exceptions import TypedAttributeLookupError as TypedAttributeLookupError",
        "from ._core._exceptions import WouldBlock as WouldBlock",
        "from ._core._fileio import AsyncFile as AsyncFile",
        "from ._core._fileio import Path as Path",
        "from ._core._fileio import open_file as open_file",
        "from ._core._fileio import wrap_file as wrap_file",
        "from ._core._resources import aclose_forcefully as aclose_forcefully",
        "from ._core._signals import open_signal_receiver as open_signal_receiver",
        "from ._core._sockets import TCPConnectable as TCPConnectable",
        "from ._core._sockets import UNIXConnectable as UNIXConnectable",
        "from ._core._sockets import as_connectable as as_connectable",
        "from ._core._sockets import connect_tcp as connect_tcp",
        "from ._core._sockets import connect_unix as connect_unix",
        "from ._core._sockets import create_connected_udp_socket as create_connected_udp_socket",
        "from ._core._sockets import (",
        "from ._core._sockets import create_tcp_listener as create_tcp_listener",
        "from ._core._sockets import create_udp_socket as create_udp_socket",
        "from ._core._sockets import create_unix_datagram_socket as create_unix_datagram_socket",
        "from ._core._sockets import create_unix_listener as create_unix_listener",
        "from ._core._sockets import getaddrinfo as getaddrinfo",
        "from ._core._sockets import getnameinfo as getnameinfo",
        "from ._core._sockets import notify_closing as notify_closing",
        "from ._core._sockets import wait_readable as wait_readable",
        "from ._core._sockets import wait_socket_readable as wait_socket_readable",
        "from ._core._sockets import wait_socket_writable as wait_socket_writable",
        "from ._core._sockets import wait_writable as wait_writable",
        "from ._core._streams import create_memory_object_stream as create_memory_object_stream",
        "from ._core._subprocesses import open_process as open_process",
        "from ._core._subprocesses import run_process as run_process",
        "from ._core._synchronization import CapacityLimiter as CapacityLimiter",
        "from ._core._synchronization import (",
        "from ._core._synchronization import Condition as Condition",
        "from ._core._synchronization import ConditionStatistics as ConditionStatistics",
        "from ._core._synchronization import Event as Event",
        "from ._core._synchronization import EventStatistics as EventStatistics",
        "from ._core._synchronization import Lock as Lock",
        "from ._core._synchronization import LockStatistics as LockStatistics",
        "from ._core._synchronization import ResourceGuard as ResourceGuard",
        "from ._core._synchronization import Semaphore as Semaphore",
        "from ._core._synchronization import SemaphoreStatistics as SemaphoreStatistics",
        "from ._core._tasks import TASK_STATUS_IGNORED as TASK_STATUS_IGNORED",
        "from ._core._tasks import CancelScope as CancelScope",
        "from ._core._tasks import create_task_group as create_task_group",
        "from ._core._tasks import current_effective_deadline as current_effective_deadline",
        "from ._core._tasks import fail_after as fail_after",
        "from ._core._tasks import move_on_after as move_on_after",
        "from ._core._tempfile import NamedTemporaryFile as NamedTemporaryFile",
        "from ._core._tempfile import SpooledTemporaryFile as SpooledTemporaryFile",
        "from ._core._tempfile import TemporaryDirectory as TemporaryDirectory",
        "from ._core._tempfile import TemporaryFile as TemporaryFile",
        "from ._core._tempfile import gettempdir as gettempdir",
        "from ._core._tempfile import gettempdirb as gettempdirb",
        "from ._core._tempfile import mkdtemp as mkdtemp",
        "from ._core._tempfile import mkstemp as mkstemp",
        "from ._core._testing import TaskInfo as TaskInfo",
        "from ._core._testing import get_current_task as get_current_task",
        "from ._core._testing import get_running_tasks as get_running_tasks",
        "from ._core._testing import wait_all_tasks_blocked as wait_all_tasks_blocked",
        "from ._core._typedattr import TypedAttributeProvider as TypedAttributeProvider",
        "from ._core._typedattr import TypedAttributeSet as TypedAttributeSet",
        "from ._core._typedattr import typed_attribute as typed_attribute"
      ],
      "estimated_loc_savings": 16,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/pip/__init__.py",
      "current_size_lines": 8,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__version__ = \"25.2\""
      ],
      "estimated_loc_savings": 2,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/aiohttp_retry/__init__.py",
      "current_size_lines": 2,
      "has_imports": true,
      "has_version": false,
      "has_all": false,
      "preserved_content": [
        "from .client import *  # noqa: F403",
        "from .retry_options import *  # noqa: F403"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/babel/__init__.py",
      "current_size_lines": 31,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "__version__ = '2.17.0'",
        "__all__ = [",
        "    '__version__',"
      ],
      "estimated_loc_savings": 23,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/sklearn/__init__.py",
      "current_size_lines": 138,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from ._config import config_context, get_config, set_config",
        "__version__ = \"1.7.1\"",
        "from . import (  # noqa: F401 E402",
        "from .base import clone  # noqa: E402",
        "from .utils._show_versions import show_versions  # noqa: E402",
        "__all__ = _submodules + [",
        "    return __all__"
      ],
      "estimated_loc_savings": 126,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/mkdocstrings/__init__.py",
      "current_size_lines": 61,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "__all__: list[str] = ["
      ],
      "estimated_loc_savings": 55,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/importlib_resources/__init__.py",
      "current_size_lines": 37,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "from ._common import (",
        "from ._functional import (",
        "from .abc import ResourceReader",
        "__all__ = ["
      ],
      "estimated_loc_savings": 28,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/dataclasses_json/__init__.py",
      "current_size_lines": 10,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from dataclasses_json.__version__ import __version__",
        "__all__ = ['DataClassJsonMixin', 'LetterCase', 'dataclass_json',"
      ],
      "estimated_loc_savings": 3,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/smmap/__init__.py",
      "current_size_lines": 9,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "__author__ = \"Sebastian Thiel\"",
        "__version__ = '.'.join(str(i) for i in version_info)",
        "from .mman import *",
        "from .buf import *"
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/asn1crypto/__init__.py",
      "current_size_lines": 41,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .version import __version__, __version_info__",
        "__all__ = [",
        "    '__version__',"
      ],
      "estimated_loc_savings": 33,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/mkdocs_autorefs/__init__.py",
      "current_size_lines": 33,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "__all__: list[str] = ["
      ],
      "estimated_loc_savings": 27,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/httpx/__init__.py",
      "current_size_lines": 98,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .__version__ import __description__, __title__, __version__",
        "from ._api import *",
        "from ._auth import *",
        "from ._client import *",
        "from ._config import *",
        "from ._content import *",
        "from ._exceptions import *",
        "from ._models import *",
        "from ._status_codes import *",
        "from ._transports import *",
        "from ._types import *",
        "from ._urls import *",
        "    from ._main import main",
        "__all__ = [",
        "    \"__version__\",",
        "for __name in __all__:"
      ],
      "estimated_loc_savings": 77,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/joblib/__init__.py",
      "current_size_lines": 132,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "__version__ = \"1.5.1\"",
        "from ._cloudpickle_wrapper import wrap_non_picklable_objects",
        "from ._parallel_backends import ParallelBackendBase",
        "from ._store_backends import StoreBackendBase",
        "from .compressor import register_compressor",
        "from .hashing import hash",
        "from .logger import Logger, PrintTime",
        "from .memory import MemorizedResult, Memory, expires_after, register_store_backend",
        "from .numpy_pickle import dump, load",
        "from .parallel import (",
        "__all__ = ["
      ],
      "estimated_loc_savings": 116,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/certifi/__init__.py",
      "current_size_lines": 3,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .core import contents, where",
        "__all__ = [\"contents\", \"where\"]",
        "__version__ = \"2025.08.03\""
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/prompt_toolkit/__init__.py",
      "current_size_lines": 41,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .application import Application",
        "from .formatted_text import ANSI, HTML",
        "from .shortcuts import PromptSession, print_formatted_text, prompt",
        "__version__ = metadata.version(\"prompt_toolkit\")",
        "assert pep440.match(__version__)",
        "VERSION = tuple(int(v.rstrip(\"abrc\")) for v in __version__.split(\".\")[:3])",
        "__all__ = [",
        "    \"__version__\","
      ],
      "estimated_loc_savings": 28,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/griffe/__init__.py",
      "current_size_lines": 539,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "from _griffe.agents.nodes.exports import ExportedName, get__all__, safe_get__all__",
        "__all__ = [",
        "    \"get__all__\",",
        "    \"safe_get__all__\","
      ],
      "estimated_loc_savings": 530,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/safety_schemas/__init__.py",
      "current_size_lines": 0,
      "has_imports": false,
      "has_version": false,
      "has_all": false,
      "preserved_content": [],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/github/__init__.py",
      "current_size_lines": 101,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "from . import Auth",
        "from .AppAuthentication import AppAuthentication",
        "from .GithubException import (",
        "from .GithubIntegration import GithubIntegration",
        "from .GithubRetry import GithubRetry",
        "from .InputFileContent import InputFileContent",
        "from .InputGitAuthor import InputGitAuthor",
        "from .InputGitTreeElement import InputGitTreeElement",
        "from .MainClass import Github",
        "__all__ = ["
      ],
      "estimated_loc_savings": 86,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/sniffio/__init__.py",
      "current_size_lines": 14,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "__all__ = [",
        "from ._version import __version__",
        "from ._impl import ("
      ],
      "estimated_loc_savings": 6,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/attr/__init__.py",
      "current_size_lines": 84,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from . import converters, exceptions, filters, setters, validators",
        "from ._cmp import cmp_using",
        "from ._config import get_run_validators, set_run_validators",
        "from ._funcs import asdict, assoc, astuple, has, resolve_types",
        "from ._make import (",
        "from ._next_gen import define, field, frozen, mutable",
        "from ._version_info import VersionInfo",
        "__all__ = [",
        "        if name not in (\"__version__\", \"__version_info__\"):"
      ],
      "estimated_loc_savings": 70,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/watchdog/__init__.py",
      "current_size_lines": 0,
      "has_imports": false,
      "has_version": false,
      "has_all": false,
      "preserved_content": [],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/pexpect/__init__.py",
      "current_size_lines": 69,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from .exceptions import ExceptionPexpect, EOF, TIMEOUT",
        "from .utils import split_command_line, which, is_executable_file",
        "from .expect import Expecter, searcher_re, searcher_string",
        "    from .pty_spawn import spawn, spawnu",
        "    from .run import run, runu",
        "__version__ = '4.9.0'",
        "__all__ = ['ExceptionPexpect', 'EOF', 'TIMEOUT', 'spawn', 'spawnu', 'run', 'runu',",
        "           'which', 'split_command_line', '__version__', '__revision__']"
      ],
      "estimated_loc_savings": 56,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/tiktoken/__init__.py",
      "current_size_lines": 7,
      "has_imports": true,
      "has_version": true,
      "has_all": false,
      "preserved_content": [
        "from .core import Encoding as Encoding",
        "from .model import encoding_for_model as encoding_for_model",
        "from .model import encoding_name_for_model as encoding_name_for_model",
        "from .registry import get_encoding as get_encoding",
        "from .registry import list_encoding_names as list_encoding_names",
        "__version__ = \"0.10.0\""
      ],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/tree_sitter_python/__init__.py",
      "current_size_lines": 23,
      "has_imports": true,
      "has_version": false,
      "has_all": true,
      "preserved_content": [
        "from ._binding import language",
        "__all__ = [",
        "    return sorted(__all__ + [",
        "        \"__all__\", \"__builtins__\", \"__cached__\", \"__doc__\", \"__file__\","
      ],
      "estimated_loc_savings": 14,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/transformers/__init__.py",
      "current_size_lines": 918,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "__version__ = \"4.55.0\"",
        "from . import dependency_versions_check",
        "from .utils import (",
        "from .utils import is_bitsandbytes_available as is_bitsandbytes_available",
        "from .utils import is_flax_available as is_flax_available",
        "from .utils import is_keras_nlp_available as is_keras_nlp_available",
        "from .utils import is_scipy_available as is_scipy_available",
        "from .utils import is_sentencepiece_available as is_sentencepiece_available",
        "from .utils import is_speech_available as is_speech_available",
        "from .utils import is_tensorflow_text_available as is_tensorflow_text_available",
        "from .utils import is_tf_available as is_tf_available",
        "from .utils import is_timm_available as is_timm_available",
        "from .utils import is_tokenizers_available as is_tokenizers_available",
        "from .utils import is_torch_available as is_torch_available",
        "from .utils import is_torchaudio_available as is_torchaudio_available",
        "from .utils import is_torchvision_available as is_torchvision_available",
        "from .utils import is_vision_available as is_vision_available",
        "from .utils import logging as logging",
        "from .utils.import_utils import define_import_structure",
        "    from .utils import dummy_tokenizers_objects",
        "    from .utils import dummy_sentencepiece_and_tokenizers_objects",
        "    from .utils import dummy_mistral_common_objects",
        "    from .utils import dummy_vision_objects",
        "    from .utils import dummy_torchvision_objects",
        "    from .utils import dummy_pt_objects",
        "    from .utils import dummy_tf_objects",
        "    from .utils import dummy_flax_objects",
        "    from .cache_utils import Cache as Cache",
        "    from .cache_utils import CacheConfig as CacheConfig",
        "    from .cache_utils import DynamicCache as DynamicCache",
        "    from .cache_utils import EncoderDecoderCache as EncoderDecoderCache",
        "    from .cache_utils import HQQQuantizedCache as HQQQuantizedCache",
        "    from .cache_utils import HybridCache as HybridCache",
        "    from .cache_utils import MambaCache as MambaCache",
        "    from .cache_utils import OffloadedCache as OffloadedCache",
        "    from .cache_utils import OffloadedStaticCache as OffloadedStaticCache",
        "    from .cache_utils import QuantizedCache as QuantizedCache",
        "    from .cache_utils import QuantizedCacheConfig as QuantizedCacheConfig",
        "    from .cache_utils import QuantoQuantizedCache as QuantoQuantizedCache",
        "    from .cache_utils import SinkCache as SinkCache",
        "    from .cache_utils import SlidingWindowCache as SlidingWindowCache",
        "    from .cache_utils import StaticCache as StaticCache",
        "    from .configuration_utils import PretrainedConfig as PretrainedConfig",
        "    from .convert_slow_tokenizer import SLOW_TO_FAST_CONVERTERS as SLOW_TO_FAST_CONVERTERS",
        "    from .convert_slow_tokenizer import convert_slow_tokenizer as convert_slow_tokenizer",
        "    from .data import DataProcessor as DataProcessor",
        "    from .data import InputExample as InputExample",
        "    from .data import InputFeatures as InputFeatures",
        "    from .data import SingleSentenceClassificationProcessor as SingleSentenceClassificationProcessor",
        "    from .data import SquadExample as SquadExample",
        "    from .data import SquadFeatures as SquadFeatures",
        "    from .data import SquadV1Processor as SquadV1Processor",
        "    from .data import SquadV2Processor as SquadV2Processor",
        "    from .data import glue_compute_metrics as glue_compute_metrics",
        "    from .data import glue_convert_examples_to_features as glue_convert_examples_to_features",
        "    from .data import glue_output_modes as glue_output_modes",
        "    from .data import glue_processors as glue_processors",
        "    from .data import glue_tasks_num_labels as glue_tasks_num_labels",
        "    from .data import squad_convert_examples_to_features as squad_convert_examples_to_features",
        "    from .data import xnli_compute_metrics as xnli_compute_metrics",
        "    from .data import xnli_output_modes as xnli_output_modes",
        "    from .data import xnli_processors as xnli_processors",
        "    from .data import xnli_tasks_num_labels as xnli_tasks_num_labels",
        "    from .data.data_collator import DataCollator as DataCollator",
        "    from .data.data_collator import DataCollatorForLanguageModeling as DataCollatorForLanguageModeling",
        "    from .data.data_collator import DataCollatorForMultipleChoice as DataCollatorForMultipleChoice",
        "    from .data.data_collator import (",
        "    from .data.data_collator import DataCollatorForSeq2Seq as DataCollatorForSeq2Seq",
        "    from .data.data_collator import DataCollatorForSOP as DataCollatorForSOP",
        "    from .data.data_collator import DataCollatorForTokenClassification as DataCollatorForTokenClassification",
        "    from .data.data_collator import DataCollatorForWholeWordMask as DataCollatorForWholeWordMask",
        "    from .data.data_collator import DataCollatorWithFlattening as DataCollatorWithFlattening",
        "    from .data.data_collator import DataCollatorWithPadding as DataCollatorWithPadding",
        "    from .data.data_collator import DefaultDataCollator as DefaultDataCollator",
        "    from .data.data_collator import default_data_collator as default_data_collator",
        "    from .data.datasets import GlueDataset as GlueDataset",
        "    from .data.datasets import GlueDataTrainingArguments as GlueDataTrainingArguments",
        "    from .data.datasets import LineByLineTextDataset as LineByLineTextDataset",
        "    from .data.datasets import LineByLineWithRefDataset as LineByLineWithRefDataset",
        "    from .data.datasets import LineByLineWithSOPTextDataset as LineByLineWithSOPTextDataset",
        "    from .data.datasets import SquadDataset as SquadDataset",
        "    from .data.datasets import SquadDataTrainingArguments as SquadDataTrainingArguments",
        "    from .data.datasets import TextDataset as TextDataset",
        "    from .data.datasets import TextDatasetForNextSentencePrediction as TextDatasetForNextSentencePrediction",
        "    from .feature_extraction_sequence_utils import SequenceFeatureExtractor as SequenceFeatureExtractor",
        "    from .feature_extraction_utils import BatchFeature as BatchFeature",
        "    from .feature_extraction_utils import FeatureExtractionMixin as FeatureExtractionMixin",
        "    from .generation import AlternatingCodebooksLogitsProcessor as AlternatingCodebooksLogitsProcessor",
        "    from .generation import AsyncTextIteratorStreamer as AsyncTextIteratorStreamer",
        "    from .generation import BayesianDetectorConfig as BayesianDetectorConfig",
        "    from .generation import BayesianDetectorModel as BayesianDetectorModel",
        "    from .generation import BeamScorer as BeamScorer",
        "    from .generation import BeamSearchScorer as BeamSearchScorer",
        "    from .generation import ClassifierFreeGuidanceLogitsProcessor as ClassifierFreeGuidanceLogitsProcessor",
        "    from .generation import CompileConfig as CompileConfig",
        "    from .generation import ConstrainedBeamSearchScorer as ConstrainedBeamSearchScorer",
        "    from .generation import Constraint as Constraint",
        "    from .generation import ConstraintListState as ConstraintListState",
        "    from .generation import DisjunctiveConstraint as DisjunctiveConstraint",
        "    from .generation import EncoderNoRepeatNGramLogitsProcessor as EncoderNoRepeatNGramLogitsProcessor",
        "    from .generation import EncoderRepetitionPenaltyLogitsProcessor as EncoderRepetitionPenaltyLogitsProcessor",
        "    from .generation import EosTokenCriteria as EosTokenCriteria",
        "    from .generation import EpsilonLogitsWarper as EpsilonLogitsWarper",
        "    from .generation import EtaLogitsWarper as EtaLogitsWarper",
        "    from .generation import ExponentialDecayLengthPenalty as ExponentialDecayLengthPenalty",
        "    from .generation import FlaxForcedBOSTokenLogitsProcessor as FlaxForcedBOSTokenLogitsProcessor",
        "    from .generation import FlaxForcedEOSTokenLogitsProcessor as FlaxForcedEOSTokenLogitsProcessor",
        "    from .generation import FlaxForceTokensLogitsProcessor as FlaxForceTokensLogitsProcessor",
        "    from .generation import FlaxGenerationMixin as FlaxGenerationMixin",
        "    from .generation import FlaxLogitsProcessor as FlaxLogitsProcessor",
        "    from .generation import FlaxLogitsProcessorList as FlaxLogitsProcessorList",
        "    from .generation import FlaxLogitsWarper as FlaxLogitsWarper",
        "    from .generation import FlaxMinLengthLogitsProcessor as FlaxMinLengthLogitsProcessor",
        "    from .generation import FlaxSuppressTokensAtBeginLogitsProcessor as FlaxSuppressTokensAtBeginLogitsProcessor",
        "    from .generation import FlaxSuppressTokensLogitsProcessor as FlaxSuppressTokensLogitsProcessor",
        "    from .generation import FlaxTemperatureLogitsWarper as FlaxTemperatureLogitsWarper",
        "    from .generation import FlaxTopKLogitsWarper as FlaxTopKLogitsWarper",
        "    from .generation import FlaxTopPLogitsWarper as FlaxTopPLogitsWarper",
        "    from .generation import FlaxWhisperTimeStampLogitsProcessor as FlaxWhisperTimeStampLogitsProcessor",
        "    from .generation import ForcedBOSTokenLogitsProcessor as ForcedBOSTokenLogitsProcessor",
        "    from .generation import ForcedEOSTokenLogitsProcessor as ForcedEOSTokenLogitsProcessor",
        "    from .generation import GenerationConfig as GenerationConfig",
        "    from .generation import GenerationMixin as GenerationMixin",
        "    from .generation import HammingDiversityLogitsProcessor as HammingDiversityLogitsProcessor",
        "    from .generation import InfNanRemoveLogitsProcessor as InfNanRemoveLogitsProcessor",
        "    from .generation import LogitNormalization as LogitNormalization",
        "    from .generation import LogitsProcessor as LogitsProcessor",
        "    from .generation import LogitsProcessorList as LogitsProcessorList",
        "    from .generation import MaxLengthCriteria as MaxLengthCriteria",
        "    from .generation import MaxTimeCriteria as MaxTimeCriteria",
        "    from .generation import MinLengthLogitsProcessor as MinLengthLogitsProcessor",
        "    from .generation import MinNewTokensLengthLogitsProcessor as MinNewTokensLengthLogitsProcessor",
        "    from .generation import MinPLogitsWarper as MinPLogitsWarper",
        "    from .generation import NoBadWordsLogitsProcessor as NoBadWordsLogitsProcessor",
        "    from .generation import NoRepeatNGramLogitsProcessor as NoRepeatNGramLogitsProcessor",
        "    from .generation import PhrasalConstraint as PhrasalConstraint",
        "    from .generation import PrefixConstrainedLogitsProcessor as PrefixConstrainedLogitsProcessor",
        "    from .generation import RepetitionPenaltyLogitsProcessor as RepetitionPenaltyLogitsProcessor",
        "    from .generation import SequenceBiasLogitsProcessor as SequenceBiasLogitsProcessor",
        "    from .generation import StoppingCriteria as StoppingCriteria",
        "    from .generation import StoppingCriteriaList as StoppingCriteriaList",
        "    from .generation import StopStringCriteria as StopStringCriteria",
        "    from .generation import SuppressTokensAtBeginLogitsProcessor as SuppressTokensAtBeginLogitsProcessor",
        "    from .generation import SuppressTokensLogitsProcessor as SuppressTokensLogitsProcessor",
        "    from .generation import SynthIDTextWatermarkDetector as SynthIDTextWatermarkDetector",
        "    from .generation import SynthIDTextWatermarkingConfig as SynthIDTextWatermarkingConfig",
        "    from .generation import SynthIDTextWatermarkLogitsProcessor as SynthIDTextWatermarkLogitsProcessor",
        "    from .generation import TemperatureLogitsWarper as TemperatureLogitsWarper",
        "    from .generation import TextIteratorStreamer as TextIteratorStreamer",
        "    from .generation import TextStreamer as TextStreamer",
        "    from .generation import TFForcedBOSTokenLogitsProcessor as TFForcedBOSTokenLogitsProcessor",
        "    from .generation import TFForcedEOSTokenLogitsProcessor as TFForcedEOSTokenLogitsProcessor",
        "    from .generation import TFForceTokensLogitsProcessor as TFForceTokensLogitsProcessor",
        "    from .generation import TFGenerationMixin as TFGenerationMixin",
        "    from .generation import TFLogitsProcessor as TFLogitsProcessor",
        "    from .generation import TFLogitsProcessorList as TFLogitsProcessorList",
        "    from .generation import TFLogitsWarper as TFLogitsWarper",
        "    from .generation import TFMinLengthLogitsProcessor as TFMinLengthLogitsProcessor",
        "    from .generation import TFNoBadWordsLogitsProcessor as TFNoBadWordsLogitsProcessor",
        "    from .generation import TFNoRepeatNGramLogitsProcessor as TFNoRepeatNGramLogitsProcessor",
        "    from .generation import TFRepetitionPenaltyLogitsProcessor as TFRepetitionPenaltyLogitsProcessor",
        "    from .generation import TFSuppressTokensAtBeginLogitsProcessor as TFSuppressTokensAtBeginLogitsProcessor",
        "    from .generation import TFSuppressTokensLogitsProcessor as TFSuppressTokensLogitsProcessor",
        "    from .generation import TFTemperatureLogitsWarper as TFTemperatureLogitsWarper",
        "    from .generation import TFTopKLogitsWarper as TFTopKLogitsWarper",
        "    from .generation import TFTopPLogitsWarper as TFTopPLogitsWarper",
        "    from .generation import TopKLogitsWarper as TopKLogitsWarper",
        "    from .generation import TopPLogitsWarper as TopPLogitsWarper",
        "    from .generation import TypicalLogitsWarper as TypicalLogitsWarper",
        "    from .generation import (",
        "    from .generation import WatermarkDetector as WatermarkDetector",
        "    from .generation import WatermarkingConfig as WatermarkingConfig",
        "    from .generation import WatermarkLogitsProcessor as WatermarkLogitsProcessor",
        "    from .generation import WhisperTimeStampLogitsProcessor as WhisperTimeStampLogitsProcessor",
        "    from .hf_argparser import HfArgumentParser as HfArgumentParser",
        "    from .image_processing_base import ImageProcessingMixin as ImageProcessingMixin",
        "    from .image_processing_utils import BaseImageProcessor as BaseImageProcessor",
        "    from .image_processing_utils_fast import BaseImageProcessorFast as BaseImageProcessorFast",
        "    from .image_utils import ImageFeatureExtractionMixin as ImageFeatureExtractionMixin",
        "    from .integrations import is_clearml_available as is_clearml_available",
        "    from .integrations import is_comet_available as is_comet_available",
        "    from .integrations import is_dvclive_available as is_dvclive_available",
        "    from .integrations import is_neptune_available as is_neptune_available",
        "    from .integrations import is_optuna_available as is_optuna_available",
        "    from .integrations import is_ray_available as is_ray_available",
        "    from .integrations import is_ray_tune_available as is_ray_tune_available",
        "    from .integrations import is_sigopt_available as is_sigopt_available",
        "    from .integrations import is_swanlab_available as is_swanlab_available",
        "    from .integrations import is_tensorboard_available as is_tensorboard_available",
        "    from .integrations import is_trackio_available as is_trackio_available",
        "    from .integrations import is_wandb_available as is_wandb_available",
        "    from .integrations.executorch import TorchExportableModuleWithStaticCache as TorchExportableModuleWithStaticCache",
        "    from .integrations.executorch import convert_and_export_with_cache as convert_and_export_with_cache",
        "    from .keras_callbacks import KerasMetricCallback as KerasMetricCallback",
        "    from .keras_callbacks import PushToHubCallback as PushToHubCallback",
        "    from .masking_utils import AttentionMaskInterface as AttentionMaskInterface",
        "    from .model_debugging_utils import model_addition_debugger_context as model_addition_debugger_context",
        "    from .modelcard import ModelCard as ModelCard",
        "    from .modeling_flax_utils import FlaxPreTrainedModel as FlaxPreTrainedModel",
        "    from .modeling_layers import GradientCheckpointingLayer as GradientCheckpointingLayer",
        "    from .modeling_rope_utils import ROPE_INIT_FUNCTIONS as ROPE_INIT_FUNCTIONS",
        "    from .modeling_rope_utils import dynamic_rope_update as dynamic_rope_update",
        "    from .modeling_tf_pytorch_utils import (",
        "    from .modeling_tf_pytorch_utils import load_pytorch_checkpoint_in_tf2_model as load_pytorch_checkpoint_in_tf2_model",
        "    from .modeling_tf_pytorch_utils import load_pytorch_model_in_tf2_model as load_pytorch_model_in_tf2_model",
        "    from .modeling_tf_pytorch_utils import load_pytorch_weights_in_tf2_model as load_pytorch_weights_in_tf2_model",
        "    from .modeling_tf_pytorch_utils import load_tf2_checkpoint_in_pytorch_model as load_tf2_checkpoint_in_pytorch_model",
        "    from .modeling_tf_pytorch_utils import load_tf2_model_in_pytorch_model as load_tf2_model_in_pytorch_model",
        "    from .modeling_tf_pytorch_utils import load_tf2_weights_in_pytorch_model as load_tf2_weights_in_pytorch_model",
        "    from .modeling_tf_utils import TFPreTrainedModel as TFPreTrainedModel",
        "    from .modeling_tf_utils import TFSequenceSummary as TFSequenceSummary",
        "    from .modeling_tf_utils import TFSharedEmbeddings as TFSharedEmbeddings",
        "    from .modeling_tf_utils import shape_list as shape_list",
        "    from .modeling_utils import AttentionInterface as AttentionInterface",
        "    from .modeling_utils import PreTrainedModel as PreTrainedModel",
        "    from .models import *",
        "    from .models.timm_wrapper import TimmWrapperImageProcessor as TimmWrapperImageProcessor",
        "    from .optimization import Adafactor as Adafactor",
        "    from .optimization import get_constant_schedule as get_constant_schedule",
        "    from .optimization import get_constant_schedule_with_warmup as get_constant_schedule_with_warmup",
        "    from .optimization import get_cosine_schedule_with_warmup as get_cosine_schedule_with_warmup",
        "    from .optimization import (",
        "    from .optimization import get_inverse_sqrt_schedule as get_inverse_sqrt_schedule",
        "    from .optimization import get_linear_schedule_with_warmup as get_linear_schedule_with_warmup",
        "    from .optimization import get_polynomial_decay_schedule_with_warmup as get_polynomial_decay_schedule_with_warmup",
        "    from .optimization import get_scheduler as get_scheduler",
        "    from .optimization import get_wsd_schedule as get_wsd_schedule",
        "    from .optimization_tf import AdamWeightDecay as AdamWeightDecay",
        "    from .optimization_tf import GradientAccumulator as GradientAccumulator",
        "    from .optimization_tf import WarmUp as WarmUp",
        "    from .optimization_tf import create_optimizer as create_optimizer",
        "    from .pipelines import AudioClassificationPipeline as AudioClassificationPipeline",
        "    from .pipelines import AutomaticSpeechRecognitionPipeline as AutomaticSpeechRecognitionPipeline",
        "    from .pipelines import CsvPipelineDataFormat as CsvPipelineDataFormat",
        "    from .pipelines import DepthEstimationPipeline as DepthEstimationPipeline",
        "    from .pipelines import DocumentQuestionAnsweringPipeline as DocumentQuestionAnsweringPipeline",
        "    from .pipelines import FeatureExtractionPipeline as FeatureExtractionPipeline",
        "    from .pipelines import FillMaskPipeline as FillMaskPipeline",
        "    from .pipelines import ImageClassificationPipeline as ImageClassificationPipeline",
        "    from .pipelines import ImageFeatureExtractionPipeline as ImageFeatureExtractionPipeline",
        "    from .pipelines import ImageSegmentationPipeline as ImageSegmentationPipeline",
        "    from .pipelines import ImageTextToTextPipeline as ImageTextToTextPipeline",
        "    from .pipelines import ImageToImagePipeline as ImageToImagePipeline",
        "    from .pipelines import ImageToTextPipeline as ImageToTextPipeline",
        "    from .pipelines import JsonPipelineDataFormat as JsonPipelineDataFormat",
        "    from .pipelines import MaskGenerationPipeline as MaskGenerationPipeline",
        "    from .pipelines import NerPipeline as NerPipeline",
        "    from .pipelines import ObjectDetectionPipeline as ObjectDetectionPipeline",
        "    from .pipelines import PipedPipelineDataFormat as PipedPipelineDataFormat",
        "    from .pipelines import Pipeline as Pipeline",
        "    from .pipelines import PipelineDataFormat as PipelineDataFormat",
        "    from .pipelines import QuestionAnsweringPipeline as QuestionAnsweringPipeline",
        "    from .pipelines import SummarizationPipeline as SummarizationPipeline",
        "    from .pipelines import TableQuestionAnsweringPipeline as TableQuestionAnsweringPipeline",
        "    from .pipelines import Text2TextGenerationPipeline as Text2TextGenerationPipeline",
        "    from .pipelines import TextClassificationPipeline as TextClassificationPipeline",
        "    from .pipelines import TextGenerationPipeline as TextGenerationPipeline",
        "    from .pipelines import TextToAudioPipeline as TextToAudioPipeline",
        "    from .pipelines import TokenClassificationPipeline as TokenClassificationPipeline",
        "    from .pipelines import TranslationPipeline as TranslationPipeline",
        "    from .pipelines import VideoClassificationPipeline as VideoClassificationPipeline",
        "    from .pipelines import VisualQuestionAnsweringPipeline as VisualQuestionAnsweringPipeline",
        "    from .pipelines import ZeroShotAudioClassificationPipeline as ZeroShotAudioClassificationPipeline",
        "    from .pipelines import ZeroShotClassificationPipeline as ZeroShotClassificationPipeline",
        "    from .pipelines import ZeroShotImageClassificationPipeline as ZeroShotImageClassificationPipeline",
        "    from .pipelines import ZeroShotObjectDetectionPipeline as ZeroShotObjectDetectionPipeline",
        "    from .pipelines import pipeline as pipeline",
        "    from .processing_utils import ProcessorMixin as ProcessorMixin",
        "    from .pytorch_utils import Conv1D as Conv1D",
        "    from .pytorch_utils import apply_chunking_to_forward as apply_chunking_to_forward",
        "    from .pytorch_utils import prune_layer as prune_layer",
        "    from .tokenization_utils import PreTrainedTokenizer as PreTrainedTokenizer",
        "    from .tokenization_utils_base import AddedToken as AddedToken",
        "    from .tokenization_utils_base import BatchEncoding as BatchEncoding",
        "    from .tokenization_utils_base import CharSpan as CharSpan",
        "    from .tokenization_utils_base import PreTrainedTokenizerBase as PreTrainedTokenizerBase",
        "    from .tokenization_utils_base import SpecialTokensMixin as SpecialTokensMixin",
        "    from .tokenization_utils_base import TokenSpan as TokenSpan",
        "    from .tokenization_utils_fast import PreTrainedTokenizerFast as PreTrainedTokenizerFast",
        "    from .trainer import Trainer as Trainer",
        "    from .trainer_callback import DefaultFlowCallback as DefaultFlowCallback",
        "    from .trainer_callback import EarlyStoppingCallback as EarlyStoppingCallback",
        "    from .trainer_callback import PrinterCallback as PrinterCallback",
        "    from .trainer_callback import ProgressCallback as ProgressCallback",
        "    from .trainer_callback import TrainerCallback as TrainerCallback",
        "    from .trainer_callback import TrainerControl as TrainerControl",
        "    from .trainer_callback import TrainerState as TrainerState",
        "    from .trainer_pt_utils import torch_distributed_zero_first as torch_distributed_zero_first",
        "    from .trainer_seq2seq import Seq2SeqTrainer as Seq2SeqTrainer",
        "    from .trainer_utils import EvalPrediction as EvalPrediction",
        "    from .trainer_utils import IntervalStrategy as IntervalStrategy",
        "    from .trainer_utils import SchedulerType as SchedulerType",
        "    from .trainer_utils import enable_full_determinism as enable_full_determinism",
        "    from .trainer_utils import set_seed as set_seed",
        "    from .training_args import TrainingArguments as TrainingArguments",
        "    from .training_args_seq2seq import Seq2SeqTrainingArguments as Seq2SeqTrainingArguments",
        "    from .training_args_tf import TFTrainingArguments as TFTrainingArguments",
        "    from .utils import CONFIG_NAME as CONFIG_NAME",
        "    from .utils import MODEL_CARD_NAME as MODEL_CARD_NAME",
        "    from .utils import PYTORCH_PRETRAINED_BERT_CACHE as PYTORCH_PRETRAINED_BERT_CACHE",
        "    from .utils import PYTORCH_TRANSFORMERS_CACHE as PYTORCH_TRANSFORMERS_CACHE",
        "    from .utils import SPIECE_UNDERLINE as SPIECE_UNDERLINE",
        "    from .utils import TF2_WEIGHTS_NAME as TF2_WEIGHTS_NAME",
        "    from .utils import TF_WEIGHTS_NAME as TF_WEIGHTS_NAME",
        "    from .utils import TRANSFORMERS_CACHE as TRANSFORMERS_CACHE",
        "    from .utils import WEIGHTS_NAME as WEIGHTS_NAME",
        "    from .utils import TensorType as TensorType",
        "    from .utils import add_end_docstrings as add_end_docstrings",
        "    from .utils import add_start_docstrings as add_start_docstrings",
        "    from .utils import is_apex_available as is_apex_available",
        "    from .utils import is_av_available as is_av_available",
        "    from .utils import is_datasets_available as is_datasets_available",
        "    from .utils import is_faiss_available as is_faiss_available",
        "    from .utils import is_matplotlib_available as is_matplotlib_available",
        "    from .utils import is_phonemizer_available as is_phonemizer_available",
        "    from .utils import is_psutil_available as is_psutil_available",
        "    from .utils import is_py3nvml_available as is_py3nvml_available",
        "    from .utils import is_pyctcdecode_available as is_pyctcdecode_available",
        "    from .utils import is_sacremoses_available as is_sacremoses_available",
        "    from .utils import is_safetensors_available as is_safetensors_available",
        "    from .utils import is_sklearn_available as is_sklearn_available",
        "    from .utils import is_torch_hpu_available as is_torch_hpu_available",
        "    from .utils import is_torch_mlu_available as is_torch_mlu_available",
        "    from .utils import is_torch_musa_available as is_torch_musa_available",
        "    from .utils import is_torch_neuroncore_available as is_torch_neuroncore_available",
        "    from .utils import is_torch_npu_available as is_torch_npu_available",
        "    from .utils import is_torch_xla_available as is_torch_xla_available",
        "    from .utils import is_torch_xpu_available as is_torch_xpu_available",
        "    from .utils import logging as logging",
        "    from .utils.quantization_config import AqlmConfig as AqlmConfig",
        "    from .utils.quantization_config import AutoRoundConfig as AutoRoundConfig",
        "    from .utils.quantization_config import AwqConfig as AwqConfig",
        "    from .utils.quantization_config import BitNetQuantConfig as BitNetQuantConfig",
        "    from .utils.quantization_config import BitsAndBytesConfig as BitsAndBytesConfig",
        "    from .utils.quantization_config import CompressedTensorsConfig as CompressedTensorsConfig",
        "    from .utils.quantization_config import EetqConfig as EetqConfig",
        "    from .utils.quantization_config import FbgemmFp8Config as FbgemmFp8Config",
        "    from .utils.quantization_config import FineGrainedFP8Config as FineGrainedFP8Config",
        "    from .utils.quantization_config import FPQuantConfig as FPQuantConfig",
        "    from .utils.quantization_config import GPTQConfig as GPTQConfig",
        "    from .utils.quantization_config import HiggsConfig as HiggsConfig",
        "    from .utils.quantization_config import HqqConfig as HqqConfig",
        "    from .utils.quantization_config import QuantoConfig as QuantoConfig",
        "    from .utils.quantization_config import QuarkConfig as QuarkConfig",
        "    from .utils.quantization_config import SpQRConfig as SpQRConfig",
        "    from .utils.quantization_config import TorchAoConfig as TorchAoConfig",
        "    from .utils.quantization_config import VptqConfig as VptqConfig",
        "    from .video_processing_utils import BaseVideoProcessor as BaseVideoProcessor",
        "        extra_objects={\"__version__\": __version__},"
      ],
      "estimated_loc_savings": 564,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/click_option_group/__init__.py",
      "current_size_lines": 29,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from ._core import (",
        "from ._decorators import optgroup",
        "from ._version import __version__",
        "__all__ = [",
        "    \"__version__\","
      ],
      "estimated_loc_savings": 19,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/jsonschema/__init__.py",
      "current_size_lines": 110,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "    if name == \"__version__\":",
        "            \"Accessing jsonschema.__version__ is deprecated and will be \"",
        "__all__ = ["
      ],
      "estimated_loc_savings": 102,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/multipart/__init__.py",
      "current_size_lines": 22,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "    from python_multipart import __all__, __author__, __copyright__, __license__, __version__"
      ],
      "estimated_loc_savings": 16,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/tqdm/__init__.py",
      "current_size_lines": 31,
      "has_imports": true,
      "has_version": true,
      "has_all": true,
      "preserved_content": [
        "from ._monitor import TMonitor, TqdmSynchronisationWarning",
        "from ._tqdm_pandas import tqdm_pandas",
        "from .cli import main  # TODO: remove in v5.0.0",
        "from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0",
        "from .gui import trange as tgrange  # TODO: remove in v5.0.0",
        "from .std import (",
        "from .version import __version__",
        "__all__ = ['tqdm', 'tqdm_gui', 'trange', 'tgrange', 'tqdm_pandas',",
        "           '__version__']",
        "    from .notebook import tqdm as _tqdm_notebook",
        "    from .notebook import trange as _tnrange"
      ],
      "estimated_loc_savings": 15,
      "requires_standardization": true
    },
    {
      "file_path": "/Users/bogdan/work/leanvibe-dev/bee-hive/venv/lib/python3.12/site-packages/mypy/__init__.py",
      "current_size_lines": 1,
      "has_imports": false,
      "has_version": false,
      "has_all": false,
      "preserved_content": [],
      "estimated_loc_savings": 0,
      "requires_standardization": true
    }
  ],
  "estimated_loc_savings": 4096,
  "file_count": 50
}