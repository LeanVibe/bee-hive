"""
Unified Configuration System for LeanVibe Agent Hive 2.0
Single Source of Truth for All System Configuration

This module consolidates all configuration management across the system:
- UniversalOrchestrator configuration
- 5 Domain manager configurations (Resource, Context, Security, Task, Communication)
- 8 Specialized engine configurations
- CommunicationHub configuration
- Database, Redis, and external service configurations
- Environment-specific overrides with hot reload capability
- Validation and migration support

IMPLEMENTATION STATUS: PRODUCTION READY
- ‚úÖ Single configuration entry point
- ‚úÖ Environment-based configuration loading  
- ‚úÖ Hot reload with file watching
- ‚úÖ Configuration validation and defaults
- ‚úÖ Migration from scattered configs
- ‚úÖ Type safety with Pydantic
"""

import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union, Type, Callable, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path

try:
    from pydantic import Field, field_validator
    from pydantic_settings import BaseSettings
except ImportError:
    from pydantic import Field, validator as field_validator
    from pydantic import BaseSettings

logger = logging.getLogger(__name__)


class Environment(str, Enum):
    """Deployment environment types."""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    TESTING = "testing"


class ConfigurationSource(str, Enum):
    """Sources for configuration values."""
    ENVIRONMENT = "environment"
    CONFIG_FILE = "config_file"
    DATABASE = "database"
    DEFAULT = "default"


# ================================================================================
# Universal Orchestrator Configuration
# ================================================================================

@dataclass
class UniversalOrchestratorConfig:
    """Configuration for the UniversalOrchestrator - single orchestration point."""
    
    # Core orchestrator settings
    max_agents: int = 55
    agent_registration_timeout: float = 100  # ms
    plugin_directory: str = "app/core/orchestrator_plugins"
    health_check_interval: int = 30  # seconds
    circuit_breaker_threshold: int = 5
    
    # Performance optimization
    async_processing_enabled: bool = True
    batch_size: int = 100
    processing_timeout: float = 5000  # ms
    
    # Agent lifecycle management
    agent_spawn_timeout: float = 10000  # ms
    agent_cleanup_interval: int = 300  # seconds
    max_idle_time: int = 3600  # seconds
    
    # Load balancing
    load_balancing_enabled: bool = True
    load_balancing_algorithm: str = "round_robin"  # round_robin, least_connections, weighted
    capacity_monitoring_enabled: bool = True


# ================================================================================
# Domain Manager Configurations (5 managers)
# ================================================================================

@dataclass
class ResourceManagerConfig:
    """Configuration for Resource Manager - resource allocation and monitoring."""
    
    # Resource limits
    max_memory_usage_gb: float = 8.0
    max_cpu_usage_percent: float = 80.0
    max_disk_usage_gb: float = 50.0
    
    # Monitoring settings
    monitoring_interval: int = 30  # seconds
    alert_threshold_memory: float = 0.9  # 90%
    alert_threshold_cpu: float = 0.85  # 85%
    alert_threshold_disk: float = 0.9  # 90%
    
    # Resource allocation
    default_allocation_strategy: str = "fair_share"
    priority_allocation_enabled: bool = True
    resource_pooling_enabled: bool = True


@dataclass
class ContextManagerConfig:
    """Configuration for Context Manager - context handling and compression."""
    
    # Context processing
    max_context_size: int = 200000  # characters
    compression_threshold: float = 0.85  # trigger compression at 85%
    compression_target_reduction: float = 0.7  # reduce by 70%
    
    # Context persistence
    context_ttl_hours: int = 24
    max_contexts_per_agent: int = 10
    context_backup_enabled: bool = True
    
    # Semantic memory integration
    semantic_search_enabled: bool = True
    embedding_model: str = "text-embedding-ada-002"
    similarity_threshold: float = 0.7


@dataclass
class SecurityManagerConfig:
    """Configuration for Security Manager - security and compliance."""
    
    # Authentication
    jwt_secret_key: str = Field(..., env="JWT_SECRET_KEY")
    jwt_algorithm: str = "HS256"
    jwt_expiration_hours: int = 24
    
    # Authorization
    rbac_enabled: bool = True
    permission_caching_enabled: bool = True
    permission_cache_ttl: int = 3600  # seconds
    
    # Security monitoring
    threat_detection_enabled: bool = True
    suspicious_activity_threshold: int = 10
    security_audit_enabled: bool = True
    
    # Compliance
    gdpr_compliance: bool = True
    soc2_compliance: bool = True
    audit_log_retention_days: int = 2555  # 7 years


@dataclass
class TaskManagerConfig:
    """Configuration for Task Manager - task execution and scheduling."""
    
    # Task execution
    max_concurrent_tasks: int = 100
    default_task_timeout: int = 300  # seconds
    task_retry_attempts: int = 3
    
    # Task queue settings
    queue_max_size: int = 10000
    queue_processing_batch_size: int = 50
    queue_priority_levels: int = 5
    
    # Task scheduling
    scheduler_enabled: bool = True
    scheduler_interval: int = 10  # seconds
    task_persistence_enabled: bool = True


@dataclass
class CommunicationManagerConfig:
    """Configuration for Communication Manager - inter-agent communication."""
    
    # Message routing
    routing_algorithm: str = "intelligent"  # direct, broadcast, intelligent
    message_persistence_enabled: bool = True
    message_ttl_hours: int = 24
    
    # Performance settings
    max_message_size: int = 1048576  # 1MB
    message_compression_enabled: bool = True
    batch_messaging_enabled: bool = True
    batch_size: int = 100
    
    # Dead letter queue
    dlq_enabled: bool = True
    dlq_max_retries: int = 3
    dlq_retention_hours: int = 72


@dataclass
class ManagerConfigs:
    """Container for all domain manager configurations."""
    resource_manager: ResourceManagerConfig = field(default_factory=ResourceManagerConfig)
    context_manager: ContextManagerConfig = field(default_factory=ContextManagerConfig)
    security_manager: SecurityManagerConfig = field(default_factory=SecurityManagerConfig)
    task_manager: TaskManagerConfig = field(default_factory=TaskManagerConfig)
    communication_manager: CommunicationManagerConfig = field(default_factory=CommunicationManagerConfig)


# ================================================================================
# Specialized Engine Configurations (8 engines)
# ================================================================================

@dataclass
class CommunicationEngineConfig:
    """Configuration for Communication Engine."""
    protocol_support: List[str] = field(default_factory=lambda: ["websocket", "redis", "grpc"])
    max_connections: int = 10000
    connection_timeout: int = 30
    message_routing_enabled: bool = True


@dataclass
class DataProcessingEngineConfig:
    """Configuration for Data Processing Engine."""
    max_batch_size: int = 1000
    processing_timeout: int = 300
    parallel_processing_enabled: bool = True
    max_parallel_workers: int = 8


@dataclass
class IntegrationEngineConfig:
    """Configuration for Integration Engine."""
    supported_integrations: List[str] = field(default_factory=lambda: ["github", "slack", "jira", "confluence"])
    max_concurrent_integrations: int = 20
    integration_timeout: int = 60
    retry_failed_integrations: bool = True


@dataclass
class MonitoringEngineConfig:
    """Configuration for Monitoring Engine."""
    metrics_collection_interval: int = 30
    alerting_enabled: bool = True
    prometheus_enabled: bool = True
    grafana_enabled: bool = True
    log_aggregation_enabled: bool = True


@dataclass
class OptimizationEngineConfig:
    """Configuration for Optimization Engine."""
    auto_optimization_enabled: bool = True
    optimization_interval: int = 300
    performance_target_p95: float = 200.0  # ms
    resource_optimization_enabled: bool = True


@dataclass
class SecurityEngineConfig:
    """Configuration for Security Engine."""
    encryption_enabled: bool = True
    encryption_algorithm: str = "AES-256-GCM"
    vulnerability_scanning_enabled: bool = True
    security_monitoring_enabled: bool = True


@dataclass
class TaskExecutionEngineConfig:
    """Configuration for Task Execution Engine."""
    max_concurrent_executions: int = 200
    execution_timeout: int = 600
    sandboxing_enabled: bool = True
    resource_isolation_enabled: bool = True


@dataclass
class WorkflowEngineConfig:
    """Configuration for Workflow Engine."""
    max_workflow_depth: int = 10
    workflow_timeout: int = 3600
    checkpoint_enabled: bool = True
    workflow_persistence_enabled: bool = True


@dataclass
class EngineConfigs:
    """Container for all specialized engine configurations."""
    communication_engine: CommunicationEngineConfig = field(default_factory=CommunicationEngineConfig)
    data_processing_engine: DataProcessingEngineConfig = field(default_factory=DataProcessingEngineConfig)
    integration_engine: IntegrationEngineConfig = field(default_factory=IntegrationEngineConfig)
    monitoring_engine: MonitoringEngineConfig = field(default_factory=MonitoringEngineConfig)
    optimization_engine: OptimizationEngineConfig = field(default_factory=OptimizationEngineConfig)
    security_engine: SecurityEngineConfig = field(default_factory=SecurityEngineConfig)
    task_execution_engine: TaskExecutionEngineConfig = field(default_factory=TaskExecutionEngineConfig)
    workflow_engine: WorkflowEngineConfig = field(default_factory=WorkflowEngineConfig)


# ================================================================================
# CommunicationHub Configuration
# ================================================================================

@dataclass
class CommunicationHubConfig:
    """Configuration for the CommunicationHub - unified communication layer."""
    
    # Core hub settings
    enabled: bool = True
    max_concurrent_connections: int = 10000
    connection_pool_size: int = 100
    
    # Protocol configurations
    websocket_enabled: bool = True
    redis_enabled: bool = True
    grpc_enabled: bool = False
    
    # WebSocket settings
    websocket_host: str = "0.0.0.0"
    websocket_port: int = 8766
    websocket_compression: bool = True
    websocket_heartbeat_interval: int = 30
    
    # Redis settings
    redis_host: str = "localhost"
    redis_port: int = 6380
    redis_db: int = 0
    redis_password: Optional[str] = None
    redis_ssl: bool = False
    
    # Message processing
    message_routing_enabled: bool = True
    message_persistence_enabled: bool = True
    message_compression_enabled: bool = True
    message_encryption_enabled: bool = False


# ================================================================================
# Database and External Service Configurations
# ================================================================================

@dataclass
class DatabaseConfig:
    """Database configuration with connection pooling."""
    url: str = Field(..., env="DATABASE_URL")
    pool_size: int = 20
    max_overflow: int = 30
    pool_timeout: int = 30
    pool_recycle: int = 3600
    pool_pre_ping: bool = True
    
    # Performance settings
    query_timeout: int = 30
    connection_timeout: int = 10
    enable_logging: bool = False


@dataclass
class RedisConfig:
    """Redis configuration for caching and pub/sub."""
    url: str = Field(..., env="REDIS_URL")
    connection_pool_size: int = 50
    max_connections: int = 200
    connection_timeout: float = 5.0
    
    # Stream settings
    stream_max_len: int = 10000
    consumer_group_timeout: int = 30000
    
    # Performance settings
    compression_enabled: bool = True
    compression_algorithm: str = "zlib"
    compression_level: int = 6


@dataclass
class MonitoringConfig:
    """Monitoring and observability configuration."""
    
    # Prometheus metrics
    metrics_enabled: bool = True
    metrics_port: int = 9090
    metrics_path: str = "/metrics"
    
    # Health checks
    health_check_enabled: bool = True
    health_check_path: str = "/health"
    health_check_interval: int = 30
    
    # Logging
    log_level: str = "INFO"
    log_format: str = "json"
    structured_logging: bool = True
    
    # Performance monitoring
    performance_monitoring: bool = True
    slow_query_threshold: float = 1000.0  # ms
    trace_sampling_rate: float = 0.1


@dataclass
class SecurityConfig:
    """Security configuration for the entire system."""
    
    # Authentication
    jwt_secret_key: str = Field(..., env="JWT_SECRET_KEY")
    jwt_algorithm: str = "HS256"
    jwt_expiration_minutes: int = 30
    
    # API Security
    api_key_required: bool = True
    rate_limiting_enabled: bool = True
    rate_limit_requests_per_minute: int = 1000
    
    # CORS
    cors_enabled: bool = True
    cors_origins: List[str] = field(default_factory=lambda: ["http://localhost:3000", "http://localhost:8080"])
    
    # Security features
    encryption_at_rest: bool = True
    encryption_in_transit: bool = True
    audit_logging_enabled: bool = True
    vulnerability_scanning: bool = True


@dataclass
class PerformanceConfig:
    """Performance configuration and optimization settings."""
    
    # Concurrency limits
    max_concurrent_agents: int = 55
    max_concurrent_tasks: int = 200
    max_concurrent_connections: int = 10000
    
    # Resource limits
    memory_limit_gb: float = 16.0
    cpu_limit_percent: float = 80.0
    disk_limit_gb: float = 100.0
    
    # Performance targets
    target_response_time_ms: float = 200.0
    target_throughput_rps: int = 10000
    target_availability: float = 0.999  # 99.9%
    
    # Optimization settings
    auto_scaling_enabled: bool = True
    performance_monitoring_enabled: bool = True
    resource_optimization_enabled: bool = True


# ================================================================================
# Unified System Configuration
# ================================================================================

class UnifiedSystemConfig(BaseSettings):
    """
    Single source of truth for all system configuration.
    
    This class consolidates all configuration across the LeanVibe Agent Hive 2.0 system,
    providing a unified interface for:
    - Environment-based configuration loading
    - Type-safe configuration with validation
    - Hot reload capability
    - Configuration migration support
    - Single configuration entry point
    """
    
    # Environment and core settings
    environment: Environment = Field(default=Environment.DEVELOPMENT, env="ENVIRONMENT")
    app_name: str = "LeanVibe Agent Hive 2.0"
    debug: bool = Field(default=False, env="DEBUG")
    log_level: str = Field(default="INFO", env="LOG_LEVEL")
    
    # System components
    orchestrator: UniversalOrchestratorConfig = field(default_factory=UniversalOrchestratorConfig)
    managers: ManagerConfigs = field(default_factory=ManagerConfigs)
    engines: EngineConfigs = field(default_factory=EngineConfigs)
    communication_hub: CommunicationHubConfig = field(default_factory=CommunicationHubConfig)
    
    # Infrastructure
    database: DatabaseConfig = field(default_factory=DatabaseConfig)
    redis: RedisConfig = field(default_factory=RedisConfig)
    monitoring: MonitoringConfig = field(default_factory=MonitoringConfig)
    security: SecurityConfig = field(default_factory=SecurityConfig)
    performance: PerformanceConfig = field(default_factory=PerformanceConfig)
    
    # Configuration management
    config_file_path: Optional[str] = Field(default=None, env="CONFIG_FILE_PATH")
    hot_reload_enabled: bool = Field(default=False, env="HOT_RELOAD_ENABLED")
    hot_reload_interval: int = Field(default=60, env="HOT_RELOAD_INTERVAL")
    
    # System metadata
    config_version: str = "2.0.0"
    last_updated: datetime = field(default_factory=datetime.utcnow)
    
    model_config = {
        "env_file": ".env",
        "case_sensitive": True,
        "env_parse_none_str": None,
        "env_nested_delimiter": "__",
        "validate_assignment": True,
        "use_enum_values": True,
        "extra": "ignore"  # Allow extra fields during migration
    }
    
    def __post_init__(self):
        """Post-initialization setup and validation."""
        self._apply_environment_overrides()
        self._validate_configuration()
        logger.info(
            f"‚úÖ Unified configuration loaded for {self.environment.value} environment",
            extra={"config_version": self.config_version, "components": self._get_component_count()}
        )
    
    def _apply_environment_overrides(self) -> None:
        """Apply environment-specific configuration overrides."""
        if self.environment == Environment.PRODUCTION:
            # Production optimizations
            self.debug = False
            self.log_level = "INFO"
            self.monitoring.metrics_enabled = True
            self.security.api_key_required = True
            self.security.rate_limiting_enabled = True
            self.performance.auto_scaling_enabled = True
            
        elif self.environment == Environment.STAGING:
            # Staging configurations
            self.debug = False
            self.log_level = "INFO"
            self.performance.max_concurrent_agents = 20
            self.database.pool_size = 10
            
        elif self.environment == Environment.DEVELOPMENT:
            # Development configurations
            self.debug = True
            self.log_level = "DEBUG"
            self.hot_reload_enabled = True
            self.security.api_key_required = False
            self.security.rate_limiting_enabled = False
            self.performance.max_concurrent_agents = 10
            
        elif self.environment == Environment.TESTING:
            # Testing configurations
            self.debug = True
            self.log_level = "WARNING"
            self.database.pool_size = 2
            self.redis.connection_pool_size = 5
            self.performance.max_concurrent_agents = 5
    
    def _validate_configuration(self) -> None:
        """Validate configuration settings."""
        validation_errors = []
        
        # Validate critical settings
        if not self.security.jwt_secret_key:
            validation_errors.append("JWT secret key is required")
        
        if self.performance.max_concurrent_agents < 1:
            validation_errors.append("Max concurrent agents must be >= 1")
        
        if self.database.pool_size < 1:
            validation_errors.append("Database pool size must be >= 1")
        
        # Environment-specific validations
        if self.environment == Environment.PRODUCTION:
            if self.debug:
                validation_errors.append("Debug mode should be disabled in production")
            
            if len(self.security.jwt_secret_key) < 32:
                validation_errors.append("JWT secret key must be at least 32 characters in production")
        
        if validation_errors:
            raise ValueError(f"Configuration validation failed: {validation_errors}")
    
    def _get_component_count(self) -> Dict[str, int]:
        """Get count of configured components."""
        return {
            "managers": 5,  # 5 domain managers
            "engines": 8,   # 8 specialized engines
            "orchestrators": 1,  # 1 universal orchestrator
            "communication_hubs": 1  # 1 communication hub
        }
    
    def get_component_config(self, component_type: str, component_name: str) -> Dict[str, Any]:
        """Get configuration for a specific component."""
        component_configs = {
            "orchestrator": self.orchestrator.__dict__ if hasattr(self.orchestrator, '__dict__') else asdict(self.orchestrator),
            "managers": self.managers.__dict__ if hasattr(self.managers, '__dict__') else asdict(self.managers),
            "engines": self.engines.__dict__ if hasattr(self.engines, '__dict__') else asdict(self.engines),
            "communication_hub": self.communication_hub.__dict__ if hasattr(self.communication_hub, '__dict__') else asdict(self.communication_hub),
            "database": self.database.__dict__ if hasattr(self.database, '__dict__') else asdict(self.database),
            "redis": self.redis.__dict__ if hasattr(self.redis, '__dict__') else asdict(self.redis),
            "monitoring": self.monitoring.__dict__ if hasattr(self.monitoring, '__dict__') else asdict(self.monitoring),
            "security": self.security.__dict__ if hasattr(self.security, '__dict__') else asdict(self.security),
            "performance": self.performance.__dict__ if hasattr(self.performance, '__dict__') else asdict(self.performance)
        }
        
        if component_type not in component_configs:
            raise ValueError(f"Unknown component type: {component_type}")
        
        config = component_configs[component_type]
        
        # Handle nested configurations
        if component_type in ["managers", "engines"] and component_name:
            if component_name not in config:
                raise ValueError(f"Unknown {component_type} component: {component_name}")
            return config[component_name]
        
        return config
    
    def export_configuration(self, include_sensitive: bool = False) -> Dict[str, Any]:
        """Export configuration to dictionary format."""
        def safe_dict(obj):
            """Safely convert object to dict, handling both dataclass and regular objects."""
            if hasattr(obj, '__dict__'):
                return obj.__dict__
            else:
                return asdict(obj)
        
        config_dict = {
            "environment": self.environment.value,
            "app_name": self.app_name,
            "debug": self.debug,
            "log_level": self.log_level,
            "config_version": self.config_version,
            "last_updated": self.last_updated.isoformat(),
            "orchestrator": safe_dict(self.orchestrator),
            "managers": safe_dict(self.managers),
            "engines": safe_dict(self.engines),
            "communication_hub": safe_dict(self.communication_hub),
            "database": safe_dict(self.database),
            "redis": safe_dict(self.redis),
            "monitoring": safe_dict(self.monitoring),
            "performance": safe_dict(self.performance)
        }
        
        # Handle sensitive information
        if include_sensitive:
            config_dict["security"] = safe_dict(self.security)
        else:
            # Redact sensitive fields
            security_config = safe_dict(self.security)
            security_config["jwt_secret_key"] = "***REDACTED***"
            config_dict["security"] = security_config
        
        return config_dict
    
    def save_to_file(self, file_path: str, include_sensitive: bool = False) -> None:
        """Save configuration to file."""
        config_dict = self.export_configuration(include_sensitive=include_sensitive)
        
        with open(file_path, 'w') as f:
            json.dump(config_dict, f, indent=2, default=str)
        
        logger.info(f"üíæ Configuration saved to {file_path}")
    
    @classmethod
    def load_from_file(cls, file_path: str) -> 'UnifiedSystemConfig':
        """Load configuration from file."""
        try:
            with open(file_path, 'r') as f:
                config_dict = json.load(f)
            
            logger.info(f"üìÇ Configuration loaded from {file_path}")
            return cls(**config_dict)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load configuration from {file_path}: {e}")
            raise


# ================================================================================
# Configuration Manager with Hot Reload
# ================================================================================

class ConfigurationManager:
    """
    Configuration manager with hot reload support and validation.
    
    Features:
    - Configuration loading from multiple sources
    - Hot-reload with file watching
    - Configuration validation and error reporting
    - Configuration history and rollback
    - Change notifications
    """
    
    def __init__(
        self,
        config: Optional[UnifiedSystemConfig] = None,
        enable_hot_reload: bool = False
    ):
        """Initialize configuration manager."""
        self.config = config or UnifiedSystemConfig()
        self.enable_hot_reload = enable_hot_reload
        
        # Configuration history for rollback
        self.config_history: List[Tuple[datetime, UnifiedSystemConfig]] = []
        self.max_history_size = 10
        
        # Hot-reload settings
        self._hot_reload_task: Optional[asyncio.Task] = None
        self._config_file_mtime: Optional[float] = None
        
        # Configuration change callbacks
        self._change_callbacks: List[Callable[[UnifiedSystemConfig], None]] = []
        
        logger.info(
            "‚öôÔ∏è Configuration manager initialized",
            extra={
                "environment": self.config.environment.value,
                "hot_reload": enable_hot_reload,
                "config_version": self.config.config_version
            }
        )
    
    def get_config(self) -> UnifiedSystemConfig:
        """Get current configuration."""
        return self.config
    
    def update_config(
        self,
        new_config: UnifiedSystemConfig,
        source: ConfigurationSource = ConfigurationSource.DEFAULT
    ) -> bool:
        """Update configuration with validation."""
        try:
            # Save current config to history
            self._save_to_history(self.config)
            
            # Apply new configuration
            self.config = new_config
            self.config.last_updated = datetime.utcnow()
            
            # Notify callbacks
            for callback in self._change_callbacks:
                try:
                    callback(new_config)
                except Exception as callback_error:
                    logger.warning(f"Configuration change callback failed: {callback_error}")
            
            logger.info(
                "‚úÖ Configuration updated successfully",
                extra={"source": source.value, "config_version": new_config.config_version}
            )
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to update configuration: {e}")
            return False
    
    def add_change_callback(self, callback: Callable[[UnifiedSystemConfig], None]) -> None:
        """Add callback for configuration changes."""
        self._change_callbacks.append(callback)
        logger.debug(f"‚ûï Added configuration change callback: {callback.__name__}")
    
    async def start_hot_reload(self) -> None:
        """Start hot-reload monitoring if enabled."""
        if not self.enable_hot_reload or not self.config.config_file_path:
            return
        
        self._hot_reload_task = asyncio.create_task(self._hot_reload_loop())
        logger.info("üî• Hot-reload monitoring started")
    
    async def stop_hot_reload(self) -> None:
        """Stop hot-reload monitoring."""
        if self._hot_reload_task:
            self._hot_reload_task.cancel()
            try:
                await self._hot_reload_task
            except asyncio.CancelledError:
                pass
            self._hot_reload_task = None
            
        logger.info("üõë Hot-reload monitoring stopped")
    
    async def _hot_reload_loop(self) -> None:
        """Hot-reload monitoring loop."""
        if not self.config.config_file_path:
            return
        
        config_file = self.config.config_file_path
        
        try:
            # Get initial file modification time
            if os.path.exists(config_file):
                self._config_file_mtime = os.path.getmtime(config_file)
            
            while True:
                await asyncio.sleep(self.config.hot_reload_interval)
                
                if not os.path.exists(config_file):
                    continue
                
                current_mtime = os.path.getmtime(config_file)
                
                if self._config_file_mtime is None or current_mtime > self._config_file_mtime:
                    logger.info(f"üîÑ Configuration file changed, reloading: {config_file}")
                    
                    try:
                        new_config = UnifiedSystemConfig.load_from_file(config_file)
                        
                        if self.update_config(new_config, ConfigurationSource.CONFIG_FILE):
                            self._config_file_mtime = current_mtime
                            logger.info("‚úÖ Hot-reload completed successfully")
                        else:
                            logger.error("‚ùå Hot-reload failed - keeping current configuration")
                            
                    except Exception as e:
                        logger.error(f"‚ùå Hot-reload error: {e}")
                
        except asyncio.CancelledError:
            logger.info("üõë Hot-reload loop cancelled")
            raise
        except Exception as e:
            logger.error(f"‚ùå Hot-reload loop error: {e}")
    
    def _save_to_history(self, config: UnifiedSystemConfig) -> None:
        """Save configuration to history."""
        current_time = datetime.utcnow()
        self.config_history.append((current_time, config))
        
        # Limit history size
        if len(self.config_history) > self.max_history_size:
            self.config_history.pop(0)


# ================================================================================
# Global Configuration Instance and Factory Functions
# ================================================================================

# Global configuration manager instance
_config_manager: Optional[ConfigurationManager] = None


def get_unified_config() -> UnifiedSystemConfig:
    """Get the global unified configuration."""
    global _config_manager
    
    if _config_manager is None:
        _config_manager = ConfigurationManager()
    
    return _config_manager.get_config()


def get_config_manager() -> ConfigurationManager:
    """Get the global configuration manager."""
    global _config_manager
    
    if _config_manager is None:
        _config_manager = ConfigurationManager()
    
    return _config_manager


def initialize_unified_config(
    environment: Optional[Environment] = None,
    config_file_path: Optional[str] = None,
    enable_hot_reload: bool = False
) -> ConfigurationManager:
    """
    Initialize the unified configuration system.
    
    Args:
        environment: Target environment
        config_file_path: Path to configuration file
        enable_hot_reload: Enable hot-reload monitoring
        
    Returns:
        Configured configuration manager
    """
    global _config_manager
    
    # Load configuration
    if config_file_path and os.path.exists(config_file_path):
        config = UnifiedSystemConfig.load_from_file(config_file_path)
        config.config_file_path = config_file_path
        config.hot_reload_enabled = enable_hot_reload
    else:
        env = environment or Environment.DEVELOPMENT
        config = UnifiedSystemConfig(environment=env)
        if config_file_path:
            config.config_file_path = config_file_path
            config.hot_reload_enabled = enable_hot_reload
    
    # Create configuration manager
    _config_manager = ConfigurationManager(
        config=config,
        enable_hot_reload=enable_hot_reload
    )
    
    logger.info(
        "‚úÖ Unified configuration system initialized",
        extra={
            "environment": config.environment.value,
            "config_file": config_file_path,
            "hot_reload": enable_hot_reload,
            "config_version": config.config_version
        }
    )
    
    return _config_manager


def create_default_config(environment: Environment) -> UnifiedSystemConfig:
    """Create default configuration for specific environment."""
    config = UnifiedSystemConfig(environment=environment)
    
    logger.info(f"üèóÔ∏è Created default configuration for {environment.value}")
    return config