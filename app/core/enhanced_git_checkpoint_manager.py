"""
Enhanced Git-Based Checkpoint Manager with Sleep Cycle Integration.

Provides production-ready checkpoint management with:
- Deep integration with sleep-wake cycles
- Enhanced metadata for agent state preservation  
- Context usage tracking and optimization
- Performance monitoring and analytics
- Automated cleanup and recovery capabilities
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from uuid import UUID
import hashlib

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, desc

from ..models.sleep_wake import (
    SleepWakeCycle, SleepState, CheckpointType, Checkpoint
)
from ..models.agent import Agent
from ..models.system_checkpoint import SystemCheckpoint
from ..core.database import get_async_session
from ..core.checkpoint_manager import CheckpointManager, get_checkpoint_manager
from ..core.sleep_wake_manager import SleepWakeManager
from ..core.config import get_settings

logger = logging.getLogger(__name__)


class EnhancedGitCheckpointManager:
    """
    Enhanced Git-based checkpoint manager with deep sleep cycle integration.
    
    Provides comprehensive agent state preservation including:
    - Sleep cycle context and trigger information
    - Context usage statistics and optimization data
    - Agent performance metrics and behavior patterns
    - Full reproducible state with Git versioning
    - Automated cleanup and retention policies
    """
    
    def __init__(self, base_checkpoint_manager: Optional[CheckpointManager] = None):
        self.settings = get_settings()
        self.base_manager = base_checkpoint_manager or get_checkpoint_manager()
        
        # Enhanced metadata tracking
        self.sleep_cycle_metadata: Dict[str, Any] = {}
        self.performance_metrics: Dict[str, Any] = {}
        
        # Git integration settings
        self.sleep_cycle_branch_prefix = "sleep-cycle"
        self.context_threshold_branch_prefix = "context-threshold"
        self.performance_branch_prefix = "performance"
        
        # Analytics settings
        self.enable_performance_analytics = True
        self.enable_context_optimization = True
        self.enable_predictive_checkpoints = True
        
        logger.info("ğŸ”„ Enhanced Git Checkpoint Manager initialized")
    
    async def create_enhanced_sleep_cycle_checkpoint(
        self,
        agent_id: UUID,
        sleep_cycle_data: Dict[str, Any],
        cycle_id: Optional[UUID] = None
    ) -> Optional[str]:
        """
        Create enhanced Git checkpoint with comprehensive sleep cycle integration.
        
        Args:
            agent_id: Agent identifier
            sleep_cycle_data: Complete sleep cycle context and metadata
            cycle_id: Optional sleep cycle identifier
            
        Returns:
            Git commit hash if successful, None otherwise
        """
        try:
            start_time = datetime.utcnow()
            
            # Prepare enhanced metadata
            enhanced_metadata = await self._prepare_enhanced_metadata(
                agent_id, sleep_cycle_data, cycle_id
            )
            
            # Create Git branch for this sleep cycle
            branch_name = self._generate_sleep_cycle_branch_name(agent_id, cycle_id)
            
            # Collect comprehensive state data
            state_data = await self._collect_comprehensive_state(agent_id, sleep_cycle_data)
            
            # Create the enhanced checkpoint
            git_commit_hash = await self.base_manager._create_git_checkpoint(
                checkpoint_id=cycle_id or UUID.uuid4(),
                agent_id=agent_id,
                checkpoint_type=CheckpointType.SLEEP_CYCLE,
                state_data=state_data,
                metadata=enhanced_metadata,
                git_branch=branch_name
            )
            
            if git_commit_hash:
                # Store checkpoint analytics
                await self._store_checkpoint_analytics(
                    agent_id, git_commit_hash, enhanced_metadata, start_time
                )
                
                # Update performance metrics
                await self._update_performance_metrics(agent_id, sleep_cycle_data)
                
                # Trigger optimization analysis
                if self.enable_context_optimization:
                    await self._analyze_context_optimization_opportunities(
                        agent_id, sleep_cycle_data, git_commit_hash
                    )
                
                logger.info(
                    f"âœ… Enhanced sleep cycle checkpoint created",
                    agent_id=str(agent_id),
                    git_commit_hash=git_commit_hash,
                    branch_name=branch_name,
                    context_usage=enhanced_metadata.get("context_usage_percent"),
                    cycle_trigger=enhanced_metadata.get("consolidation_trigger")
                )
                
                return git_commit_hash
            
            return None
            
        except Exception as e:
            logger.error(
                f"âŒ Failed to create enhanced sleep cycle checkpoint: {e}",
                agent_id=str(agent_id),
                cycle_id=str(cycle_id) if cycle_id else None
            )
            return None
    
    async def restore_from_enhanced_checkpoint(
        self,
        git_commit_hash: str,
        agent_id: Optional[UUID] = None,
        validate_context: bool = True
    ) -> Tuple[bool, Dict[str, Any]]:
        """
        Restore agent state from enhanced Git checkpoint with full context validation.
        
        Args:
            git_commit_hash: Git commit hash to restore from
            agent_id: Optional agent ID for validation
            validate_context: Whether to validate context consistency
            
        Returns:
            Tuple of (success, restoration_metadata)
        """
        try:
            start_time = datetime.utcnow()
            
            # Restore base state using existing checkpoint manager
            success, restoration_data = await self.base_manager.restore_checkpoint(
                git_commit_hash, agent_id
            )
            
            if not success:
                return False, {"error": "Base checkpoint restoration failed"}
            
            # Load enhanced metadata
            enhanced_metadata = await self._load_enhanced_metadata(git_commit_hash)
            
            # Validate context consistency if requested
            if validate_context:
                context_validation = await self._validate_context_consistency(
                    agent_id, enhanced_metadata, restoration_data
                )
                
                if not context_validation["valid"]:
                    logger.warning(
                        f"âš ï¸ Context consistency validation failed",
                        agent_id=str(agent_id) if agent_id else None,
                        git_commit_hash=git_commit_hash,
                        validation_issues=context_validation["issues"]
                    )
                    # Continue with restoration but note the issues
                    restoration_data["context_validation_issues"] = context_validation["issues"]
            
            # Restore sleep cycle specific state
            sleep_cycle_restoration = await self._restore_sleep_cycle_specific_state(
                enhanced_metadata, restoration_data
            )
            
            # Calculate restoration metrics
            restoration_time = (datetime.utcnow() - start_time).total_seconds()
            
            restoration_metadata = {
                **restoration_data,
                "enhanced_metadata": enhanced_metadata,
                "sleep_cycle_restoration": sleep_cycle_restoration,
                "restoration_time_seconds": restoration_time,
                "context_validation_performed": validate_context,
                "restoration_timestamp": datetime.utcnow().isoformat()
            }
            
            logger.info(
                f"âœ… Enhanced checkpoint restoration completed",
                agent_id=str(agent_id) if agent_id else None,
                git_commit_hash=git_commit_hash,
                restoration_time_seconds=restoration_time,
                context_validated=validate_context
            )
            
            return True, restoration_metadata
            
        except Exception as e:
            logger.error(
                f"âŒ Enhanced checkpoint restoration failed: {e}",
                agent_id=str(agent_id) if agent_id else None,
                git_commit_hash=git_commit_hash
            )
            return False, {"error": str(e)}
    
    async def create_context_threshold_checkpoint(
        self,
        agent_id: UUID,
        context_usage_percent: float,
        threshold_trigger: str,
        consolidation_opportunity: bool = False
    ) -> Optional[str]:
        """
        Create checkpoint triggered by context usage threshold.
        
        Args:
            agent_id: Agent identifier
            context_usage_percent: Current context usage percentage
            threshold_trigger: What triggered the threshold (e.g., "85_percent", "memory_pressure")
            consolidation_opportunity: Whether this is a good consolidation opportunity
            
        Returns:
            Git commit hash if successful
        """
        try:
            threshold_data = {
                "context_usage_percent": context_usage_percent,
                "threshold_trigger": threshold_trigger,
                "consolidation_opportunity": consolidation_opportunity,
                "timestamp": datetime.utcnow().isoformat(),
                "checkpoint_reason": "context_threshold"
            }
            
            # Create specialized branch for context threshold checkpoints
            branch_name = f"{self.context_threshold_branch_prefix}/{agent_id}/{threshold_trigger}"
            
            # Use enhanced checkpoint creation
            return await self.create_enhanced_sleep_cycle_checkpoint(
                agent_id=agent_id,
                sleep_cycle_data=threshold_data,
                cycle_id=UUID.uuid4()
            )
            
        except Exception as e:
            logger.error(
                f"âŒ Context threshold checkpoint creation failed: {e}",
                agent_id=str(agent_id),
                context_usage_percent=context_usage_percent,
                threshold_trigger=threshold_trigger
            )
            return None
    
    async def get_checkpoint_analytics(
        self,
        agent_id: Optional[UUID] = None,
        time_range: Optional[Tuple[datetime, datetime]] = None,
        include_performance_trends: bool = True
    ) -> Dict[str, Any]:
        """
        Get comprehensive analytics for checkpoints and sleep cycles.
        
        Args:
            agent_id: Optional agent filter
            time_range: Optional time range filter
            include_performance_trends: Whether to include performance trend analysis
            
        Returns:
            Comprehensive analytics data
        """
        try:
            analytics = {
                "summary": {},
                "agent_specific": {},
                "performance_trends": {},
                "optimization_opportunities": {},
                "health_metrics": {}
            }
            
            # Get base checkpoint analytics
            base_analytics = await self._get_base_checkpoint_analytics(agent_id, time_range)
            analytics["summary"] = base_analytics
            
            # Get sleep cycle specific analytics
            if agent_id:
                sleep_cycle_analytics = await self._get_sleep_cycle_analytics(agent_id, time_range)
                analytics["agent_specific"][str(agent_id)] = sleep_cycle_analytics
            
            # Performance trend analysis
            if include_performance_trends:
                performance_trends = await self._analyze_performance_trends(agent_id, time_range)
                analytics["performance_trends"] = performance_trends
            
            # Optimization opportunities
            optimization_opportunities = await self._identify_optimization_opportunities(agent_id)
            analytics["optimization_opportunities"] = optimization_opportunities
            
            # System health metrics
            health_metrics = await self._calculate_health_metrics()
            analytics["health_metrics"] = health_metrics
            
            return analytics
            
        except Exception as e:
            logger.error(f"âŒ Failed to get checkpoint analytics: {e}")
            return {"error": str(e)}
    
    # Private helper methods
    
    async def _prepare_enhanced_metadata(
        self,
        agent_id: UUID,
        sleep_cycle_data: Dict[str, Any],
        cycle_id: Optional[UUID]
    ) -> Dict[str, Any]:
        """Prepare comprehensive metadata for enhanced checkpoint."""
        base_metadata = {
            "sleep_cycle_id": str(cycle_id) if cycle_id else None,
            "agent_id": str(agent_id),
            "checkpoint_type": "enhanced_sleep_cycle",
            "created_at": datetime.utcnow().isoformat(),
            "version": "2.0"
        }
        
        # Sleep cycle specific metadata
        sleep_metadata = {
            "context_usage_percent": sleep_cycle_data.get("context_usage_percent", 0),
            "consolidation_trigger": sleep_cycle_data.get("consolidation_trigger", "unknown"),
            "trigger_reason": sleep_cycle_data.get("trigger_reason", "unknown"),
            "expected_wake_time": sleep_cycle_data.get("expected_wake_time"),
            "cycle_type": sleep_cycle_data.get("cycle_type", "manual"),
            "consolidation_performed": sleep_cycle_data.get("consolidation_performed", False),
            "memory_usage_mb": sleep_cycle_data.get("memory_usage_mb", 0),
            "active_context_count": sleep_cycle_data.get("active_context_count", 0)
        }
        
        # Performance metadata
        performance_metadata = await self._collect_performance_metadata(agent_id)
        
        # Context optimization metadata
        context_metadata = await self._collect_context_metadata(agent_id)
        
        return {
            **base_metadata,
            "sleep_cycle": sleep_metadata,
            "performance": performance_metadata,
            "context": context_metadata
        }
    
    async def _collect_comprehensive_state(
        self,
        agent_id: UUID,
        sleep_cycle_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Collect comprehensive agent state for checkpoint."""
        try:
            async with get_async_session() as session:
                # Get agent state
                agent_query = select(Agent).where(Agent.id == agent_id)
                agent_result = await session.execute(agent_query)
                agent = agent_result.scalar_one_or_none()
                
                if not agent:
                    raise ValueError(f"Agent {agent_id} not found")
                
                # Get active sleep-wake cycles
                cycle_query = select(SleepWakeCycle).where(
                    and_(
                        SleepWakeCycle.agent_id == agent_id,
                        SleepWakeCycle.state.in_([SleepState.SLEEPING, SleepState.WAKING])
                    )
                )
                cycle_result = await session.execute(cycle_query)
                active_cycles = cycle_result.scalars().all()
                
                # Collect comprehensive state
                state_data = {
                    "agent": {
                        "id": str(agent.id),
                        "name": agent.name,
                        "status": agent.status,
                        "capabilities": agent.capabilities,
                        "current_task_id": str(agent.current_task_id) if agent.current_task_id else None,
                        "last_heartbeat": agent.last_heartbeat.isoformat() if agent.last_heartbeat else None,
                        "metadata": agent.metadata or {}
                    },
                    "sleep_cycles": [
                        {
                            "id": str(cycle.id),
                            "state": cycle.state,
                            "sleep_started_at": cycle.sleep_started_at.isoformat() if cycle.sleep_started_at else None,
                            "expected_wake_at": cycle.expected_wake_at.isoformat() if cycle.expected_wake_at else None,
                            "actual_wake_at": cycle.actual_wake_at.isoformat() if cycle.actual_wake_at else None,
                            "consolidation_summary": cycle.consolidation_summary,
                            "performance_metrics": cycle.performance_metrics or {}
                        }
                        for cycle in active_cycles
                    ],
                    "sleep_cycle_context": sleep_cycle_data,
                    "capture_timestamp": datetime.utcnow().isoformat()
                }
                
                return state_data
                
        except Exception as e:
            logger.error(f"âŒ Failed to collect comprehensive state: {e}")
            return {}
    
    async def _collect_performance_metadata(self, agent_id: UUID) -> Dict[str, Any]:
        """Collect performance metrics for the agent."""
        try:
            # This would integrate with existing performance monitoring
            return {
                "avg_task_completion_time_ms": 0,  # Placeholder
                "success_rate_percent": 100,       # Placeholder
                "memory_efficiency_score": 85,     # Placeholder
                "context_utilization_score": 75,   # Placeholder
                "tool_usage_frequency": {},        # Placeholder
                "error_rate_percent": 5            # Placeholder
            }
        except Exception as e:
            logger.error(f"âŒ Failed to collect performance metadata: {e}")
            return {}
    
    async def _collect_context_metadata(self, agent_id: UUID) -> Dict[str, Any]:
        """Collect context-related metadata for optimization."""
        try:
            # This would integrate with context management system
            return {
                "total_contexts": 0,              # Placeholder
                "active_contexts": 0,             # Placeholder
                "compressed_contexts": 0,         # Placeholder
                "compression_ratio": 0.0,         # Placeholder
                "retrieval_frequency": {},        # Placeholder
                "context_age_distribution": {}    # Placeholder
            }
        except Exception as e:
            logger.error(f"âŒ Failed to collect context metadata: {e}")
            return {}
    
    def _generate_sleep_cycle_branch_name(
        self,
        agent_id: UUID,
        cycle_id: Optional[UUID]
    ) -> str:
        """Generate consistent branch name for sleep cycle checkpoints."""
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        cycle_suffix = str(cycle_id)[:8] if cycle_id else "manual"
        return f"{self.sleep_cycle_branch_prefix}/{agent_id}/{timestamp}_{cycle_suffix}"
    
    async def _store_checkpoint_analytics(
        self,
        agent_id: UUID,
        git_commit_hash: str,
        metadata: Dict[str, Any],
        start_time: datetime
    ) -> None:
        """Store checkpoint analytics for future analysis."""
        try:
            creation_time = (datetime.utcnow() - start_time).total_seconds()
            
            analytics_data = {
                "agent_id": str(agent_id),
                "git_commit_hash": git_commit_hash,
                "creation_time_seconds": creation_time,
                "context_usage_percent": metadata.get("sleep_cycle", {}).get("context_usage_percent", 0),
                "consolidation_trigger": metadata.get("sleep_cycle", {}).get("consolidation_trigger"),
                "memory_usage_mb": metadata.get("sleep_cycle", {}).get("memory_usage_mb", 0),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            # Store in analytics store (could be database, Redis, or file)
            logger.debug(f"ğŸ“Š Stored checkpoint analytics: {analytics_data}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to store checkpoint analytics: {e}")
    
    async def _update_performance_metrics(
        self,
        agent_id: UUID,
        sleep_cycle_data: Dict[str, Any]
    ) -> None:
        """Update performance metrics based on sleep cycle data."""
        try:
            # Update internal performance tracking
            agent_key = str(agent_id)
            if agent_key not in self.performance_metrics:
                self.performance_metrics[agent_key] = {
                    "total_sleep_cycles": 0,
                    "avg_context_usage": 0,
                    "avg_cycle_duration": 0,
                    "consolidation_success_rate": 100
                }
            
            metrics = self.performance_metrics[agent_key]
            metrics["total_sleep_cycles"] += 1
            
            # Update averages (simplified)
            context_usage = sleep_cycle_data.get("context_usage_percent", 0)
            metrics["avg_context_usage"] = (
                (metrics["avg_context_usage"] + context_usage) / 2
            )
            
            logger.debug(f"ğŸ“Š Updated performance metrics for agent {agent_id}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to update performance metrics: {e}")
    
    async def _analyze_context_optimization_opportunities(
        self,
        agent_id: UUID,
        sleep_cycle_data: Dict[str, Any],
        git_commit_hash: str
    ) -> None:
        """Analyze context usage patterns for optimization opportunities."""
        try:
            context_usage = sleep_cycle_data.get("context_usage_percent", 0)
            
            # Identify optimization opportunities
            if context_usage > 85:
                logger.info(
                    f"ğŸ” High context usage detected - optimization opportunity",
                    agent_id=str(agent_id),
                    context_usage_percent=context_usage,
                    git_commit_hash=git_commit_hash
                )
                
                # Could trigger automated compression or cleanup
                
            elif context_usage < 30:
                logger.info(
                    f"ğŸ” Low context usage detected - potential over-allocation",
                    agent_id=str(agent_id),
                    context_usage_percent=context_usage,
                    git_commit_hash=git_commit_hash
                )
            
        except Exception as e:
            logger.error(f"âŒ Context optimization analysis failed: {e}")
    
    async def _load_enhanced_metadata(self, git_commit_hash: str) -> Dict[str, Any]:
        """Load enhanced metadata for a Git checkpoint."""
        try:
            # Load metadata from Git commit or associated storage
            # This is a placeholder - would integrate with actual Git metadata storage
            return {
                "sleep_cycle": {},
                "performance": {},
                "context": {},
                "loaded_from_git": git_commit_hash
            }
        except Exception as e:
            logger.error(f"âŒ Failed to load enhanced metadata: {e}")
            return {}
    
    async def _validate_context_consistency(
        self,
        agent_id: Optional[UUID],
        metadata: Dict[str, Any],
        restoration_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Validate context consistency after restoration."""
        try:
            issues = []
            
            # Validate agent ID consistency
            if agent_id and metadata.get("agent_id") != str(agent_id):
                issues.append("Agent ID mismatch")
            
            # Validate timestamp consistency
            # Add more validation logic as needed
            
            return {
                "valid": len(issues) == 0,
                "issues": issues,
                "validation_timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {
                "valid": False,
                "issues": [f"Validation error: {e}"],
                "validation_timestamp": datetime.utcnow().isoformat()
            }
    
    async def _restore_sleep_cycle_specific_state(
        self,
        metadata: Dict[str, Any],
        restoration_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Restore sleep cycle specific state and context."""
        try:
            sleep_metadata = metadata.get("sleep_cycle", {})
            
            restoration_info = {
                "sleep_cycle_restored": True,
                "context_usage_restored": sleep_metadata.get("context_usage_percent"),
                "consolidation_trigger_restored": sleep_metadata.get("consolidation_trigger"),
                "expected_wake_time": sleep_metadata.get("expected_wake_time"),
                "restoration_successful": True
            }
            
            return restoration_info
            
        except Exception as e:
            logger.error(f"âŒ Sleep cycle state restoration failed: {e}")
            return {"restoration_successful": False, "error": str(e)}
    
    # Analytics methods (simplified implementations)
    
    async def _get_base_checkpoint_analytics(
        self, agent_id: Optional[UUID], time_range: Optional[Tuple[datetime, datetime]]
    ) -> Dict[str, Any]:
        """Get base checkpoint analytics."""
        return {"total_checkpoints": 0, "successful_checkpoints": 0}
    
    async def _get_sleep_cycle_analytics(
        self, agent_id: UUID, time_range: Optional[Tuple[datetime, datetime]]
    ) -> Dict[str, Any]:
        """Get sleep cycle specific analytics."""
        return {"total_cycles": 0, "avg_context_usage": 0}
    
    async def _analyze_performance_trends(
        self, agent_id: Optional[UUID], time_range: Optional[Tuple[datetime, datetime]]
    ) -> Dict[str, Any]:
        """Analyze performance trends."""
        return {"trend_direction": "stable", "improvement_score": 85}
    
    async def _identify_optimization_opportunities(
        self, agent_id: Optional[UUID]
    ) -> Dict[str, Any]:
        """Identify optimization opportunities."""
        return {"opportunities": [], "priority_score": 75}
    
    async def _calculate_health_metrics(self) -> Dict[str, Any]:
        """Calculate system health metrics."""
        return {"overall_health": "good", "checkpoint_success_rate": 98.5}


# Factory function
def get_enhanced_git_checkpoint_manager() -> EnhancedGitCheckpointManager:
    """Get the enhanced Git checkpoint manager instance."""
    return EnhancedGitCheckpointManager()