"""
Production Readiness Orchestrator for LeanVibe Agent Hive 2.0

Comprehensive production orchestrator that enhances existing monitoring infrastructure
with advanced production features including advanced alerting, SLA monitoring,
anomaly detection, auto-scaling, security monitoring, and disaster recovery.

Integrates with existing Prometheus/Grafana, performance_orchestrator, and 
agent infrastructure to provide enterprise-grade production readiness.
"""

import asyncio
import json
import uuid
import time
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import logging

import structlog
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, func, and_, or_
import psutil

from .database import get_session
from .redis import get_redis
from .config import settings
from .orchestrator import AgentOrchestrator
from .performance_orchestrator import PerformanceOrchestrator
from ..observability.prometheus_exporter import get_metrics_exporter
from ..models.performance_metric import PerformanceMetric
from ..models.agent import Agent, AgentStatus
from ..models.task import Task, TaskStatus
from ..models.session import Session, SessionStatus

logger = structlog.get_logger()


class ProductionEventSeverity(str, Enum):
    """Production event severity levels."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class SystemHealth(str, Enum):
    """Overall system health status."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CRITICAL = "critical"


class AutoScalingAction(str, Enum):
    """Auto-scaling action types."""
    SCALE_UP = "scale_up"
    SCALE_DOWN = "scale_down"
    MAINTAIN = "maintain"
    EMERGENCY_SCALE = "emergency_scale"


@dataclass
class ProductionMetrics:
    """Production system metrics."""
    timestamp: datetime
    
    # System performance
    cpu_usage_percent: float
    memory_usage_percent: float
    disk_usage_percent: float
    network_throughput_mbps: float
    
    # Application metrics
    active_agents: int
    total_sessions: int
    pending_tasks: int
    failed_tasks_last_hour: int
    average_response_time_ms: float
    
    # Database metrics
    db_connections: int
    db_query_time_ms: float
    db_pool_usage_percent: float
    
    # Redis metrics
    redis_memory_usage_mb: float
    redis_connections: int
    redis_latency_ms: float
    
    # SLA metrics
    availability_percent: float
    error_rate_percent: float
    response_time_p95_ms: float
    response_time_p99_ms: float
    
    # Security metrics
    failed_auth_attempts: int
    security_events: int
    blocked_requests: int


@dataclass
class AlertRule:
    """Production alert rule definition."""
    name: str
    description: str
    condition: str  # Expression to evaluate
    severity: ProductionEventSeverity
    threshold_value: float
    comparison_operator: str  # >, <, >=, <=, ==, !=
    evaluation_window_minutes: int = 5
    cooldown_minutes: int = 10
    escalation_minutes: int = 30
    
    # Advanced features
    anomaly_detection: bool = False
    trend_analysis: bool = False
    correlation_rules: List[str] = field(default_factory=list)
    notification_channels: List[str] = field(default_factory=list)
    
    # State tracking
    last_triggered: Optional[datetime] = None
    last_resolved: Optional[datetime] = None
    current_state: str = "ok"  # ok, warning, critical
    trigger_count: int = 0


@dataclass
class SLATarget:
    """Service Level Agreement target definition."""
    name: str
    description: str
    target_value: float
    measurement_window_hours: int = 24
    breach_threshold_percent: float = 5.0  # Allowable breach percentage
    
    # Tracking
    current_value: float = 0.0
    breach_count: int = 0
    last_breach: Optional[datetime] = None
    compliance_percent: float = 100.0


@dataclass
class ProductionAlert:
    """Production alert instance."""
    alert_id: str
    rule_name: str
    severity: ProductionEventSeverity
    title: str
    description: str
    triggered_at: datetime
    resolved_at: Optional[datetime] = None
    
    # Context
    affected_components: List[str] = field(default_factory=list)
    metric_values: Dict[str, Any] = field(default_factory=dict)
    correlation_id: Optional[str] = None
    
    # Response tracking
    acknowledged: bool = False
    acknowledged_by: Optional[str] = None
    acknowledged_at: Optional[datetime] = None
    resolution_notes: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert alert to dictionary."""
        return {
            **asdict(self),
            'triggered_at': self.triggered_at.isoformat() if self.triggered_at else None,
            'resolved_at': self.resolved_at.isoformat() if self.resolved_at else None,
            'acknowledged_at': self.acknowledged_at.isoformat() if self.acknowledged_at else None
        }


@dataclass
class AutoScalingDecision:
    """Auto-scaling decision result."""
    action: AutoScalingAction
    reason: str
    confidence: float
    recommended_agent_count: int
    current_agent_count: int
    metric_drivers: Dict[str, float]
    estimated_impact: str
    execute_immediately: bool = False


@dataclass
class DisasterRecoveryStatus:
    """Disaster recovery status."""
    backup_status: str
    last_backup: Optional[datetime]
    recovery_point_objective_minutes: int
    recovery_time_objective_minutes: int
    
    # Current state
    replication_lag_seconds: float = 0.0
    backup_age_hours: float = 0.0
    data_integrity_score: float = 100.0
    
    # Capability assessment
    can_recover: bool = True
    estimated_recovery_time_minutes: int = 0
    data_loss_risk: str = "minimal"


class ProductionOrchestrator:
    """
    Comprehensive Production Readiness Orchestrator.
    
    Provides enterprise-grade production features including:
    - Advanced monitoring and alerting with anomaly detection
    - SLA monitoring and compliance reporting
    - Auto-scaling and resource management
    - Security monitoring and threat detection
    - Disaster recovery and backup automation
    - Performance regression detection
    - Real-time dashboards and reporting
    """
    
    def __init__(
        self,
        agent_orchestrator: Optional[AgentOrchestrator] = None,
        performance_orchestrator: Optional[PerformanceOrchestrator] = None,
        db_session: Optional[AsyncSession] = None
    ):
        """Initialize production orchestrator."""
        self.agent_orchestrator = agent_orchestrator
        self.performance_orchestrator = performance_orchestrator
        self.db_session = db_session
        
        # Metrics and monitoring
        self.metrics_exporter = get_metrics_exporter()
        self.current_metrics: Optional[ProductionMetrics] = None
        self.metrics_history: List[ProductionMetrics] = []
        
        # Alert management
        self.alert_rules: List[AlertRule] = []
        self.active_alerts: Dict[str, ProductionAlert] = {}
        self.alert_history: List[ProductionAlert] = []
        
        # SLA monitoring
        self.sla_targets: List[SLATarget] = []
        
        # Auto-scaling
        self.auto_scaling_enabled: bool = True
        self.min_agents: int = 1
        self.max_agents: int = 20
        self.scaling_cooldown_minutes: int = 5
        self.last_scaling_action: Optional[datetime] = None
        
        # Disaster recovery
        self.backup_enabled: bool = True
        self.backup_interval_hours: int = 6
        self.backup_retention_days: int = 30
        self.last_backup: Optional[datetime] = None
        
        # State tracking
        self.is_running: bool = False
        self.start_time: datetime = datetime.utcnow()
        self.monitoring_tasks: List[asyncio.Task] = []
        
        # Initialize default configuration
        self._initialize_default_configuration()
        
    def _initialize_default_configuration(self) -> None:
        """Initialize default production configuration."""
        
        # Default alert rules
        self.alert_rules = [
            # System resource alerts
            AlertRule(
                name="high_cpu_usage",
                description="CPU usage above 80%",
                condition="cpu_usage_percent",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=80.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="critical_cpu_usage",
                description="CPU usage above 95%",
                condition="cpu_usage_percent",
                severity=ProductionEventSeverity.CRITICAL,
                threshold_value=95.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="high_memory_usage",
                description="Memory usage above 85%",
                condition="memory_usage_percent",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=85.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="critical_memory_usage",
                description="Memory usage above 95%",
                condition="memory_usage_percent",
                severity=ProductionEventSeverity.CRITICAL,
                threshold_value=95.0,
                comparison_operator=">"
            ),
            
            # Application performance alerts
            AlertRule(
                name="high_response_time",
                description="P95 response time above 2 seconds",
                condition="response_time_p95_ms",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=2000.0,
                comparison_operator=">",
                trend_analysis=True
            ),
            AlertRule(
                name="high_error_rate",
                description="Error rate above 5%",
                condition="error_rate_percent",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=5.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="critical_error_rate",
                description="Error rate above 10%",
                condition="error_rate_percent",
                severity=ProductionEventSeverity.CRITICAL,
                threshold_value=10.0,
                comparison_operator=">"
            ),
            
            # Database alerts
            AlertRule(
                name="high_db_connections",
                description="Database connections above 80% of pool",
                condition="db_pool_usage_percent",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=80.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="slow_db_queries",
                description="Average database query time above 500ms",
                condition="db_query_time_ms",
                severity=ProductionEventSeverity.MEDIUM,
                threshold_value=500.0,
                comparison_operator=">",
                trend_analysis=True
            ),
            
            # Agent health alerts
            AlertRule(
                name="agent_failure_rate",
                description="Failed tasks above 10% in last hour",
                condition="failed_tasks_last_hour",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=10.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="no_active_agents",
                description="No active agents available",
                condition="active_agents",
                severity=ProductionEventSeverity.CRITICAL,
                threshold_value=1.0,
                comparison_operator="<"
            ),
            
            # Security alerts
            AlertRule(
                name="high_failed_auth",
                description="High number of failed authentication attempts",
                condition="failed_auth_attempts",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=50.0,
                comparison_operator=">"
            ),
            AlertRule(
                name="security_events_spike",
                description="Unusual spike in security events",
                condition="security_events",
                severity=ProductionEventSeverity.MEDIUM,
                threshold_value=20.0,
                comparison_operator=">",
                anomaly_detection=True
            ),
            
            # Availability and SLA alerts
            AlertRule(
                name="low_availability",
                description="System availability below 99%",
                condition="availability_percent",
                severity=ProductionEventSeverity.HIGH,
                threshold_value=99.0,
                comparison_operator="<"
            )
        ]
        
        # Default SLA targets
        self.sla_targets = [
            SLATarget(
                name="system_availability",
                description="System uptime and availability",
                target_value=99.9  # 99.9% uptime
            ),
            SLATarget(
                name="response_time_p95",
                description="95th percentile response time",
                target_value=1000.0  # 1 second
            ),
            SLATarget(
                name="error_rate",
                description="Overall error rate",
                target_value=1.0  # 1% error rate
            ),
            SLATarget(
                name="task_completion_rate",
                description="Task completion success rate",
                target_value=95.0  # 95% completion rate
            )
        ]
    
    async def start(self) -> None:
        """Start the production orchestrator."""
        logger.info("ðŸš€ Starting Production Orchestrator...")
        
        try:
            # Initialize database session if not provided
            if self.db_session is None:
                self.db_session = await anext(get_session())
            
            self.is_running = True
            self.start_time = datetime.utcnow()
            
            # Start monitoring tasks
            self.monitoring_tasks = [
                asyncio.create_task(self._metrics_collection_loop()),
                asyncio.create_task(self._alert_evaluation_loop()),
                asyncio.create_task(self._sla_monitoring_loop()),
                asyncio.create_task(self._auto_scaling_loop()),
                asyncio.create_task(self._security_monitoring_loop()),
                asyncio.create_task(self._backup_management_loop()),
                asyncio.create_task(self._health_check_loop()),
                asyncio.create_task(self._anomaly_detection_loop())
            ]
            
            # Initialize health monitor and alerting engine
            from .health_monitor import HealthMonitor
            from .alerting_engine import AlertingEngine
            
            self.health_monitor = HealthMonitor(self)
            self.alerting_engine = AlertingEngine(self)
            
            await self.health_monitor.initialize()
            await self.alerting_engine.initialize()
            
            logger.info("âœ… Production Orchestrator started successfully")
            
        except Exception as e:
            logger.error(f"âŒ Failed to start Production Orchestrator: {e}")
            raise
    
    async def shutdown(self) -> None:
        """Gracefully shutdown the production orchestrator."""
        logger.info("ðŸ›‘ Shutting down Production Orchestrator...")
        
        self.is_running = False
        
        # Cancel all monitoring tasks
        for task in self.monitoring_tasks:
            if not task.done():
                task.cancel()
        
        # Wait for tasks to complete with timeout
        if self.monitoring_tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*self.monitoring_tasks, return_exceptions=True),
                    timeout=30.0
                )
            except asyncio.TimeoutError:
                logger.warning("Some monitoring tasks did not shutdown gracefully")
        
        logger.info("âœ… Production Orchestrator shutdown complete")
    
    async def get_production_status(self) -> Dict[str, Any]:
        """Get comprehensive production status."""
        return {
            "orchestrator_status": "running" if self.is_running else "stopped",
            "uptime_seconds": (datetime.utcnow() - self.start_time).total_seconds(),
            "system_health": await self._calculate_system_health(),
            "current_metrics": self.current_metrics.__dict__ if self.current_metrics else None,
            "active_alerts": len(self.active_alerts),
            "critical_alerts": len([a for a in self.active_alerts.values() 
                                  if a.severity == ProductionEventSeverity.CRITICAL]),
            "sla_compliance": await self._calculate_sla_compliance(),
            "auto_scaling_status": await self._get_auto_scaling_status(),
            "disaster_recovery_status": await self._get_disaster_recovery_status(),
            "component_health": await self._get_component_health_summary(),
            "performance_summary": await self._get_performance_summary()
        }
    
    async def _metrics_collection_loop(self) -> None:
        """Main metrics collection loop."""
        while self.is_running:
            try:
                # Collect comprehensive metrics
                metrics = await self._collect_production_metrics()
                self.current_metrics = metrics
                
                # Store in history (keep last 1000 entries)
                self.metrics_history.append(metrics)
                if len(self.metrics_history) > 1000:
                    self.metrics_history.pop(0)
                
                # Store in database for persistence
                await self._store_metrics_in_database(metrics)
                
                # Update Prometheus metrics
                await self._update_prometheus_metrics(metrics)
                
                # Sleep for collection interval
                await asyncio.sleep(30)  # Collect every 30 seconds
                
            except Exception as e:
                logger.error(f"Error in metrics collection loop: {e}")
                await asyncio.sleep(60)  # Longer sleep on error
    
    async def _collect_production_metrics(self) -> ProductionMetrics:
        """Collect comprehensive production metrics."""
        
        # System metrics
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        network_stats = psutil.net_io_counters()
        network_throughput = (network_stats.bytes_sent + network_stats.bytes_recv) / (1024 * 1024)  # MB
        
        # Database metrics
        db_connections = await self._get_database_connections()
        db_query_time = await self._get_average_db_query_time()
        db_pool_usage = await self._get_db_pool_usage()
        
        # Redis metrics
        redis_memory, redis_connections, redis_latency = await self._get_redis_metrics()
        
        # Application metrics
        active_agents = await self._get_active_agent_count()
        total_sessions = await self._get_total_session_count()
        pending_tasks = await self._get_pending_task_count()
        failed_tasks = await self._get_failed_tasks_last_hour()
        avg_response_time = await self._get_average_response_time()
        
        # SLA metrics
        availability = await self._calculate_availability()
        error_rate = await self._calculate_error_rate()
        response_time_p95 = await self._calculate_response_time_percentile(95)
        response_time_p99 = await self._calculate_response_time_percentile(99)
        
        # Security metrics
        failed_auth = await self._get_failed_auth_attempts()
        security_events = await self._get_security_events()
        blocked_requests = await self._get_blocked_requests()
        
        return ProductionMetrics(
            timestamp=datetime.utcnow(),
            cpu_usage_percent=cpu_percent,
            memory_usage_percent=memory.percent,
            disk_usage_percent=(disk.used / disk.total) * 100,
            network_throughput_mbps=network_throughput,
            active_agents=active_agents,
            total_sessions=total_sessions,
            pending_tasks=pending_tasks,
            failed_tasks_last_hour=failed_tasks,
            average_response_time_ms=avg_response_time,
            db_connections=db_connections,
            db_query_time_ms=db_query_time,
            db_pool_usage_percent=db_pool_usage,
            redis_memory_usage_mb=redis_memory,
            redis_connections=redis_connections,
            redis_latency_ms=redis_latency,
            availability_percent=availability,
            error_rate_percent=error_rate,
            response_time_p95_ms=response_time_p95,
            response_time_p99_ms=response_time_p99,
            failed_auth_attempts=failed_auth,
            security_events=security_events,
            blocked_requests=blocked_requests
        )
    
    async def _alert_evaluation_loop(self) -> None:
        """Evaluate alert rules and trigger alerts."""
        while self.is_running:
            try:
                if self.current_metrics:
                    await self._evaluate_alert_rules(self.current_metrics)
                
                # Check for alert resolutions
                await self._check_alert_resolutions()
                
                await asyncio.sleep(60)  # Evaluate every minute
                
            except Exception as e:
                logger.error(f"Error in alert evaluation loop: {e}")
                await asyncio.sleep(60)
    
    async def _evaluate_alert_rules(self, metrics: ProductionMetrics) -> None:
        """Evaluate all alert rules against current metrics."""
        
        for rule in self.alert_rules:
            try:
                # Check if rule is in cooldown
                if (rule.last_triggered and 
                    datetime.utcnow() - rule.last_triggered < timedelta(minutes=rule.cooldown_minutes)):
                    continue
                
                # Get metric value for rule condition
                metric_value = getattr(metrics, rule.condition, None)
                if metric_value is None:
                    continue
                
                # Evaluate condition
                should_trigger = self._evaluate_condition(
                    metric_value, rule.threshold_value, rule.comparison_operator
                )
                
                # Enhanced evaluation with anomaly detection
                if rule.anomaly_detection:
                    should_trigger = should_trigger or await self._detect_anomaly(rule, metric_value)
                
                # Trend analysis
                if rule.trend_analysis:
                    should_trigger = should_trigger or await self._analyze_trend(rule, metric_value)
                
                if should_trigger and rule.name not in self.active_alerts:
                    await self._trigger_alert(rule, metric_value, metrics)
                    
            except Exception as e:
                logger.error(f"Error evaluating alert rule {rule.name}: {e}")
    
    def _evaluate_condition(self, value: float, threshold: float, operator: str) -> bool:
        """Evaluate alert condition."""
        operators = {
            ">": lambda v, t: v > t,
            "<": lambda v, t: v < t,
            ">=": lambda v, t: v >= t,
            "<=": lambda v, t: v <= t,
            "==": lambda v, t: v == t,
            "!=": lambda v, t: v != t
        }
        return operators.get(operator, lambda v, t: False)(value, threshold)
    
    async def _detect_anomaly(self, rule: AlertRule, current_value: float) -> bool:
        """Detect anomalies using statistical analysis."""
        if len(self.metrics_history) < 10:
            return False
        
        # Get historical values for the same metric
        historical_values = []
        for metrics in self.metrics_history[-50:]:  # Last 50 data points
            value = getattr(metrics, rule.condition, None)
            if value is not None:
                historical_values.append(value)
        
        if len(historical_values) < 10:
            return False
        
        # Calculate statistical thresholds
        mean = statistics.mean(historical_values)
        stdev = statistics.stdev(historical_values)
        
        # Consider it an anomaly if value is more than 3 standard deviations from mean
        threshold = mean + (3 * stdev)
        
        return current_value > threshold
    
    async def _analyze_trend(self, rule: AlertRule, current_value: float) -> bool:
        """Analyze trends for predictive alerting."""
        if len(self.metrics_history) < 5:
            return False
        
        # Get recent values
        recent_values = []
        for metrics in self.metrics_history[-5:]:
            value = getattr(metrics, rule.condition, None)
            if value is not None:
                recent_values.append(value)
        
        if len(recent_values) < 5:
            return False
        
        # Calculate trend (simple linear regression slope)
        x_values = list(range(len(recent_values)))
        n = len(recent_values)
        
        slope = (n * sum(x * y for x, y in zip(x_values, recent_values)) - 
                sum(x_values) * sum(recent_values)) / (n * sum(x**2 for x in x_values) - sum(x_values)**2)
        
        # Trigger if trend is rapidly increasing towards threshold
        projected_value = current_value + (slope * 3)  # Project 3 periods ahead
        
        return self._evaluate_condition(projected_value, rule.threshold_value, rule.comparison_operator)
    
    async def _trigger_alert(self, rule: AlertRule, metric_value: float, metrics: ProductionMetrics) -> None:
        """Trigger a new alert."""
        alert_id = str(uuid.uuid4())
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name=rule.name,
            severity=rule.severity,
            title=f"{rule.name.replace('_', ' ').title()}",
            description=f"{rule.description}. Current value: {metric_value}",
            triggered_at=datetime.utcnow(),
            metric_values={
                rule.condition: metric_value,
                "threshold": rule.threshold_value
            }
        )
        
        # Add to active alerts
        self.active_alerts[rule.name] = alert
        self.alert_history.append(alert)
        
        # Update rule state
        rule.last_triggered = datetime.utcnow()
        rule.current_state = "critical" if rule.severity == ProductionEventSeverity.CRITICAL else "warning"
        rule.trigger_count += 1
        
        # Send notifications through alerting engine
        if hasattr(self, 'alerting_engine'):
            await self.alerting_engine.send_alert_notification(alert)
        
        # Record metrics
        self.metrics_exporter.record_alert(alert.rule_name, alert.severity.value, "production_orchestrator")
        
        logger.warning(
            f"ðŸš¨ Alert triggered: {alert.title}",
            alert_id=alert_id,
            severity=alert.severity.value,
            metric_value=metric_value,
            threshold=rule.threshold_value
        )
    
    async def _check_alert_resolutions(self) -> None:
        """Check if active alerts should be resolved."""
        if not self.current_metrics:
            return
        
        resolved_alerts = []
        
        for rule_name, alert in self.active_alerts.items():
            rule = next((r for r in self.alert_rules if r.name == rule_name), None)
            if not rule:
                continue
            
            # Get current metric value
            metric_value = getattr(self.current_metrics, rule.condition, None)
            if metric_value is None:
                continue
            
            # Check if condition is no longer met
            should_trigger = self._evaluate_condition(
                metric_value, rule.threshold_value, rule.comparison_operator
            )
            
            if not should_trigger:
                # Resolve alert
                alert.resolved_at = datetime.utcnow()
                rule.current_state = "ok"
                rule.last_resolved = datetime.utcnow()
                
                resolved_alerts.append(rule_name)
                
                logger.info(
                    f"âœ… Alert resolved: {alert.title}",
                    alert_id=alert.alert_id,
                    resolution_time_minutes=(alert.resolved_at - alert.triggered_at).total_seconds() / 60
                )
        
        # Remove resolved alerts from active list
        for rule_name in resolved_alerts:
            del self.active_alerts[rule_name]
    
    async def _sla_monitoring_loop(self) -> None:
        """Monitor SLA compliance."""
        while self.is_running:
            try:
                await self._update_sla_targets()
                await asyncio.sleep(300)  # Update every 5 minutes
                
            except Exception as e:
                logger.error(f"Error in SLA monitoring loop: {e}")
                await asyncio.sleep(300)
    
    async def _update_sla_targets(self) -> None:
        """Update SLA target compliance."""
        if not self.current_metrics:
            return
        
        for target in self.sla_targets:
            try:
                # Get current value for SLA metric
                if target.name == "system_availability":
                    target.current_value = self.current_metrics.availability_percent
                elif target.name == "response_time_p95":
                    target.current_value = self.current_metrics.response_time_p95_ms
                elif target.name == "error_rate":
                    target.current_value = self.current_metrics.error_rate_percent
                elif target.name == "task_completion_rate":
                    target.current_value = await self._calculate_task_completion_rate()
                
                # Check for SLA breach
                if target.current_value < target.target_value:
                    target.breach_count += 1
                    target.last_breach = datetime.utcnow()
                    
                    # Calculate compliance percentage
                    breach_impact = abs(target.current_value - target.target_value) / target.target_value * 100
                    target.compliance_percent = max(0, 100 - breach_impact)
                    
                    # Trigger SLA breach alert if significant
                    if breach_impact > target.breach_threshold_percent:
                        await self._trigger_sla_breach_alert(target, breach_impact)
                else:
                    target.compliance_percent = 100.0
                    
            except Exception as e:
                logger.error(f"Error updating SLA target {target.name}: {e}")
    
    async def _trigger_sla_breach_alert(self, target: SLATarget, breach_impact: float) -> None:
        """Trigger SLA breach alert."""
        alert_id = str(uuid.uuid4())
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name=f"sla_breach_{target.name}",
            severity=ProductionEventSeverity.HIGH,
            title=f"SLA Breach: {target.name}",
            description=f"SLA target breached. Target: {target.target_value}, Current: {target.current_value:.2f}, Impact: {breach_impact:.1f}%",
            triggered_at=datetime.utcnow(),
            affected_components=["sla_monitoring"],
            metric_values={
                "target_value": target.target_value,
                "current_value": target.current_value,
                "breach_impact": breach_impact
            }
        )
        
        self.alert_history.append(alert)
        
        logger.error(
            f"ðŸš¨ SLA Breach Alert: {target.name}",
            target_value=target.target_value,
            current_value=target.current_value,
            breach_impact=breach_impact
        )
    
    async def _auto_scaling_loop(self) -> None:
        """Auto-scaling decision and execution loop."""
        while self.is_running:
            try:
                if self.auto_scaling_enabled:
                    decision = await self._make_auto_scaling_decision()
                    if decision.action != AutoScalingAction.MAINTAIN:
                        await self._execute_auto_scaling_decision(decision)
                
                await asyncio.sleep(300)  # Check every 5 minutes
                
            except Exception as e:
                logger.error(f"Error in auto-scaling loop: {e}")
                await asyncio.sleep(300)
    
    async def _make_auto_scaling_decision(self) -> AutoScalingDecision:
        """Make intelligent auto-scaling decision."""
        if not self.current_metrics:
            return AutoScalingDecision(
                action=AutoScalingAction.MAINTAIN,
                reason="No metrics available",
                confidence=0.0,
                recommended_agent_count=self.min_agents,
                current_agent_count=self.current_metrics.active_agents if self.current_metrics else 0,
                metric_drivers={},
                estimated_impact="none"
            )
        
        current_agents = self.current_metrics.active_agents
        
        # Collect scaling indicators
        scaling_indicators = {
            "cpu_pressure": max(0, self.current_metrics.cpu_usage_percent - 70) / 30,  # 0-1 scale
            "memory_pressure": max(0, self.current_metrics.memory_usage_percent - 80) / 20,
            "pending_task_pressure": min(1.0, self.current_metrics.pending_tasks / 50),
            "response_time_pressure": max(0, self.current_metrics.response_time_p95_ms - 1000) / 2000,
            "error_rate_pressure": min(1.0, self.current_metrics.error_rate_percent / 10)
        }
        
        # Calculate overall pressure score
        pressure_score = sum(scaling_indicators.values()) / len(scaling_indicators)
        
        # Make scaling decision
        if pressure_score > 0.7 and current_agents < self.max_agents:
            # Scale up
            recommended_agents = min(self.max_agents, current_agents + max(1, int(pressure_score * 3)))
            return AutoScalingDecision(
                action=AutoScalingAction.SCALE_UP,
                reason=f"High system pressure detected (score: {pressure_score:.2f})",
                confidence=min(1.0, pressure_score),
                recommended_agent_count=recommended_agents,
                current_agent_count=current_agents,
                metric_drivers=scaling_indicators,
                estimated_impact="Reduced latency and improved throughput",
                execute_immediately=pressure_score > 0.9
            )
        elif pressure_score < 0.2 and current_agents > self.min_agents:
            # Scale down
            recommended_agents = max(self.min_agents, current_agents - 1)
            return AutoScalingDecision(
                action=AutoScalingAction.SCALE_DOWN,
                reason=f"Low system pressure detected (score: {pressure_score:.2f})",
                confidence=min(1.0, 1.0 - pressure_score),
                recommended_agent_count=recommended_agents,
                current_agent_count=current_agents,
                metric_drivers=scaling_indicators,
                estimated_impact="Reduced resource costs while maintaining performance"
            )
        else:
            return AutoScalingDecision(
                action=AutoScalingAction.MAINTAIN,
                reason=f"System pressure within acceptable range (score: {pressure_score:.2f})",
                confidence=0.8,
                recommended_agent_count=current_agents,
                current_agent_count=current_agents,
                metric_drivers=scaling_indicators,
                estimated_impact="Stable performance maintained"
            )
    
    async def _execute_auto_scaling_decision(self, decision: AutoScalingDecision) -> None:
        """Execute auto-scaling decision."""
        # Check cooldown period
        if (self.last_scaling_action and 
            datetime.utcnow() - self.last_scaling_action < timedelta(minutes=self.scaling_cooldown_minutes)):
            logger.info(f"Auto-scaling in cooldown period, skipping action: {decision.action}")
            return
        
        try:
            if decision.action == AutoScalingAction.SCALE_UP:
                agents_to_add = decision.recommended_agent_count - decision.current_agent_count
                if self.agent_orchestrator:
                    for _ in range(agents_to_add):
                        await self.agent_orchestrator.spawn_agent(
                            role=self.agent_orchestrator.AgentRole.BACKEND_DEVELOPER  # Default role
                        )
                        
                logger.info(
                    f"ðŸ”¼ Auto-scaled UP: Added {agents_to_add} agents",
                    reason=decision.reason,
                    new_total=decision.recommended_agent_count
                )
                
            elif decision.action == AutoScalingAction.SCALE_DOWN:
                agents_to_remove = decision.current_agent_count - decision.recommended_agent_count
                if self.agent_orchestrator:
                    # Get least utilized agents to remove
                    agents_to_shutdown = await self._get_least_utilized_agents(agents_to_remove)
                    for agent_id in agents_to_shutdown:
                        await self.agent_orchestrator.shutdown_agent(agent_id, graceful=True)
                        
                logger.info(
                    f"ðŸ”½ Auto-scaled DOWN: Removed {agents_to_remove} agents",
                    reason=decision.reason,
                    new_total=decision.recommended_agent_count
                )
            
            self.last_scaling_action = datetime.utcnow()
            
            # Record scaling metrics
            self.metrics_exporter.record_agent_operation(
                "auto_scaler", 
                decision.action.value, 
                "success", 
                1.0
            )
            
        except Exception as e:
            logger.error(f"Failed to execute auto-scaling decision: {e}")
            self.metrics_exporter.record_error("auto_scaling", "execution_failed")
    
    async def _security_monitoring_loop(self) -> None:
        """Security monitoring and threat detection loop."""
        while self.is_running:
            try:
                await self._monitor_security_events()
                await asyncio.sleep(60)  # Monitor every minute
                
            except Exception as e:
                logger.error(f"Error in security monitoring loop: {e}")
                await asyncio.sleep(60)
    
    async def _monitor_security_events(self) -> None:
        """Monitor for security threats and anomalies."""
        if not self.current_metrics:
            return
        
        # Check for brute force attacks
        if self.current_metrics.failed_auth_attempts > 100:
            await self._trigger_security_alert(
                "brute_force_attack",
                f"High number of failed authentication attempts: {self.current_metrics.failed_auth_attempts}"
            )
        
        # Check for unusual security event patterns
        if self.current_metrics.security_events > 50:
            await self._trigger_security_alert(
                "security_event_spike",
                f"Unusual spike in security events: {self.current_metrics.security_events}"
            )
        
        # Monitor blocked requests for DDoS patterns
        if self.current_metrics.blocked_requests > 1000:
            await self._trigger_security_alert(
                "potential_ddos",
                f"High number of blocked requests: {self.current_metrics.blocked_requests}"
            )
    
    async def _trigger_security_alert(self, event_type: str, description: str) -> None:
        """Trigger security-specific alert."""
        alert_id = str(uuid.uuid4())
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name=f"security_{event_type}",
            severity=ProductionEventSeverity.HIGH,
            title=f"Security Alert: {event_type.replace('_', ' ').title()}",
            description=description,
            triggered_at=datetime.utcnow(),
            affected_components=["security_system"]
        )
        
        self.alert_history.append(alert)
        
        logger.error(f"ðŸ”’ Security Alert: {alert.title}", description=description)
    
    async def _backup_management_loop(self) -> None:
        """Backup and disaster recovery management loop."""
        while self.is_running:
            try:
                if self.backup_enabled:
                    await self._manage_backups()
                
                await asyncio.sleep(3600)  # Check every hour
                
            except Exception as e:
                logger.error(f"Error in backup management loop: {e}")
                await asyncio.sleep(3600)
    
    async def _manage_backups(self) -> None:
        """Manage automated backups."""
        now = datetime.utcnow()
        
        # Check if backup is due
        if (not self.last_backup or 
            now - self.last_backup >= timedelta(hours=self.backup_interval_hours)):
            
            try:
                await self._create_backup()
                self.last_backup = now
                
                logger.info("ðŸ’¾ Automated backup completed successfully")
                
            except Exception as e:
                logger.error(f"âŒ Automated backup failed: {e}")
                await self._trigger_backup_failure_alert(str(e))
        
        # Clean up old backups
        await self._cleanup_old_backups()
    
    async def _create_backup(self) -> None:
        """Create system backup."""
        # This is a placeholder - implement actual backup logic
        backup_id = str(uuid.uuid4())
        backup_path = f"backups/backup_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{backup_id}"
        
        # In a real implementation, this would:
        # 1. Create database dump
        # 2. Backup configuration files
        # 3. Archive critical data
        # 4. Upload to cloud storage
        # 5. Verify backup integrity
        
        logger.info(f"Creating backup: {backup_path}")
        await asyncio.sleep(1)  # Simulate backup operation
    
    async def _cleanup_old_backups(self) -> None:
        """Clean up backups older than retention period."""
        cutoff_date = datetime.utcnow() - timedelta(days=self.backup_retention_days)
        
        # In a real implementation, this would clean up actual backup files
        logger.debug(f"Cleaning up backups older than {cutoff_date}")
    
    async def _trigger_backup_failure_alert(self, error_message: str) -> None:
        """Trigger alert for backup failure."""
        alert_id = str(uuid.uuid4())
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name="backup_failure",
            severity=ProductionEventSeverity.HIGH,
            title="Backup Failure",
            description=f"Automated backup failed: {error_message}",
            triggered_at=datetime.utcnow(),
            affected_components=["backup_system"]
        )
        
        self.alert_history.append(alert)
        
        logger.error(f"ðŸ’¾ Backup Failure Alert: {error_message}")
    
    async def _health_check_loop(self) -> None:
        """Overall system health monitoring loop."""
        while self.is_running:
            try:
                health_status = await self._calculate_system_health()
                
                if health_status in [SystemHealth.UNHEALTHY, SystemHealth.CRITICAL]:
                    await self._trigger_health_alert(health_status)
                
                await asyncio.sleep(120)  # Check every 2 minutes
                
            except Exception as e:
                logger.error(f"Error in health check loop: {e}")
                await asyncio.sleep(120)
    
    async def _calculate_system_health(self) -> SystemHealth:
        """Calculate overall system health status."""
        if not self.current_metrics:
            return SystemHealth.UNHEALTHY
        
        health_scores = []
        
        # System resource health
        if self.current_metrics.cpu_usage_percent > 95:
            health_scores.append(0)  # Critical
        elif self.current_metrics.cpu_usage_percent > 80:
            health_scores.append(0.5)  # Degraded
        else:
            health_scores.append(1.0)  # Healthy
        
        # Memory health
        if self.current_metrics.memory_usage_percent > 95:
            health_scores.append(0)
        elif self.current_metrics.memory_usage_percent > 85:
            health_scores.append(0.5)
        else:
            health_scores.append(1.0)
        
        # Application health
        if self.current_metrics.active_agents == 0:
            health_scores.append(0)
        elif self.current_metrics.error_rate_percent > 10:
            health_scores.append(0.2)
        elif self.current_metrics.error_rate_percent > 5:
            health_scores.append(0.6)
        else:
            health_scores.append(1.0)
        
        # Response time health
        if self.current_metrics.response_time_p95_ms > 5000:
            health_scores.append(0)
        elif self.current_metrics.response_time_p95_ms > 2000:
            health_scores.append(0.5)
        else:
            health_scores.append(1.0)
        
        # Calculate overall health
        overall_score = sum(health_scores) / len(health_scores)
        
        if overall_score < 0.3:
            return SystemHealth.CRITICAL
        elif overall_score < 0.6:
            return SystemHealth.UNHEALTHY
        elif overall_score < 0.9:
            return SystemHealth.DEGRADED
        else:
            return SystemHealth.HEALTHY
    
    async def _trigger_health_alert(self, health_status: SystemHealth) -> None:
        """Trigger system health alert."""
        alert_id = str(uuid.uuid4())
        
        severity = ProductionEventSeverity.CRITICAL if health_status == SystemHealth.CRITICAL else ProductionEventSeverity.HIGH
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name="system_health_degraded",
            severity=severity,
            title=f"System Health: {health_status.value.title()}",
            description=f"Overall system health is {health_status.value}",
            triggered_at=datetime.utcnow(),
            affected_components=["system_health"]
        )
        
        self.alert_history.append(alert)
        
        logger.error(f"ðŸ¥ System Health Alert: {health_status.value}")
    
    async def _anomaly_detection_loop(self) -> None:
        """Advanced anomaly detection loop."""
        while self.is_running:
            try:
                await self._detect_system_anomalies()
                await asyncio.sleep(300)  # Check every 5 minutes
                
            except Exception as e:
                logger.error(f"Error in anomaly detection loop: {e}")
                await asyncio.sleep(300)
    
    async def _detect_system_anomalies(self) -> None:
        """Detect system-wide anomalies using advanced techniques."""
        if len(self.metrics_history) < 20:
            return  # Need sufficient history
        
        # Implement advanced anomaly detection algorithms
        # This is a simplified version - production would use more sophisticated ML models
        
        recent_metrics = self.metrics_history[-10:]
        historical_metrics = self.metrics_history[-50:-10]
        
        if not recent_metrics or not historical_metrics:
            return
        
        # Calculate baseline statistics
        baseline_cpu = statistics.mean([m.cpu_usage_percent for m in historical_metrics])
        baseline_memory = statistics.mean([m.memory_usage_percent for m in historical_metrics])
        baseline_response_time = statistics.mean([m.response_time_p95_ms for m in historical_metrics])
        
        # Calculate recent averages
        recent_cpu = statistics.mean([m.cpu_usage_percent for m in recent_metrics])
        recent_memory = statistics.mean([m.memory_usage_percent for m in recent_metrics])
        recent_response_time = statistics.mean([m.response_time_p95_ms for m in recent_metrics])
        
        # Detect significant deviations
        cpu_deviation = abs(recent_cpu - baseline_cpu) / baseline_cpu if baseline_cpu > 0 else 0
        memory_deviation = abs(recent_memory - baseline_memory) / baseline_memory if baseline_memory > 0 else 0
        response_time_deviation = abs(recent_response_time - baseline_response_time) / baseline_response_time if baseline_response_time > 0 else 0
        
        # Trigger anomaly alerts if deviations are significant
        if cpu_deviation > 0.5:  # 50% deviation
            await self._trigger_anomaly_alert("cpu_usage", cpu_deviation, recent_cpu, baseline_cpu)
        
        if memory_deviation > 0.3:  # 30% deviation
            await self._trigger_anomaly_alert("memory_usage", memory_deviation, recent_memory, baseline_memory)
        
        if response_time_deviation > 0.4:  # 40% deviation
            await self._trigger_anomaly_alert("response_time", response_time_deviation, recent_response_time, baseline_response_time)
    
    async def _trigger_anomaly_alert(self, metric_name: str, deviation: float, recent_value: float, baseline_value: float) -> None:
        """Trigger anomaly detection alert."""
        alert_id = str(uuid.uuid4())
        
        alert = ProductionAlert(
            alert_id=alert_id,
            rule_name=f"anomaly_{metric_name}",
            severity=ProductionEventSeverity.MEDIUM,
            title=f"Anomaly Detected: {metric_name.replace('_', ' ').title()}",
            description=f"Significant deviation detected in {metric_name}. Recent: {recent_value:.2f}, Baseline: {baseline_value:.2f}, Deviation: {deviation:.1%}",
            triggered_at=datetime.utcnow(),
            affected_components=["anomaly_detection"],
            metric_values={
                "recent_value": recent_value,
                "baseline_value": baseline_value,
                "deviation_percent": deviation * 100
            }
        )
        
        self.alert_history.append(alert)
        
        logger.warning(f"ðŸ” Anomaly Alert: {alert.title}", deviation_percent=deviation * 100)
    
    # Helper methods for metric collection
    
    async def _get_database_connections(self) -> int:
        """Get current database connection count."""
        try:
            if self.db_session:
                result = await self.db_session.execute(
                    select(func.count()).select_from(
                        select(1).where(1 == 1)  # Simple query to test connection
                    )
                )
                return 10  # Placeholder - implement actual connection counting
        except Exception:
            pass
        return 0
    
    async def _get_average_db_query_time(self) -> float:
        """Get average database query time."""
        # Placeholder - implement actual query time monitoring
        return 50.0  # milliseconds
    
    async def _get_db_pool_usage(self) -> float:
        """Get database connection pool usage percentage."""
        # Placeholder - implement actual pool monitoring
        return 25.0  # percent
    
    async def _get_redis_metrics(self) -> Tuple[float, int, float]:
        """Get Redis memory, connections, and latency."""
        try:
            redis_client = get_redis()
            info = await redis_client.info()
            
            memory_mb = info.get('used_memory', 0) / (1024 * 1024)
            connections = info.get('connected_clients', 0)
            
            # Measure latency with ping
            start_time = time.time()
            await redis_client.ping()
            latency_ms = (time.time() - start_time) * 1000
            
            return memory_mb, connections, latency_ms
            
        except Exception:
            return 0.0, 0, 0.0
    
    async def _get_active_agent_count(self) -> int:
        """Get count of active agents."""
        try:
            if self.db_session:
                result = await self.db_session.execute(
                    select(func.count(Agent.id)).where(Agent.status == AgentStatus.ACTIVE)
                )
                return result.scalar() or 0
        except Exception:
            pass
        return 0
    
    async def _get_total_session_count(self) -> int:
        """Get total active session count."""
        try:
            if self.db_session:
                result = await self.db_session.execute(
                    select(func.count(Session.id)).where(Session.status == SessionStatus.ACTIVE)
                )
                return result.scalar() or 0
        except Exception:
            pass
        return 0
    
    async def _get_pending_task_count(self) -> int:
        """Get count of pending tasks."""
        try:
            if self.db_session:
                result = await self.db_session.execute(
                    select(func.count(Task.id)).where(Task.status == TaskStatus.PENDING)
                )
                return result.scalar() or 0
        except Exception:
            pass
        return 0
    
    async def _get_failed_tasks_last_hour(self) -> int:
        """Get count of failed tasks in the last hour."""
        try:
            if self.db_session:
                one_hour_ago = datetime.utcnow() - timedelta(hours=1)
                result = await self.db_session.execute(
                    select(func.count(Task.id)).where(
                        and_(
                            Task.status == TaskStatus.FAILED,
                            Task.updated_at >= one_hour_ago
                        )
                    )
                )
                return result.scalar() or 0
        except Exception:
            pass
        return 0
    
    async def _get_average_response_time(self) -> float:
        """Get average response time from recent metrics."""
        if len(self.metrics_history) >= 5:
            recent_times = [m.response_time_p95_ms for m in self.metrics_history[-5:]]
            return statistics.mean(recent_times)
        return 0.0
    
    async def _calculate_availability(self) -> float:
        """Calculate system availability percentage."""
        # Simplified calculation - in production, this would be more sophisticated
        if self.current_metrics and self.current_metrics.active_agents > 0:
            return 99.9  # High availability when agents are running
        return 95.0  # Degraded availability
    
    async def _calculate_error_rate(self) -> float:
        """Calculate current error rate percentage."""
        try:
            if self.db_session:
                one_hour_ago = datetime.utcnow() - timedelta(hours=1)
                
                # Get total tasks in last hour
                total_result = await self.db_session.execute(
                    select(func.count(Task.id)).where(Task.created_at >= one_hour_ago)
                )
                total_tasks = total_result.scalar() or 0
                
                # Get failed tasks in last hour
                failed_result = await self.db_session.execute(
                    select(func.count(Task.id)).where(
                        and_(
                            Task.status == TaskStatus.FAILED,
                            Task.created_at >= one_hour_ago
                        )
                    )
                )
                failed_tasks = failed_result.scalar() or 0
                
                if total_tasks > 0:
                    return (failed_tasks / total_tasks) * 100
                    
        except Exception:
            pass
        return 0.0
    
    async def _calculate_response_time_percentile(self, percentile: int) -> float:
        """Calculate response time percentile."""
        # Placeholder - implement actual percentile calculation from request logs
        if percentile == 95:
            return 800.0  # milliseconds
        elif percentile == 99:
            return 1500.0  # milliseconds
        return 500.0
    
    async def _get_failed_auth_attempts(self) -> int:
        """Get count of failed authentication attempts."""
        # Placeholder - implement actual auth failure tracking
        return 5
    
    async def _get_security_events(self) -> int:
        """Get count of security events."""
        # Placeholder - implement actual security event tracking
        return 2
    
    async def _get_blocked_requests(self) -> int:
        """Get count of blocked requests."""
        # Placeholder - implement actual blocked request tracking
        return 10
    
    async def _calculate_task_completion_rate(self) -> float:
        """Calculate task completion rate."""
        try:
            if self.db_session:
                one_hour_ago = datetime.utcnow() - timedelta(hours=1)
                
                # Get total completed/failed tasks
                result = await self.db_session.execute(
                    select(func.count(Task.id)).where(
                        and_(
                            Task.status.in_([TaskStatus.COMPLETED, TaskStatus.FAILED]),
                            Task.updated_at >= one_hour_ago
                        )
                    )
                )
                total_finished = result.scalar() or 0
                
                # Get completed tasks
                completed_result = await self.db_session.execute(
                    select(func.count(Task.id)).where(
                        and_(
                            Task.status == TaskStatus.COMPLETED,
                            Task.updated_at >= one_hour_ago
                        )
                    )
                )
                completed_tasks = completed_result.scalar() or 0
                
                if total_finished > 0:
                    return (completed_tasks / total_finished) * 100
                    
        except Exception:
            pass
        return 95.0  # Default high completion rate
    
    async def _calculate_sla_compliance(self) -> Dict[str, Any]:
        """Calculate overall SLA compliance."""
        if not self.sla_targets:
            return {"overall_compliance": 100.0, "targets": {}}
        
        target_compliance = {}
        for target in self.sla_targets:
            target_compliance[target.name] = {
                "compliance_percent": target.compliance_percent,
                "current_value": target.current_value,
                "target_value": target.target_value,
                "breach_count": target.breach_count,
                "last_breach": target.last_breach.isoformat() if target.last_breach else None
            }
        
        # Calculate overall compliance
        compliance_values = [t.compliance_percent for t in self.sla_targets]
        overall_compliance = statistics.mean(compliance_values) if compliance_values else 100.0
        
        return {
            "overall_compliance": overall_compliance,
            "targets": target_compliance
        }
    
    async def _get_auto_scaling_status(self) -> Dict[str, Any]:
        """Get auto-scaling status."""
        return {
            "enabled": self.auto_scaling_enabled,
            "min_agents": self.min_agents,
            "max_agents": self.max_agents,
            "current_agents": self.current_metrics.active_agents if self.current_metrics else 0,
            "last_scaling_action": self.last_scaling_action.isoformat() if self.last_scaling_action else None,
            "cooldown_minutes": self.scaling_cooldown_minutes
        }
    
    async def _get_disaster_recovery_status(self) -> DisasterRecoveryStatus:
        """Get disaster recovery status."""
        return DisasterRecoveryStatus(
            backup_status="healthy" if self.backup_enabled else "disabled",
            last_backup=self.last_backup,
            recovery_point_objective_minutes=60,  # 1 hour RPO
            recovery_time_objective_minutes=30,   # 30 minute RTO
            backup_age_hours=(datetime.utcnow() - self.last_backup).total_seconds() / 3600 if self.last_backup else 999,
            data_integrity_score=99.9,
            estimated_recovery_time_minutes=25
        )
    
    async def _get_component_health_summary(self) -> Dict[str, str]:
        """Get component health summary."""
        return {
            "database": "healthy",
            "redis": "healthy", 
            "agent_orchestrator": "healthy" if self.agent_orchestrator else "unavailable",
            "performance_orchestrator": "healthy" if self.performance_orchestrator else "unavailable",
            "backup_system": "healthy" if self.backup_enabled else "disabled",
            "alerting_system": "healthy",
            "monitoring_system": "healthy"
        }
    
    async def _get_performance_summary(self) -> Dict[str, Any]:
        """Get performance summary."""
        if not self.current_metrics:
            return {}
        
        return {
            "response_time_p95_ms": self.current_metrics.response_time_p95_ms,
            "response_time_p99_ms": self.current_metrics.response_time_p99_ms,
            "error_rate_percent": self.current_metrics.error_rate_percent,
            "availability_percent": self.current_metrics.availability_percent,
            "throughput_estimate": max(0, 1000 - self.current_metrics.pending_tasks),  # Simplified
            "resource_utilization": {
                "cpu": self.current_metrics.cpu_usage_percent,
                "memory": self.current_metrics.memory_usage_percent,
                "disk": self.current_metrics.disk_usage_percent
            }
        }
    
    async def _get_least_utilized_agents(self, count: int) -> List[str]:
        """Get IDs of least utilized agents for scale-down."""
        # Placeholder - implement actual agent utilization tracking
        # This would query agent performance metrics and return least busy agents
        try:
            if self.db_session:
                result = await self.db_session.execute(
                    select(Agent.id).where(Agent.status == AgentStatus.ACTIVE).limit(count)
                )
                return [str(row[0]) for row in result.fetchall()]
        except Exception:
            pass
        return []
    
    async def _store_metrics_in_database(self, metrics: ProductionMetrics) -> None:
        """Store metrics in database for persistence."""
        try:
            if self.db_session:
                # Store key metrics as performance metrics
                metric_entries = [
                    PerformanceMetric(
                        metric_name="production_cpu_usage",
                        metric_value=metrics.cpu_usage_percent,
                        tags={"component": "system"}
                    ),
                    PerformanceMetric(
                        metric_name="production_memory_usage",
                        metric_value=metrics.memory_usage_percent,
                        tags={"component": "system"}
                    ),
                    PerformanceMetric(
                        metric_name="production_response_time_p95",
                        metric_value=metrics.response_time_p95_ms,
                        tags={"component": "application"}
                    ),
                    PerformanceMetric(
                        metric_name="production_error_rate",
                        metric_value=metrics.error_rate_percent,
                        tags={"component": "application"}
                    )
                ]
                
                for metric in metric_entries:
                    self.db_session.add(metric)
                
                await self.db_session.commit()
                
        except Exception as e:
            logger.error(f"Failed to store metrics in database: {e}")
    
    async def _update_prometheus_metrics(self, metrics: ProductionMetrics) -> None:
        """Update Prometheus metrics with current values."""
        try:
            # Update system metrics
            self.metrics_exporter.system_cpu_usage_percent.set(metrics.cpu_usage_percent)
            self.metrics_exporter.system_memory_usage_bytes.labels(type='percent').set(metrics.memory_usage_percent)
            
            # Update application metrics
            self.metrics_exporter.active_agents_total.set(metrics.active_agents)
            self.metrics_exporter.active_sessions_total.set(metrics.total_sessions)
            self.metrics_exporter.tasks_in_progress.labels(task_type='all').set(metrics.pending_tasks)
            
            # Update performance metrics
            self.metrics_exporter.performance_percentiles.labels(operation_type='http_request').observe(
                metrics.response_time_p95_ms / 1000  # Convert to seconds
            )
            
        except Exception as e:
            logger.error(f"Failed to update Prometheus metrics: {e}")


# Factory function
async def create_production_orchestrator(
    agent_orchestrator: Optional[AgentOrchestrator] = None,
    performance_orchestrator: Optional[PerformanceOrchestrator] = None
) -> ProductionOrchestrator:
    """Create and initialize production orchestrator."""
    orchestrator = ProductionOrchestrator(
        agent_orchestrator=agent_orchestrator,
        performance_orchestrator=performance_orchestrator
    )
    await orchestrator.start()
    return orchestrator