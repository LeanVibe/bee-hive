"""
Graceful Degradation Framework for LeanVibe Agent Hive 2.0 - VS 3.3

Production-ready graceful degradation with intelligent fallback mechanisms:
- Multi-level degradation strategies (none, minimal, partial, full)
- Service-specific fallback implementations
- Performance monitoring with <2ms overhead
- Integration with circuit breaker and observability systems
- Intelligent recovery detection and restoration
"""

import asyncio
import time
import json
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union, Callable, Type
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import structlog

from fastapi import Response
from fastapi.responses import JSONResponse

logger = structlog.get_logger()


class DegradationLevel(Enum):
    """Degradation levels for service fallback."""
    NONE = "none"           # No degradation - full functionality
    MINIMAL = "minimal"     # Minor feature reduction
    PARTIAL = "partial"     # Significant feature reduction with core functionality
    FULL = "full"          # Full degradation - basic/cached responses only


class ServiceStatus(Enum):
    """Service health status for degradation decisions."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNAVAILABLE = "unavailable"


@dataclass
class DegradationConfig:
    """Configuration for graceful degradation behavior."""
    enabled: bool = True
    default_level: DegradationLevel = DegradationLevel.NONE
    auto_recovery_enabled: bool = True
    recovery_check_interval_seconds: int = 30
    recovery_success_threshold: int = 3
    
    # Performance settings
    max_processing_time_ms: float = 2.0  # Target <2ms overhead
    enable_metrics: bool = True
    enable_logging: bool = True
    
    # Cache settings for degraded responses
    cache_enabled: bool = True
    cache_ttl_seconds: int = 300  # 5 minutes
    max_cache_size: int = 1000
    
    # Service-specific settings
    service_timeouts: Dict[str, int] = field(default_factory=lambda: {
        "semantic_memory": 5000,     # 5 seconds
        "workflow_engine": 10000,    # 10 seconds
        "agent_communication": 3000,  # 3 seconds
        "database": 2000,            # 2 seconds
        "redis": 1000                # 1 second
    })


@dataclass
class DegradationMetrics:
    """Metrics for graceful degradation performance."""
    total_requests: int = 0
    degraded_requests: int = 0
    degradation_activations: int = 0
    degradation_recoveries: int = 0
    
    # Level-specific metrics
    minimal_degradations: int = 0
    partial_degradations: int = 0
    full_degradations: int = 0
    
    # Performance metrics
    average_processing_time_ms: float = 0.0
    max_processing_time_ms: float = 0.0
    cache_hits: int = 0
    cache_misses: int = 0
    
    # Time-based metrics
    last_degradation_time: Optional[datetime] = None
    last_recovery_time: Optional[datetime] = None
    total_degraded_time_seconds: float = 0.0


class FallbackStrategy(ABC):
    """Abstract base class for fallback strategies."""
    
    @abstractmethod
    async def execute_fallback(
        self,
        service_path: str,
        degradation_level: DegradationLevel,
        error_context: Dict[str, Any],
        original_request_data: Optional[Dict[str, Any]] = None
    ) -> Optional[Response]:
        """Execute fallback strategy for degraded service."""
        pass
    
    @abstractmethod
    def supports_path(self, service_path: str) -> bool:
        """Check if this strategy supports the given service path."""
        pass


class CachedResponseStrategy(FallbackStrategy):
    """Fallback strategy using cached responses."""
    
    def __init__(self, cache_ttl_seconds: int = 300, max_cache_size: int = 1000):
        self.cache_ttl_seconds = cache_ttl_seconds
        self.max_cache_size = max_cache_size
        self._cache: Dict[str, Tuple[datetime, Response]] = {}
        self._cache_lock = asyncio.Lock()
    
    async def execute_fallback(
        self,
        service_path: str,
        degradation_level: DegradationLevel,
        error_context: Dict[str, Any],
        original_request_data: Optional[Dict[str, Any]] = None
    ) -> Optional[Response]:
        """Return cached response if available and not expired."""
        
        async with self._cache_lock:
            cache_key = self._generate_cache_key(service_path, original_request_data)
            
            if cache_key in self._cache:
                cached_time, cached_response = self._cache[cache_key]
                
                # Check if cache is still valid
                if datetime.utcnow() - cached_time < timedelta(seconds=self.cache_ttl_seconds):
                    logger.debug(
                        "ðŸ“¦ Returning cached response for degraded service",
                        service_path=service_path,
                        degradation_level=degradation_level.value,
                        cache_age_seconds=(datetime.utcnow() - cached_time).total_seconds()
                    )
                    return cached_response
                else:
                    # Remove expired cache entry
                    del self._cache[cache_key]
        
        return None
    
    def supports_path(self, service_path: str) -> bool:
        """All paths can potentially use cached responses."""
        return True
    
    async def cache_response(
        self,
        service_path: str,
        response: Response,
        request_data: Optional[Dict[str, Any]] = None
    ) -> None:
        """Cache a successful response for future fallback use."""
        
        async with self._cache_lock:
            # Clean up old entries if cache is full
            if len(self._cache) >= self.max_cache_size:
                await self._cleanup_expired_cache()
                
                # If still full, remove oldest entries
                if len(self._cache) >= self.max_cache_size:
                    oldest_keys = sorted(
                        self._cache.keys(),
                        key=lambda k: self._cache[k][0]
                    )[:self.max_cache_size // 4]
                    
                    for key in oldest_keys:
                        del self._cache[key]
            
            cache_key = self._generate_cache_key(service_path, request_data)
            self._cache[cache_key] = (datetime.utcnow(), response)
    
    def _generate_cache_key(
        self,
        service_path: str,
        request_data: Optional[Dict[str, Any]]
    ) -> str:
        """Generate cache key from service path and request data."""
        
        if request_data:
            # Create a stable hash of request data
            data_str = json.dumps(request_data, sort_keys=True, default=str)
            return f"{service_path}:{hash(data_str)}"
        else:
            return service_path
    
    async def _cleanup_expired_cache(self) -> None:
        """Remove expired entries from cache."""
        current_time = datetime.utcnow()
        expired_keys = []
        
        for key, (cached_time, _) in self._cache.items():
            if current_time - cached_time >= timedelta(seconds=self.cache_ttl_seconds):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self._cache[key]
    
    def get_cache_metrics(self) -> Dict[str, Any]:
        """Get cache performance metrics."""
        return {
            "cache_size": len(self._cache),
            "max_cache_size": self.max_cache_size,
            "cache_ttl_seconds": self.cache_ttl_seconds
        }


class StaticResponseStrategy(FallbackStrategy):
    """Fallback strategy returning static responses based on service type."""
    
    def __init__(self):
        self.static_responses = {
            "/api/v1/agents": {
                "agents": [],
                "total": 0,
                "message": "Agent service temporarily unavailable"
            },
            "/api/v1/tasks": {
                "tasks": [],
                "total": 0,
                "message": "Task service temporarily unavailable"
            },
            "/api/v1/workflows": {
                "workflows": [],
                "total": 0,
                "message": "Workflow service temporarily unavailable"
            },
            "/api/v1/semantic_memory": {
                "results": [],
                "message": "Semantic memory service temporarily unavailable"
            }
        }
    
    async def execute_fallback(
        self,
        service_path: str,
        degradation_level: DegradationLevel,
        error_context: Dict[str, Any],
        original_request_data: Optional[Dict[str, Any]] = None
    ) -> Optional[Response]:
        """Return static response based on service path."""
        
        # Find matching static response
        static_response = None
        for path_pattern, response_data in self.static_responses.items():
            if service_path.startswith(path_pattern):
                static_response = response_data.copy()
                break
        
        if static_response:
            # Add degradation information
            static_response["degraded"] = True
            static_response["degradation_level"] = degradation_level.value
            static_response["error_context"] = {
                "type": error_context.get("error_type", "unknown"),
                "message": "Service temporarily degraded"
            }
            
            logger.debug(
                "ðŸ“‹ Returning static response for degraded service",
                service_path=service_path,
                degradation_level=degradation_level.value
            )
            
            return JSONResponse(
                status_code=206,  # Partial Content
                content=static_response,
                headers={
                    "X-Degradation-Level": degradation_level.value,
                    "X-Fallback-Strategy": "static_response"
                }
            )
        
        return None
    
    def supports_path(self, service_path: str) -> bool:
        """Check if we have a static response for this path."""
        return any(service_path.startswith(pattern) for pattern in self.static_responses.keys())


class ServiceHealthTracker:
    """Tracks service health for degradation decisions."""
    
    def __init__(self, recovery_check_interval: int = 30, success_threshold: int = 3):
        self.recovery_check_interval = recovery_check_interval
        self.success_threshold = success_threshold
        
        # Service health tracking
        self._service_status: Dict[str, ServiceStatus] = {}
        self._service_errors: Dict[str, List[Tuple[datetime, str]]] = {}
        self._service_successes: Dict[str, List[datetime]] = {}
        self._degradation_start_times: Dict[str, datetime] = {}
        
        # Recovery tracking
        self._recovery_tasks: Dict[str, asyncio.Task] = {}
        
    async def record_service_error(self, service_name: str, error: str) -> None:
        """Record an error for a service."""
        current_time = datetime.utcnow()
        
        if service_name not in self._service_errors:
            self._service_errors[service_name] = []
        
        self._service_errors[service_name].append((current_time, error))
        
        # Keep only recent errors (last hour)
        cutoff_time = current_time - timedelta(hours=1)
        self._service_errors[service_name] = [
            (time, err) for time, err in self._service_errors[service_name]
            if time > cutoff_time
        ]
        
        # Update service status based on error pattern
        await self._update_service_status(service_name)
    
    async def record_service_success(self, service_name: str) -> None:
        """Record a success for a service."""
        current_time = datetime.utcnow()
        
        if service_name not in self._service_successes:
            self._service_successes[service_name] = []
        
        self._service_successes[service_name].append(current_time)
        
        # Keep only recent successes (last hour)
        cutoff_time = current_time - timedelta(hours=1)
        self._service_successes[service_name] = [
            time for time in self._service_successes[service_name]
            if time > cutoff_time
        ]
        
        # Update service status
        await self._update_service_status(service_name)
    
    def get_service_status(self, service_name: str) -> ServiceStatus:
        """Get current status of a service."""
        return self._service_status.get(service_name, ServiceStatus.HEALTHY)
    
    def get_degradation_level_for_service(self, service_name: str) -> DegradationLevel:
        """Get recommended degradation level for a service."""
        status = self.get_service_status(service_name)
        
        if status == ServiceStatus.HEALTHY:
            return DegradationLevel.NONE
        elif status == ServiceStatus.DEGRADED:
            return DegradationLevel.MINIMAL
        elif status == ServiceStatus.UNHEALTHY:
            return DegradationLevel.PARTIAL
        else:  # UNAVAILABLE
            return DegradationLevel.FULL
    
    async def _update_service_status(self, service_name: str) -> None:
        """Update service status based on recent errors and successes."""
        current_time = datetime.utcnow()
        
        # Get recent errors and successes (last 15 minutes)
        recent_cutoff = current_time - timedelta(minutes=15)
        
        recent_errors = [
            (time, err) for time, err in self._service_errors.get(service_name, [])
            if time > recent_cutoff
        ]
        
        recent_successes = [
            time for time in self._service_successes.get(service_name, [])
            if time > recent_cutoff
        ]
        
        total_recent = len(recent_errors) + len(recent_successes)
        
        if total_recent == 0:
            # No recent activity - assume healthy
            new_status = ServiceStatus.HEALTHY
        else:
            error_rate = len(recent_errors) / total_recent
            
            if error_rate <= 0.1:  # <= 10% errors
                new_status = ServiceStatus.HEALTHY
            elif error_rate <= 0.3:  # <= 30% errors
                new_status = ServiceStatus.DEGRADED
            elif error_rate <= 0.7:  # <= 70% errors
                new_status = ServiceStatus.UNHEALTHY
            else:  # > 70% errors
                new_status = ServiceStatus.UNAVAILABLE
        
        old_status = self._service_status.get(service_name, ServiceStatus.HEALTHY)
        
        if old_status != new_status:
            self._service_status[service_name] = new_status
            
            # Track degradation start time
            if new_status != ServiceStatus.HEALTHY and old_status == ServiceStatus.HEALTHY:
                self._degradation_start_times[service_name] = current_time
            elif new_status == ServiceStatus.HEALTHY:
                self._degradation_start_times.pop(service_name, None)
            
            logger.info(
                "ðŸ”„ Service status changed",
                service_name=service_name,
                old_status=old_status.value,
                new_status=new_status.value,
                recent_error_rate=len(recent_errors) / max(1, total_recent)
            )
    
    def get_health_metrics(self) -> Dict[str, Any]:
        """Get service health metrics."""
        current_time = datetime.utcnow()
        
        service_metrics = {}
        for service_name, status in self._service_status.items():
            degradation_time = 0.0
            if service_name in self._degradation_start_times:
                degradation_time = (current_time - self._degradation_start_times[service_name]).total_seconds()
            
            service_metrics[service_name] = {
                "status": status.value,
                "degradation_time_seconds": degradation_time,
                "recent_errors": len(self._service_errors.get(service_name, [])),
                "recent_successes": len(self._service_successes.get(service_name, []))
            }
        
        return {
            "services": service_metrics,
            "total_services": len(self._service_status),
            "healthy_services": sum(1 for s in self._service_status.values() if s == ServiceStatus.HEALTHY),
            "degraded_services": sum(1 for s in self._service_status.values() if s != ServiceStatus.HEALTHY)
        }


class GracefulDegradationManager:
    """
    Comprehensive graceful degradation manager.
    
    Features:
    - Multi-level degradation strategies
    - Service-specific fallback implementations
    - Intelligent recovery detection
    - Performance monitoring with <2ms overhead
    - Integration with circuit breaker patterns
    """
    
    def __init__(self, config: Optional[DegradationConfig] = None):
        """Initialize graceful degradation manager."""
        self.config = config or DegradationConfig()
        self.metrics = DegradationMetrics()
        
        # Service health tracking
        self.health_tracker = ServiceHealthTracker(
            recovery_check_interval=self.config.recovery_check_interval_seconds,
            success_threshold=self.config.recovery_success_threshold
        )
        
        # Fallback strategies
        self.fallback_strategies: List[FallbackStrategy] = []
        
        # Initialize default strategies
        if self.config.cache_enabled:
            self.cached_response_strategy = CachedResponseStrategy(
                cache_ttl_seconds=self.config.cache_ttl_seconds,
                max_cache_size=self.config.max_cache_size
            )
            self.fallback_strategies.append(self.cached_response_strategy)
        
        self.static_response_strategy = StaticResponseStrategy()
        self.fallback_strategies.append(self.static_response_strategy)
        
        # Performance tracking
        self._processing_times: List[float] = []
        
        logger.info(
            "ðŸ›¡ï¸ Graceful degradation manager initialized",
            enabled=self.config.enabled,
            auto_recovery=self.config.auto_recovery_enabled,
            fallback_strategies=len(self.fallback_strategies)
        )
    
    async def apply_degradation(
        self,
        service_path: str,
        degradation_level: DegradationLevel,
        error_context: Dict[str, Any],
        original_request_data: Optional[Dict[str, Any]] = None
    ) -> Optional[Response]:
        """
        Apply graceful degradation for a service request.
        
        Args:
            service_path: Path of the service request
            degradation_level: Level of degradation to apply
            error_context: Context about the error that triggered degradation
            original_request_data: Original request data for context
            
        Returns:
            Degraded response or None if no fallback available
        """
        if not self.config.enabled:
            return None
        
        start_time = time.time()
        
        try:
            # Update metrics
            self.metrics.total_requests += 1
            
            if degradation_level != DegradationLevel.NONE:
                self.metrics.degraded_requests += 1
                self.metrics.last_degradation_time = datetime.utcnow()
                
                # Update level-specific metrics
                if degradation_level == DegradationLevel.MINIMAL:
                    self.metrics.minimal_degradations += 1
                elif degradation_level == DegradationLevel.PARTIAL:
                    self.metrics.partial_degradations += 1
                elif degradation_level == DegradationLevel.FULL:
                    self.metrics.full_degradations += 1
            
            # Try each fallback strategy
            for strategy in self.fallback_strategies:
                if strategy.supports_path(service_path):
                    try:
                        response = await strategy.execute_fallback(
                            service_path=service_path,
                            degradation_level=degradation_level,
                            error_context=error_context,
                            original_request_data=original_request_data
                        )
                        
                        if response:
                            # Record success
                            if hasattr(self, 'cached_response_strategy') and strategy == self.cached_response_strategy:
                                self.metrics.cache_hits += 1
                            
                            processing_time = (time.time() - start_time) * 1000
                            await self._record_processing_time(processing_time)
                            
                            logger.info(
                                "âœ… Graceful degradation applied successfully",
                                service_path=service_path,
                                degradation_level=degradation_level.value,
                                strategy=strategy.__class__.__name__,
                                processing_time_ms=round(processing_time, 2)
                            )
                            
                            return response
                            
                    except Exception as strategy_error:
                        logger.warning(
                            "âš ï¸ Fallback strategy failed",
                            service_path=service_path,
                            strategy=strategy.__class__.__name__,
                            error=str(strategy_error)
                        )
                        continue
            
            # No successful fallback
            if hasattr(self, 'cached_response_strategy'):
                self.metrics.cache_misses += 1
            
            processing_time = (time.time() - start_time) * 1000
            await self._record_processing_time(processing_time)
            
            logger.warning(
                "âŒ No fallback strategy succeeded",
                service_path=service_path,
                degradation_level=degradation_level.value,
                strategies_tried=len(self.fallback_strategies)
            )
            
            return None
            
        except Exception as error:
            logger.error(
                "âŒ Error applying graceful degradation",
                service_path=service_path,
                error=str(error),
                exc_info=True
            )
            return None
    
    async def record_service_error(self, service_name: str, error: str) -> None:
        """Record an error for service health tracking."""
        await self.health_tracker.record_service_error(service_name, error)
    
    async def record_service_success(self, service_name: str) -> None:
        """Record a success for service health tracking."""
        await self.health_tracker.record_service_success(service_name)
    
    async def cache_successful_response(
        self,
        service_path: str,
        response: Response,
        request_data: Optional[Dict[str, Any]] = None
    ) -> None:
        """Cache a successful response for future fallback use."""
        if hasattr(self, 'cached_response_strategy'):
            await self.cached_response_strategy.cache_response(service_path, response, request_data)
    
    def get_service_degradation_level(self, service_name: str) -> DegradationLevel:
        """Get recommended degradation level for a service."""
        return self.health_tracker.get_degradation_level_for_service(service_name)
    
    def add_fallback_strategy(self, strategy: FallbackStrategy) -> None:
        """Add a custom fallback strategy."""
        self.fallback_strategies.append(strategy)
        logger.info(f"âž• Added fallback strategy: {strategy.__class__.__name__}")
    
    async def _record_processing_time(self, processing_time_ms: float) -> None:
        """Record processing time for performance monitoring."""
        self._processing_times.append(processing_time_ms)
        
        # Keep only recent measurements
        if len(self._processing_times) > 1000:
            self._processing_times = self._processing_times[-500:]
        
        # Update metrics
        if self._processing_times:
            self.metrics.average_processing_time_ms = sum(self._processing_times) / len(self._processing_times)
            self.metrics.max_processing_time_ms = max(self._processing_times)
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get comprehensive degradation metrics."""
        degradation_rate = 0.0
        if self.metrics.total_requests > 0:
            degradation_rate = self.metrics.degraded_requests / self.metrics.total_requests
        
        metrics = {
            "total_requests": self.metrics.total_requests,
            "degraded_requests": self.metrics.degraded_requests,
            "degradation_rate": degradation_rate,
            "degradation_activations": self.metrics.degradation_activations,
            "degradation_recoveries": self.metrics.degradation_recoveries,
            "level_breakdown": {
                "minimal": self.metrics.minimal_degradations,
                "partial": self.metrics.partial_degradations,
                "full": self.metrics.full_degradations
            },
            "performance": {
                "average_processing_time_ms": self.metrics.average_processing_time_ms,
                "max_processing_time_ms": self.metrics.max_processing_time_ms,
                "target_met": self.metrics.average_processing_time_ms <= self.config.max_processing_time_ms
            },
            "cache": {
                "hits": self.metrics.cache_hits,
                "misses": self.metrics.cache_misses,
                "hit_rate": self.metrics.cache_hits / max(1, self.metrics.cache_hits + self.metrics.cache_misses)
            },
            "service_health": self.health_tracker.get_health_metrics(),
            "configuration": {
                "enabled": self.config.enabled,
                "auto_recovery": self.config.auto_recovery_enabled,
                "cache_enabled": self.config.cache_enabled,
                "max_processing_time_ms": self.config.max_processing_time_ms
            }
        }
        
        # Add cache-specific metrics if available
        if hasattr(self, 'cached_response_strategy'):
            metrics["cache_details"] = self.cached_response_strategy.get_cache_metrics()
        
        return metrics
    
    async def health_check(self) -> Dict[str, Any]:
        """Perform health check of graceful degradation system."""
        metrics = self.get_metrics()
        
        # Determine health status
        issues = []
        if not metrics["performance"]["target_met"]:
            issues.append("Processing time exceeds target")
        
        if metrics["degradation_rate"] > 0.3:  # >30% degradation rate
            issues.append("High degradation rate detected")
        
        service_health = metrics["service_health"]
        if service_health["degraded_services"] > service_health["total_services"] * 0.5:
            issues.append("More than 50% of services degraded")
        
        status = "healthy" if not issues else "degraded"
        
        return {
            "status": status,
            "issues": issues,
            "metrics": metrics,
            "recommendations": self._get_health_recommendations(metrics)
        }
    
    def _get_health_recommendations(self, metrics: Dict[str, Any]) -> List[str]:
        """Get health recommendations based on current metrics."""
        recommendations = []
        
        if not metrics["performance"]["target_met"]:
            recommendations.append("Consider optimizing fallback strategies for better performance")
        
        if metrics["cache"]["hit_rate"] < 0.3:
            recommendations.append("Low cache hit rate - consider adjusting cache TTL or size")
        
        if metrics["degradation_rate"] > 0.2:
            recommendations.append("High degradation rate - investigate underlying service issues")
        
        degraded_services = metrics["service_health"]["degraded_services"]
        if degraded_services > 0:
            recommendations.append(f"Monitor and address {degraded_services} degraded services")
        
        return recommendations
    
    def reset_metrics(self) -> None:
        """Reset metrics for testing or monitoring resets."""
        self.metrics = DegradationMetrics()
        self._processing_times.clear()
        
        logger.info("ðŸ”„ Graceful degradation metrics reset")


# Global degradation manager instance
_degradation_manager: Optional[GracefulDegradationManager] = None


def get_degradation_manager(config: Optional[DegradationConfig] = None) -> GracefulDegradationManager:
    """Get or create global degradation manager instance."""
    global _degradation_manager
    
    if _degradation_manager is None:
        _degradation_manager = GracefulDegradationManager(config)
    
    return _degradation_manager